{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1000001",
   "metadata": {},
   "source": [
    "# 01. Time Travel\n",
    "\n",
    "Icebergì˜ **Time Travel** ê¸°ëŠ¥ì„ í™œìš©í•˜ì—¬ ê³¼ê±° ì‹œì ì˜ ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ê³ , ì‹¤ìˆ˜ë¡œ ì‚­ì œëœ ë°ì´í„°ë¥¼ ë³µêµ¬í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1000002",
   "metadata": {},
   "source": [
    "## Time Travel ê°œë…\n",
    "\n",
    "IcebergëŠ” ëª¨ë“  ë°ì´í„° ë³€ê²½ì„ **ìŠ¤ëƒ…ìƒ·(Snapshot)**ìœ¼ë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤.\n",
    "\n",
    "```\n",
    "Snapshot 1 (INSERT 100ê±´)\n",
    "    â”‚\n",
    "    â–¼\n",
    "Snapshot 2 (UPDATE 20ê±´)\n",
    "    â”‚\n",
    "    â–¼\n",
    "Snapshot 3 (DELETE 10ê±´)\n",
    "    â”‚\n",
    "    â–¼\n",
    "Snapshot 4 (INSERT 50ê±´)  â—€ current\n",
    "```\n",
    "\n",
    "- ê° ìŠ¤ëƒ…ìƒ·ì€ **ë¶ˆë³€(immutable)**í•˜ë©°, ì´ì „ ìŠ¤ëƒ…ìƒ·ì˜ ë°ì´í„° íŒŒì¼ì€ ê·¸ëŒ€ë¡œ ìœ ì§€ë©ë‹ˆë‹¤\n",
    "- `VERSION AS OF` ë˜ëŠ” `TIMESTAMP AS OF`ë¡œ ê³¼ê±° ì‹œì ì˜ ë°ì´í„°ë¥¼ ì¡°íšŒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
    "- `rollback_to_snapshot`ìœ¼ë¡œ íŠ¹ì • ìŠ¤ëƒ…ìƒ· ìƒíƒœë¡œ í…Œì´ë¸”ì„ ë˜ëŒë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
    "\n",
    "### Time Travelì˜ í™œìš© ì‚¬ë¡€\n",
    "\n",
    "| ì‹œë‚˜ë¦¬ì˜¤ | ë°©ë²• |\n",
    "|----------|------|\n",
    "| ê³¼ê±° ì‹œì  ë°ì´í„° ë¶„ì„ | `SELECT * FROM table VERSION AS OF {snapshot_id}` |\n",
    "| ì‹œê°„ ê¸°ë°˜ ë°ì´í„° ì¡°íšŒ | `SELECT * FROM table TIMESTAMP AS OF '{timestamp}'` |\n",
    "| ì‹¤ìˆ˜ ë³µêµ¬ (ì˜ëª»ëœ DELETE/UPDATE) | `CALL system.rollback_to_snapshot(...)` |\n",
    "| ë°ì´í„° ë³€ê²½ ì¶”ì  (audit) | ìŠ¤ëƒ…ìƒ·ë³„ ë°ì´í„° ë¹„êµ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1000003",
   "metadata": {},
   "source": [
    "## í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1000004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.spark_setup import create_spark_session\n",
    "from utils.data_generator import generate_orders, to_spark_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1000005",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = create_spark_session(\"TimeTravel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1000006",
   "metadata": {},
   "source": [
    "## í…Œì´ë¸” ìƒì„± ë° 4ê°œ ìŠ¤ëƒ…ìƒ· ë§Œë“¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1000007",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS demo.lab\")\n",
    "spark.sql(\"DROP TABLE IF EXISTS demo.lab.tt_orders\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    CREATE TABLE demo.lab.tt_orders (\n",
    "        order_id     BIGINT,\n",
    "        customer_id  BIGINT,\n",
    "        product_name STRING,\n",
    "        order_date   DATE,\n",
    "        amount       DOUBLE,\n",
    "        status       STRING\n",
    "    )\n",
    "    USING iceberg\n",
    "    PARTITIONED BY (months(order_date))\n",
    "\"\"\")\n",
    "\n",
    "print(\"í…Œì´ë¸” ìƒì„± ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1000008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snapshot 1: 100ê±´ INSERT\n",
    "orders1 = generate_orders(num_records=100, seed=42)\n",
    "df1 = to_spark_df(spark, orders1)\n",
    "df1.writeTo(\"demo.lab.tt_orders\").append()\n",
    "\n",
    "count = spark.sql(\"SELECT COUNT(*) AS cnt FROM demo.lab.tt_orders\").collect()[0][\"cnt\"]\n",
    "print(f\"Snapshot 1 (INSERT): {count}ê±´\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1000009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snapshot 2: 20ê±´ UPDATE\n",
    "spark.sql(\"\"\"\n",
    "    UPDATE demo.lab.tt_orders\n",
    "    SET status = 'cancelled', amount = 0.0\n",
    "    WHERE order_id <= 20\n",
    "\"\"\")\n",
    "\n",
    "count = spark.sql(\"SELECT COUNT(*) AS cnt FROM demo.lab.tt_orders\").collect()[0][\"cnt\"]\n",
    "cancelled = spark.sql(\"SELECT COUNT(*) AS cnt FROM demo.lab.tt_orders WHERE status = 'cancelled'\").collect()[0][\"cnt\"]\n",
    "print(f\"Snapshot 2 (UPDATE): ì´ {count}ê±´, cancelled={cancelled}ê±´\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d100000a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snapshot 3: 10ê±´ DELETE\n",
    "spark.sql(\"\"\"\n",
    "    DELETE FROM demo.lab.tt_orders\n",
    "    WHERE order_id BETWEEN 21 AND 30\n",
    "\"\"\")\n",
    "\n",
    "count = spark.sql(\"SELECT COUNT(*) AS cnt FROM demo.lab.tt_orders\").collect()[0][\"cnt\"]\n",
    "print(f\"Snapshot 3 (DELETE): {count}ê±´\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d100000b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snapshot 4: 50ê±´ INSERT\n",
    "orders2 = generate_orders(num_records=50, id_offset=101, seed=99)\n",
    "df2 = to_spark_df(spark, orders2)\n",
    "df2.writeTo(\"demo.lab.tt_orders\").append()\n",
    "\n",
    "count = spark.sql(\"SELECT COUNT(*) AS cnt FROM demo.lab.tt_orders\").collect()[0][\"cnt\"]\n",
    "print(f\"Snapshot 4 (INSERT): {count}ê±´\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d100000c",
   "metadata": {},
   "source": [
    "## ìŠ¤ëƒ…ìƒ· ëª©ë¡ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d100000d",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshots_df = spark.sql(\"SELECT * FROM demo.lab.tt_orders.snapshots\")\n",
    "snapshots_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d100000e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìŠ¤ëƒ…ìƒ· ID ëª©ë¡ ì €ì¥\n",
    "snapshot_rows = snapshots_df.collect()\n",
    "snapshot_ids = [row[\"snapshot_id\"] for row in snapshot_rows]\n",
    "\n",
    "print(\"ìŠ¤ëƒ…ìƒ· ID ëª©ë¡:\")\n",
    "for i, sid in enumerate(snapshot_ids):\n",
    "    print(f\"  Snapshot {i+1}: {sid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d100000f",
   "metadata": {},
   "source": [
    "## VERSION AS OFë¡œ ê³¼ê±° ì‹œì  ë°ì´í„° ì¡°íšŒ\n",
    "\n",
    "ê° ìŠ¤ëƒ…ìƒ· ì‹œì ì˜ ë°ì´í„° ìˆ˜ë¥¼ ë¹„êµí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1000010",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[ ìŠ¤ëƒ…ìƒ·ë³„ ë ˆì½”ë“œ ìˆ˜ ë¹„êµ ]\\n\")\n",
    "\n",
    "for i, sid in enumerate(snapshot_ids):\n",
    "    count = spark.sql(f\"\"\"\n",
    "        SELECT COUNT(*) AS cnt\n",
    "        FROM demo.lab.tt_orders\n",
    "        VERSION AS OF {sid}\n",
    "    \"\"\").collect()[0][\"cnt\"]\n",
    "    \n",
    "    operations = [\"INSERT 100ê±´\", \"UPDATE 20ê±´\", \"DELETE 10ê±´\", \"INSERT 50ê±´\"]\n",
    "    op = operations[i] if i < len(operations) else \"?\"\n",
    "    print(f\"  Snapshot {i+1} ({op}): {count}ê±´\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1000011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snapshot 1ì˜ ë°ì´í„° ìƒ˜í”Œ ì¡°íšŒ\n",
    "print(f\"[ Snapshot 1 ë°ì´í„° ìƒ˜í”Œ (ID: {snapshot_ids[0]}) ]\\n\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "    SELECT order_id, product_name, amount, status\n",
    "    FROM demo.lab.tt_orders\n",
    "    VERSION AS OF {snapshot_ids[0]}\n",
    "    ORDER BY order_id\n",
    "    LIMIT 10\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1000012",
   "metadata": {},
   "source": [
    "## TIMESTAMP AS OFë¡œ ì‹œê°„ ê¸°ë°˜ ì¡°íšŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1000013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê° ìŠ¤ëƒ…ìƒ·ì˜ íƒ€ì„ìŠ¤íƒ¬í”„ í™•ì¸\n",
    "history_df = spark.sql(\"\"\"\n",
    "    SELECT snapshot_id, committed_at\n",
    "    FROM demo.lab.tt_orders.snapshots\n",
    "    ORDER BY committed_at\n",
    "\"\"\")\n",
    "history_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1000014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì²« ë²ˆì§¸ ìŠ¤ëƒ…ìƒ·ì˜ íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ Time Travel\n",
    "first_ts = snapshot_rows[0][\"committed_at\"]\n",
    "ts_str = str(first_ts)\n",
    "\n",
    "print(f\"Timestamp: {ts_str}\\n\")\n",
    "\n",
    "count = spark.sql(f\"\"\"\n",
    "    SELECT COUNT(*) AS cnt\n",
    "    FROM demo.lab.tt_orders\n",
    "    TIMESTAMP AS OF '{ts_str}'\n",
    "\"\"\").collect()[0][\"cnt\"]\n",
    "\n",
    "print(f\"TIMESTAMP AS OF '{ts_str}' â†’ {count}ê±´\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1000015",
   "metadata": {},
   "source": [
    "## ì‹¤ìˆ˜ ë³µêµ¬ ì‹œë‚˜ë¦¬ì˜¤\n",
    "\n",
    "ì‹¤ìˆ˜ë¡œ í…Œì´ë¸”ì˜ **ì „ì²´ ë°ì´í„°ë¥¼ ì‚­ì œ**í•œ ë’¤, `rollback_to_snapshot`ìœ¼ë¡œ ë³µêµ¬í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ì‹œë‚˜ë¦¬ì˜¤\n",
    "1. í˜„ì¬ ìƒíƒœ í™•ì¸\n",
    "2. ì‹¤ìˆ˜ë¡œ `DELETE FROM ... WHERE 1=1` ì‹¤í–‰ (ì „ì²´ ì‚­ì œ!)\n",
    "3. ë°ì´í„°ê°€ 0ê±´ì¸ ê²ƒì„ í™•ì¸\n",
    "4. ìŠ¤ëƒ…ìƒ· ê¸°ë°˜ ë¡¤ë°±ìœ¼ë¡œ ë³µêµ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1000016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. í˜„ì¬ ìƒíƒœ\n",
    "before_count = spark.sql(\"SELECT COUNT(*) AS cnt FROM demo.lab.tt_orders\").collect()[0][\"cnt\"]\n",
    "print(f\"ì‚­ì œ ì „ ë ˆì½”ë“œ ìˆ˜: {before_count}ê±´\")\n",
    "\n",
    "# ë³µêµ¬í•  ìŠ¤ëƒ…ìƒ· ID ë¯¸ë¦¬ ì €ì¥ (í˜„ì¬ ìŠ¤ëƒ…ìƒ· = Snapshot 4)\n",
    "recovery_snapshot_id = snapshot_ids[-1]\n",
    "print(f\"ë³µêµ¬ ëŒ€ìƒ ìŠ¤ëƒ…ìƒ· ID: {recovery_snapshot_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1000017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. ì‹¤ìˆ˜ë¡œ ì „ì²´ ì‚­ì œ! ğŸ˜±\n",
    "spark.sql(\"DELETE FROM demo.lab.tt_orders WHERE 1=1\")\n",
    "\n",
    "after_count = spark.sql(\"SELECT COUNT(*) AS cnt FROM demo.lab.tt_orders\").collect()[0][\"cnt\"]\n",
    "print(f\"ì‚­ì œ í›„ ë ˆì½”ë“œ ìˆ˜: {after_count}ê±´ â€” ë°ì´í„°ê°€ ëª¨ë‘ ì‚¬ë¼ì¡ŒìŠµë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1000018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. rollback_to_snapshotìœ¼ë¡œ ë³µêµ¬\n",
    "print(f\"Snapshot {recovery_snapshot_id}ë¡œ ë¡¤ë°±í•©ë‹ˆë‹¤...\\n\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "    CALL demo.system.rollback_to_snapshot('demo.lab.tt_orders', {recovery_snapshot_id})\n",
    "\"\"\")\n",
    "\n",
    "recovered_count = spark.sql(\"SELECT COUNT(*) AS cnt FROM demo.lab.tt_orders\").collect()[0][\"cnt\"]\n",
    "print(f\"ë³µêµ¬ í›„ ë ˆì½”ë“œ ìˆ˜: {recovered_count}ê±´\")\n",
    "print(f\"\\në³µêµ¬ ì„±ê³µ! ({after_count}ê±´ â†’ {recovered_count}ê±´)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1000019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë³µêµ¬ í›„ ìŠ¤ëƒ…ìƒ· ëª©ë¡ í™•ì¸\n",
    "print(\"[ ë³µêµ¬ í›„ ìŠ¤ëƒ…ìƒ· ëª©ë¡ ]\\n\")\n",
    "spark.sql(\"SELECT * FROM demo.lab.tt_orders.snapshots\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d100001a",
   "metadata": {},
   "source": [
    "## ê´€ì°° í¬ì¸íŠ¸\n",
    "\n",
    "### Time Travel í•µì‹¬ ì •ë¦¬\n",
    "\n",
    "1. **ìŠ¤ëƒ…ìƒ· ê¸°ë°˜ ë²„ì „ ê´€ë¦¬**: ëª¨ë“  ì‘ì—…ì€ ìƒˆë¡œìš´ ìŠ¤ëƒ…ìƒ·ì„ ìƒì„±í•˜ë©°, ì´ì „ ìŠ¤ëƒ…ìƒ·ì€ ê·¸ëŒ€ë¡œ ìœ ì§€ë©ë‹ˆë‹¤\n",
    "\n",
    "2. **ë°ì´í„° ì¡°íšŒ ë°©ë²•**:\n",
    "   - `VERSION AS OF {snapshot_id}`: íŠ¹ì • ìŠ¤ëƒ…ìƒ·ì˜ ë°ì´í„°\n",
    "   - `TIMESTAMP AS OF '{timestamp}'`: íŠ¹ì • ì‹œì ì˜ ë°ì´í„°\n",
    "\n",
    "3. **ì‹¤ìˆ˜ ë³µêµ¬**: `rollback_to_snapshot`ìœ¼ë¡œ ì „ì²´ ì‚­ì œë„ ë³µêµ¬ ê°€ëŠ¥\n",
    "   - ë¡¤ë°± ìì²´ë„ ìƒˆë¡œìš´ ìŠ¤ëƒ…ìƒ·ì„ ìƒì„±í•©ë‹ˆë‹¤\n",
    "   - ê¸°ì¡´ ìŠ¤ëƒ…ìƒ·ì€ ì‚­ì œë˜ì§€ ì•ŠìŠµë‹ˆë‹¤\n",
    "\n",
    "### âš ï¸ ì£¼ì˜ì‚¬í•­\n",
    "\n",
    "- **ìŠ¤ëƒ…ìƒ·ì´ ìˆëŠ” í•œ** ë°ì´í„°ë¥¼ ë³µêµ¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
    "- ê·¸ëŸ¬ë‚˜ `expire_snapshots`ë¥¼ ì‹¤í–‰í•˜ë©´ ì˜¤ë˜ëœ ìŠ¤ëƒ…ìƒ·ì´ ì‚­ì œë˜ê³ , í•´ë‹¹ ìŠ¤ëƒ…ìƒ·ìœ¼ë¡œì˜ Time Travelì€ **ë¶ˆê°€ëŠ¥**í•´ì§‘ë‹ˆë‹¤\n",
    "- ìŠ¤ëƒ…ìƒ· ë§Œë£ŒëŠ” ìŠ¤í† ë¦¬ì§€ ì ˆì•½ì„ ìœ„í•´ ì£¼ê¸°ì ìœ¼ë¡œ ì‹¤í–‰í•˜ë˜, ë³µêµ¬ ê°€ëŠ¥ ê¸°ê°„ì„ ê³ ë ¤í•˜ì—¬ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤\n",
    "- ì´ ë¶€ë¶„ì€ `4_optimization`ì—ì„œ ë” ìì„¸íˆ ë‹¤ë£¹ë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d100001b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()\n",
    "print(\"Spark ì„¸ì…˜ ì¢…ë£Œ\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}