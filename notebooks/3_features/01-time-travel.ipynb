{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1000001",
   "metadata": {},
   "source": [
    "# 01. Time Travel\n",
    "\n",
    "Icebergì˜ **Time Travel** ê¸°ëŠ¥ì„ í™œìš©í•˜ì—¬ ê³¼ê±° ì‹œì ì˜ ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ê³ , ì‹¤ìˆ˜ë¡œ ì‚­ì œëœ ë°ì´í„°ë¥¼ ë³µêµ¬í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1000002",
   "metadata": {},
   "source": [
    "## Time Travel ê°œë…\n",
    "\n",
    "IcebergëŠ” ëª¨ë“  ë°ì´í„° ë³€ê²½ì„ **ìŠ¤ëƒ…ìƒ·(Snapshot)**ìœ¼ë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤.\n",
    "\n",
    "```\n",
    "Snapshot 1 (INSERT 100ê±´)\n",
    "    â”‚\n",
    "    â–¼\n",
    "Snapshot 2 (UPDATE 20ê±´)\n",
    "    â”‚\n",
    "    â–¼\n",
    "Snapshot 3 (DELETE 10ê±´)\n",
    "    â”‚\n",
    "    â–¼\n",
    "Snapshot 4 (INSERT 50ê±´)  â—€ current\n",
    "```\n",
    "\n",
    "- ê° ìŠ¤ëƒ…ìƒ·ì€ **ë¶ˆë³€(immutable)**í•˜ë©°, ì´ì „ ìŠ¤ëƒ…ìƒ·ì˜ ë°ì´í„° íŒŒì¼ì€ ê·¸ëŒ€ë¡œ ìœ ì§€ë©ë‹ˆë‹¤\n",
    "- `VERSION AS OF` ë˜ëŠ” `TIMESTAMP AS OF`ë¡œ ê³¼ê±° ì‹œì ì˜ ë°ì´í„°ë¥¼ ì¡°íšŒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
    "- `rollback_to_snapshot`ìœ¼ë¡œ íŠ¹ì • ìŠ¤ëƒ…ìƒ· ìƒíƒœë¡œ í…Œì´ë¸”ì„ ë˜ëŒë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
    "\n",
    "### Time Travelì˜ í™œìš© ì‚¬ë¡€\n",
    "\n",
    "| ì‹œë‚˜ë¦¬ì˜¤ | ë°©ë²• |\n",
    "|----------|------|\n",
    "| ê³¼ê±° ì‹œì  ë°ì´í„° ë¶„ì„ | `SELECT * FROM table VERSION AS OF {snapshot_id}` |\n",
    "| ì‹œê°„ ê¸°ë°˜ ë°ì´í„° ì¡°íšŒ | `SELECT * FROM table TIMESTAMP AS OF '{timestamp}'` |\n",
    "| ì‹¤ìˆ˜ ë³µêµ¬ (ì˜ëª»ëœ DELETE/UPDATE) | `CALL system.rollback_to_snapshot(...)` |\n",
    "| ë°ì´í„° ë³€ê²½ ì¶”ì  (audit) | ìŠ¤ëƒ…ìƒ·ë³„ ë°ì´í„° ë¹„êµ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1000003",
   "metadata": {},
   "source": [
    "## í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1000004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.spark_setup import create_spark_session\n",
    "from utils.data_generator import generate_orders, to_spark_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1000005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark + Iceberg ì„¸ì…˜ ì¤€ë¹„ ì™„ë£Œ (warehouse: file:///home/jovyan/data/warehouse)\n"
     ]
    }
   ],
   "source": [
    "spark = create_spark_session(\"TimeTravel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1000006",
   "metadata": {},
   "source": [
    "## í…Œì´ë¸” ìƒì„± ë° 4ê°œ ìŠ¤ëƒ…ìƒ· ë§Œë“¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1000007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í…Œì´ë¸” ìƒì„± ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS demo.lab\")\n",
    "spark.sql(\"DROP TABLE IF EXISTS demo.lab.tt_orders\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    CREATE TABLE demo.lab.tt_orders (\n",
    "        order_id     BIGINT,\n",
    "        customer_id  BIGINT,\n",
    "        product_name STRING,\n",
    "        order_date   DATE,\n",
    "        amount       DOUBLE,\n",
    "        status       STRING\n",
    "    )\n",
    "    USING iceberg\n",
    "    PARTITIONED BY (months(order_date))\n",
    "\"\"\")\n",
    "\n",
    "print(\"í…Œì´ë¸” ìƒì„± ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1000008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snapshot 1 (INSERT): 100ê±´\n"
     ]
    }
   ],
   "source": [
    "# Snapshot 1: 100ê±´ INSERT\n",
    "orders1 = generate_orders(num_records=100, seed=42)\n",
    "df1 = to_spark_df(spark, orders1)\n",
    "df1.writeTo(\"demo.lab.tt_orders\").append()\n",
    "\n",
    "count = spark.sql(\"SELECT COUNT(*) AS cnt FROM demo.lab.tt_orders\").collect()[0][\"cnt\"]\n",
    "print(f\"Snapshot 1 (INSERT): {count}ê±´\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1000009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snapshot 2 (UPDATE): ì´ 100ê±´, cancelled=35ê±´\n"
     ]
    }
   ],
   "source": [
    "# Snapshot 2: 20ê±´ UPDATE\n",
    "spark.sql(\"\"\"\n",
    "    UPDATE demo.lab.tt_orders\n",
    "    SET status = 'cancelled', amount = 0.0\n",
    "    WHERE order_id <= 20\n",
    "\"\"\")\n",
    "\n",
    "count = spark.sql(\"SELECT COUNT(*) AS cnt FROM demo.lab.tt_orders\").collect()[0][\"cnt\"]\n",
    "cancelled = spark.sql(\"SELECT COUNT(*) AS cnt FROM demo.lab.tt_orders WHERE status = 'cancelled'\").collect()[0][\"cnt\"]\n",
    "print(f\"Snapshot 2 (UPDATE): ì´ {count}ê±´, cancelled={cancelled}ê±´\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d100000a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snapshot 3 (DELETE): 90ê±´\n"
     ]
    }
   ],
   "source": [
    "# Snapshot 3: 10ê±´ DELETE\n",
    "spark.sql(\"\"\"\n",
    "    DELETE FROM demo.lab.tt_orders\n",
    "    WHERE order_id BETWEEN 21 AND 30\n",
    "\"\"\")\n",
    "\n",
    "count = spark.sql(\"SELECT COUNT(*) AS cnt FROM demo.lab.tt_orders\").collect()[0][\"cnt\"]\n",
    "print(f\"Snapshot 3 (DELETE): {count}ê±´\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d100000b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snapshot 4 (INSERT): 140ê±´\n"
     ]
    }
   ],
   "source": [
    "# Snapshot 4: 50ê±´ INSERT\n",
    "orders2 = generate_orders(num_records=50, id_offset=101, seed=99)\n",
    "df2 = to_spark_df(spark, orders2)\n",
    "df2.writeTo(\"demo.lab.tt_orders\").append()\n",
    "\n",
    "count = spark.sql(\"SELECT COUNT(*) AS cnt FROM demo.lab.tt_orders\").collect()[0][\"cnt\"]\n",
    "print(f\"Snapshot 4 (INSERT): {count}ê±´\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d100000c",
   "metadata": {},
   "source": [
    "## ìŠ¤ëƒ…ìƒ· ëª©ë¡ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d100000d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-------------------+-------------------+---------+----------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|committed_at           |snapshot_id        |parent_id          |operation|manifest_list                                                                                                               |summary                                                                                                                                                                                                                                                                                                                                                                          |\n",
      "+-----------------------+-------------------+-------------------+---------+----------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|2026-02-15 22:28:53.987|3603858730999915904|null               |append   |file:/home/jovyan/data/warehouse/lab/tt_orders/metadata/snap-3603858730999915904-1-acf40b33-3536-431e-b6f8-e05943d85bc7.avro|{spark.app.id -> local-1771194524580, added-data-files -> 3, added-records -> 100, added-files-size -> 7702, changed-partition-count -> 3, total-records -> 100, total-files-size -> 7702, total-data-files -> 3, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}                                                                             |\n",
      "|2026-02-15 22:28:55.256|9179334725420240180|3603858730999915904|overwrite|file:/home/jovyan/data/warehouse/lab/tt_orders/metadata/snap-9179334725420240180-1-1b56dea4-e47f-4c38-86d6-7f2e32c2754b.avro|{spark.app.id -> local-1771194524580, added-data-files -> 3, deleted-data-files -> 3, added-records -> 100, deleted-records -> 100, added-files-size -> 7794, removed-files-size -> 7702, changed-partition-count -> 3, total-records -> 100, total-files-size -> 7794, total-data-files -> 3, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}|\n",
      "|2026-02-15 22:28:56.387|7203291035592772825|9179334725420240180|overwrite|file:/home/jovyan/data/warehouse/lab/tt_orders/metadata/snap-7203291035592772825-1-5dceeefe-ad74-47d4-abec-06df0aac1c72.avro|{spark.app.id -> local-1771194524580, added-data-files -> 3, deleted-data-files -> 3, added-records -> 90, deleted-records -> 100, added-files-size -> 7640, removed-files-size -> 7794, changed-partition-count -> 3, total-records -> 90, total-files-size -> 7640, total-data-files -> 3, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}  |\n",
      "|2026-02-15 22:28:57.172|1412225785113933797|7203291035592772825|append   |file:/home/jovyan/data/warehouse/lab/tt_orders/metadata/snap-1412225785113933797-1-c12c2569-ec56-4507-b50c-8ab82f76192f.avro|{spark.app.id -> local-1771194524580, added-data-files -> 3, added-records -> 50, added-files-size -> 6900, changed-partition-count -> 3, total-records -> 140, total-files-size -> 14540, total-data-files -> 6, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}                                                                             |\n",
      "+-----------------------+-------------------+-------------------+---------+----------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "snapshots_df = spark.sql(\"SELECT * FROM demo.lab.tt_orders.snapshots\")\n",
    "snapshots_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d100000e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ¤ëƒ…ìƒ· ID ëª©ë¡:\n",
      "  Snapshot 1: 3603858730999915904\n",
      "  Snapshot 2: 9179334725420240180\n",
      "  Snapshot 3: 7203291035592772825\n",
      "  Snapshot 4: 1412225785113933797\n"
     ]
    }
   ],
   "source": [
    "# ìŠ¤ëƒ…ìƒ· ID ëª©ë¡ ì €ì¥\n",
    "snapshot_rows = snapshots_df.collect()\n",
    "snapshot_ids = [row[\"snapshot_id\"] for row in snapshot_rows]\n",
    "\n",
    "print(\"ìŠ¤ëƒ…ìƒ· ID ëª©ë¡:\")\n",
    "for i, sid in enumerate(snapshot_ids):\n",
    "    print(f\"  Snapshot {i+1}: {sid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d100000f",
   "metadata": {},
   "source": [
    "## VERSION AS OFë¡œ ê³¼ê±° ì‹œì  ë°ì´í„° ì¡°íšŒ\n",
    "\n",
    "ê° ìŠ¤ëƒ…ìƒ· ì‹œì ì˜ ë°ì´í„° ìˆ˜ë¥¼ ë¹„êµí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1000010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ ìŠ¤ëƒ…ìƒ·ë³„ ë ˆì½”ë“œ ìˆ˜ ë¹„êµ ]\n",
      "\n",
      "  Snapshot 1 (INSERT 100ê±´): 100ê±´\n",
      "  Snapshot 2 (UPDATE 20ê±´): 100ê±´\n",
      "  Snapshot 3 (DELETE 10ê±´): 90ê±´\n",
      "  Snapshot 4 (INSERT 50ê±´): 140ê±´\n"
     ]
    }
   ],
   "source": [
    "print(\"[ ìŠ¤ëƒ…ìƒ·ë³„ ë ˆì½”ë“œ ìˆ˜ ë¹„êµ ]\\n\")\n",
    "\n",
    "for i, sid in enumerate(snapshot_ids):\n",
    "    count = spark.sql(f\"\"\"\n",
    "        SELECT COUNT(*) AS cnt\n",
    "        FROM demo.lab.tt_orders\n",
    "        VERSION AS OF {sid}\n",
    "    \"\"\").collect()[0][\"cnt\"]\n",
    "    \n",
    "    operations = [\"INSERT 100ê±´\", \"UPDATE 20ê±´\", \"DELETE 10ê±´\", \"INSERT 50ê±´\"]\n",
    "    op = operations[i] if i < len(operations) else \"?\"\n",
    "    print(f\"  Snapshot {i+1} ({op}): {count}ê±´\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1000011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Snapshot 1 ë°ì´í„° ìƒ˜í”Œ (ID: 3603858730999915904) ]\n",
      "\n",
      "+--------+-------------+-------+----------+\n",
      "|order_id|product_name |amount |status    |\n",
      "+--------+-------------+-------+----------+\n",
      "|1       |MacBook Air  |1053.0 |pending   |\n",
      "|2       |iPad Air     |711.47 |processing|\n",
      "|3       |MacBook Pro  |2072.38|completed |\n",
      "|4       |AirPods      |178.6  |processing|\n",
      "|5       |AirPods      |217.27 |cancelled |\n",
      "|6       |AirPods Pro  |293.9  |completed |\n",
      "|7       |iPad Pro     |971.32 |pending   |\n",
      "|8       |AirPods      |236.57 |completed |\n",
      "|9       |Mac Studio   |1845.1 |shipped   |\n",
      "|10      |iPhone 14 Pro|1310.26|cancelled |\n",
      "+--------+-------------+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Snapshot 1ì˜ ë°ì´í„° ìƒ˜í”Œ ì¡°íšŒ\n",
    "print(f\"[ Snapshot 1 ë°ì´í„° ìƒ˜í”Œ (ID: {snapshot_ids[0]}) ]\\n\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "    SELECT order_id, product_name, amount, status\n",
    "    FROM demo.lab.tt_orders\n",
    "    VERSION AS OF {snapshot_ids[0]}\n",
    "    ORDER BY order_id\n",
    "    LIMIT 10\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1000012",
   "metadata": {},
   "source": [
    "## TIMESTAMP AS OFë¡œ ì‹œê°„ ê¸°ë°˜ ì¡°íšŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1000013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------------------+\n",
      "|snapshot_id        |committed_at           |\n",
      "+-------------------+-----------------------+\n",
      "|3603858730999915904|2026-02-15 22:28:53.987|\n",
      "|9179334725420240180|2026-02-15 22:28:55.256|\n",
      "|7203291035592772825|2026-02-15 22:28:56.387|\n",
      "|1412225785113933797|2026-02-15 22:28:57.172|\n",
      "+-------------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ê° ìŠ¤ëƒ…ìƒ·ì˜ íƒ€ì„ìŠ¤íƒ¬í”„ í™•ì¸\n",
    "history_df = spark.sql(\"\"\"\n",
    "    SELECT snapshot_id, committed_at\n",
    "    FROM demo.lab.tt_orders.snapshots\n",
    "    ORDER BY committed_at\n",
    "\"\"\")\n",
    "history_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1000014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 2026-02-15 22:28:53.987000\n",
      "\n",
      "TIMESTAMP AS OF '2026-02-15 22:28:53.987000' â†’ 100ê±´\n"
     ]
    }
   ],
   "source": [
    "# ì²« ë²ˆì§¸ ìŠ¤ëƒ…ìƒ·ì˜ íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ Time Travel\n",
    "first_ts = snapshot_rows[0][\"committed_at\"]\n",
    "ts_str = str(first_ts)\n",
    "\n",
    "print(f\"Timestamp: {ts_str}\\n\")\n",
    "\n",
    "count = spark.sql(f\"\"\"\n",
    "    SELECT COUNT(*) AS cnt\n",
    "    FROM demo.lab.tt_orders\n",
    "    TIMESTAMP AS OF '{ts_str}'\n",
    "\"\"\").collect()[0][\"cnt\"]\n",
    "\n",
    "print(f\"TIMESTAMP AS OF '{ts_str}' â†’ {count}ê±´\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1000015",
   "metadata": {},
   "source": [
    "## ì‹¤ìˆ˜ ë³µêµ¬ ì‹œë‚˜ë¦¬ì˜¤\n",
    "\n",
    "ì‹¤ìˆ˜ë¡œ í…Œì´ë¸”ì˜ **ì „ì²´ ë°ì´í„°ë¥¼ ì‚­ì œ**í•œ ë’¤, `rollback_to_snapshot`ìœ¼ë¡œ ë³µêµ¬í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ì‹œë‚˜ë¦¬ì˜¤\n",
    "1. í˜„ì¬ ìƒíƒœ í™•ì¸\n",
    "2. ì‹¤ìˆ˜ë¡œ `DELETE FROM ... WHERE 1=1` ì‹¤í–‰ (ì „ì²´ ì‚­ì œ!)\n",
    "3. ë°ì´í„°ê°€ 0ê±´ì¸ ê²ƒì„ í™•ì¸\n",
    "4. ìŠ¤ëƒ…ìƒ· ê¸°ë°˜ ë¡¤ë°±ìœ¼ë¡œ ë³µêµ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1000016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‚­ì œ ì „ ë ˆì½”ë“œ ìˆ˜: 140ê±´\n",
      "ë³µêµ¬ ëŒ€ìƒ ìŠ¤ëƒ…ìƒ· ID: 1412225785113933797\n"
     ]
    }
   ],
   "source": [
    "# 1. í˜„ì¬ ìƒíƒœ\n",
    "before_count = spark.sql(\"SELECT COUNT(*) AS cnt FROM demo.lab.tt_orders\").collect()[0][\"cnt\"]\n",
    "print(f\"ì‚­ì œ ì „ ë ˆì½”ë“œ ìˆ˜: {before_count}ê±´\")\n",
    "\n",
    "# ë³µêµ¬í•  ìŠ¤ëƒ…ìƒ· ID ë¯¸ë¦¬ ì €ì¥ (í˜„ì¬ ìŠ¤ëƒ…ìƒ· = Snapshot 4)\n",
    "recovery_snapshot_id = snapshot_ids[-1]\n",
    "print(f\"ë³µêµ¬ ëŒ€ìƒ ìŠ¤ëƒ…ìƒ· ID: {recovery_snapshot_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1000017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‚­ì œ í›„ ë ˆì½”ë“œ ìˆ˜: 0ê±´ â€” ë°ì´í„°ê°€ ëª¨ë‘ ì‚¬ë¼ì¡ŒìŠµë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "# 2. ì‹¤ìˆ˜ë¡œ ì „ì²´ ì‚­ì œ! ğŸ˜±\n",
    "spark.sql(\"DELETE FROM demo.lab.tt_orders WHERE 1=1\")\n",
    "\n",
    "after_count = spark.sql(\"SELECT COUNT(*) AS cnt FROM demo.lab.tt_orders\").collect()[0][\"cnt\"]\n",
    "print(f\"ì‚­ì œ í›„ ë ˆì½”ë“œ ìˆ˜: {after_count}ê±´ â€” ë°ì´í„°ê°€ ëª¨ë‘ ì‚¬ë¼ì¡ŒìŠµë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1000018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snapshot 1412225785113933797ë¡œ ë¡¤ë°±í•©ë‹ˆë‹¤...\n",
      "\n",
      "ë³µêµ¬ í›„ ë ˆì½”ë“œ ìˆ˜: 140ê±´\n",
      "\n",
      "ë³µêµ¬ ì„±ê³µ! (0ê±´ â†’ 140ê±´)\n"
     ]
    }
   ],
   "source": [
    "# 3. rollback_to_snapshotìœ¼ë¡œ ë³µêµ¬\n",
    "print(f\"Snapshot {recovery_snapshot_id}ë¡œ ë¡¤ë°±í•©ë‹ˆë‹¤...\\n\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "    CALL demo.system.rollback_to_snapshot('demo.lab.tt_orders', {recovery_snapshot_id})\n",
    "\"\"\")\n",
    "\n",
    "recovered_count = spark.sql(\"SELECT COUNT(*) AS cnt FROM demo.lab.tt_orders\").collect()[0][\"cnt\"]\n",
    "print(f\"ë³µêµ¬ í›„ ë ˆì½”ë“œ ìˆ˜: {recovered_count}ê±´\")\n",
    "print(f\"\\në³µêµ¬ ì„±ê³µ! ({after_count}ê±´ â†’ {recovered_count}ê±´)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1000019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ ë³µêµ¬ í›„ ìŠ¤ëƒ…ìƒ· ëª©ë¡ ]\n",
      "\n",
      "+-----------------------+-------------------+-------------------+---------+----------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|committed_at           |snapshot_id        |parent_id          |operation|manifest_list                                                                                                               |summary                                                                                                                                                                                                                                                                                                                                                                          |\n",
      "+-----------------------+-------------------+-------------------+---------+----------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|2026-02-15 22:28:53.987|3603858730999915904|null               |append   |file:/home/jovyan/data/warehouse/lab/tt_orders/metadata/snap-3603858730999915904-1-acf40b33-3536-431e-b6f8-e05943d85bc7.avro|{spark.app.id -> local-1771194524580, added-data-files -> 3, added-records -> 100, added-files-size -> 7702, changed-partition-count -> 3, total-records -> 100, total-files-size -> 7702, total-data-files -> 3, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}                                                                             |\n",
      "|2026-02-15 22:28:55.256|9179334725420240180|3603858730999915904|overwrite|file:/home/jovyan/data/warehouse/lab/tt_orders/metadata/snap-9179334725420240180-1-1b56dea4-e47f-4c38-86d6-7f2e32c2754b.avro|{spark.app.id -> local-1771194524580, added-data-files -> 3, deleted-data-files -> 3, added-records -> 100, deleted-records -> 100, added-files-size -> 7794, removed-files-size -> 7702, changed-partition-count -> 3, total-records -> 100, total-files-size -> 7794, total-data-files -> 3, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}|\n",
      "|2026-02-15 22:28:56.387|7203291035592772825|9179334725420240180|overwrite|file:/home/jovyan/data/warehouse/lab/tt_orders/metadata/snap-7203291035592772825-1-5dceeefe-ad74-47d4-abec-06df0aac1c72.avro|{spark.app.id -> local-1771194524580, added-data-files -> 3, deleted-data-files -> 3, added-records -> 90, deleted-records -> 100, added-files-size -> 7640, removed-files-size -> 7794, changed-partition-count -> 3, total-records -> 90, total-files-size -> 7640, total-data-files -> 3, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}  |\n",
      "|2026-02-15 22:28:57.172|1412225785113933797|7203291035592772825|append   |file:/home/jovyan/data/warehouse/lab/tt_orders/metadata/snap-1412225785113933797-1-c12c2569-ec56-4507-b50c-8ab82f76192f.avro|{spark.app.id -> local-1771194524580, added-data-files -> 3, added-records -> 50, added-files-size -> 6900, changed-partition-count -> 3, total-records -> 140, total-files-size -> 14540, total-data-files -> 6, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}                                                                             |\n",
      "|2026-02-15 22:29:00.038|5934557244617828895|1412225785113933797|delete   |file:/home/jovyan/data/warehouse/lab/tt_orders/metadata/snap-5934557244617828895-1-9557bbba-bcbe-4413-a1cf-f6b9d2b88182.avro|{spark.app.id -> local-1771194524580, deleted-data-files -> 6, deleted-records -> 140, removed-files-size -> 14540, changed-partition-count -> 3, total-records -> 0, total-files-size -> 0, total-data-files -> 0, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}                                                                           |\n",
      "+-----------------------+-------------------+-------------------+---------+----------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ë³µêµ¬ í›„ ìŠ¤ëƒ…ìƒ· ëª©ë¡ í™•ì¸\n",
    "print(\"[ ë³µêµ¬ í›„ ìŠ¤ëƒ…ìƒ· ëª©ë¡ ]\\n\")\n",
    "spark.sql(\"SELECT * FROM demo.lab.tt_orders.snapshots\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d100001a",
   "metadata": {},
   "source": [
    "## ê´€ì°° í¬ì¸íŠ¸\n",
    "\n",
    "### Time Travel í•µì‹¬ ì •ë¦¬\n",
    "\n",
    "1. **ìŠ¤ëƒ…ìƒ· ê¸°ë°˜ ë²„ì „ ê´€ë¦¬**: ëª¨ë“  ì‘ì—…ì€ ìƒˆë¡œìš´ ìŠ¤ëƒ…ìƒ·ì„ ìƒì„±í•˜ë©°, ì´ì „ ìŠ¤ëƒ…ìƒ·ì€ ê·¸ëŒ€ë¡œ ìœ ì§€ë©ë‹ˆë‹¤\n",
    "\n",
    "2. **ë°ì´í„° ì¡°íšŒ ë°©ë²•**:\n",
    "   - `VERSION AS OF {snapshot_id}`: íŠ¹ì • ìŠ¤ëƒ…ìƒ·ì˜ ë°ì´í„°\n",
    "   - `TIMESTAMP AS OF '{timestamp}'`: íŠ¹ì • ì‹œì ì˜ ë°ì´í„°\n",
    "\n",
    "3. **ì‹¤ìˆ˜ ë³µêµ¬**: `rollback_to_snapshot`ìœ¼ë¡œ ì „ì²´ ì‚­ì œë„ ë³µêµ¬ ê°€ëŠ¥\n",
    "   - ë¡¤ë°± ìì²´ë„ ìƒˆë¡œìš´ ìŠ¤ëƒ…ìƒ·ì„ ìƒì„±í•©ë‹ˆë‹¤\n",
    "   - ê¸°ì¡´ ìŠ¤ëƒ…ìƒ·ì€ ì‚­ì œë˜ì§€ ì•ŠìŠµë‹ˆë‹¤\n",
    "\n",
    "### âš ï¸ ì£¼ì˜ì‚¬í•­\n",
    "\n",
    "- **ìŠ¤ëƒ…ìƒ·ì´ ìˆëŠ” í•œ** ë°ì´í„°ë¥¼ ë³µêµ¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
    "- ê·¸ëŸ¬ë‚˜ `expire_snapshots`ë¥¼ ì‹¤í–‰í•˜ë©´ ì˜¤ë˜ëœ ìŠ¤ëƒ…ìƒ·ì´ ì‚­ì œë˜ê³ , í•´ë‹¹ ìŠ¤ëƒ…ìƒ·ìœ¼ë¡œì˜ Time Travelì€ **ë¶ˆê°€ëŠ¥**í•´ì§‘ë‹ˆë‹¤\n",
    "- ìŠ¤ëƒ…ìƒ· ë§Œë£ŒëŠ” ìŠ¤í† ë¦¬ì§€ ì ˆì•½ì„ ìœ„í•´ ì£¼ê¸°ì ìœ¼ë¡œ ì‹¤í–‰í•˜ë˜, ë³µêµ¬ ê°€ëŠ¥ ê¸°ê°„ì„ ê³ ë ¤í•˜ì—¬ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤\n",
    "- ì´ ë¶€ë¶„ì€ `4_optimization`ì—ì„œ ë” ìì„¸íˆ ë‹¤ë£¹ë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d100001b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark ì„¸ì…˜ ì¢…ë£Œ\n"
     ]
    }
   ],
   "source": [
    "spark.stop()\n",
    "print(\"Spark ì„¸ì…˜ ì¢…ë£Œ\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
