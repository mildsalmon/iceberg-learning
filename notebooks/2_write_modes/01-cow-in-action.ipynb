{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0b1c2d3",
   "metadata": {},
   "source": [
    "# COW(Copy-on-Write) 동작 원리 실습\n",
    "\n",
    "이 노트북에서는 Iceberg의 **Copy-on-Write(COW)** 전략이 실제로 어떻게 동작하는지 파일 수준에서 관찰합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c2d3e4",
   "metadata": {},
   "source": [
    "## COW(Copy-on-Write)란?\n",
    "\n",
    "COW는 Iceberg의 **기본 쓰기 전략**입니다.\n",
    "\n",
    "### 핵심 원리\n",
    "- 데이터 파일의 **단 한 행**이라도 업데이트/삭제되면, 해당 데이터 파일 **전체를 다시 씁니다**\n",
    "- 기존 파일은 그대로 두고, 변경된 내용을 반영한 **새 파일**을 생성합니다\n",
    "\n",
    "### 장점\n",
    "- **읽기에 최적화**: 삭제 파일(delete file) 없이 데이터 파일만 읽으면 됩니다\n",
    "- 읽기 시 추가적인 병합(merge) 작업이 필요 없습니다\n",
    "\n",
    "### 단점\n",
    "- **행 수준 업데이트/삭제가 느림**: 1건만 바꿔도 파일 전체를 재작성해야 합니다\n",
    "- 쓰기 증폭(write amplification)이 발생합니다\n",
    "\n",
    "```\n",
    "예시: 1000행 파일에서 1행 UPDATE\n",
    "┌─────────────────┐         ┌─────────────────┐\n",
    "│  기존 파일        │         │  새 파일          │\n",
    "│  (1000행)        │  ──→   │  (1000행, 1행 변경)│\n",
    "│  ❌ 더 이상 참조 안됨│         │  ✅ 새 스냅샷이 참조│\n",
    "└─────────────────┘         └─────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d3e4f5",
   "metadata": {},
   "source": [
    "## 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3e4f5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.spark_setup import create_spark_session\n",
    "from utils.data_generator import generate_orders, to_spark_df\n",
    "from utils.file_explorer import (\n",
    "    show_tree, snapshot_tree, diff_tree, count_files, total_size,\n",
    "    show_metadata_hierarchy,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4f5a6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark + Iceberg 세션 준비 완료 (warehouse: file:///home/jovyan/data/warehouse)\n"
     ]
    }
   ],
   "source": [
    "spark = create_spark_session()\n",
    "\n",
    "TABLE_NAME = \"demo.lab.cow_orders\"\n",
    "TABLE_PATH = \"/home/jovyan/data/warehouse/lab/cow_orders\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a6b7c8",
   "metadata": {},
   "source": [
    "## COW 테이블 생성\n",
    "\n",
    "모든 쓰기 모드(delete, update, merge)를 `copy-on-write`로 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6b7c8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테이블 생성 완료: demo.lab.cow_orders\n",
      "  write.delete.mode = copy-on-write\n",
      "  write.merge.mode = copy-on-write\n",
      "  write.parquet.compression-codec = zstd\n",
      "  write.update.mode = copy-on-write\n"
     ]
    }
   ],
   "source": [
    "spark.sql(f\"DROP TABLE IF EXISTS {TABLE_NAME}\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE {TABLE_NAME} (\n",
    "    order_id BIGINT,\n",
    "    customer_id BIGINT,\n",
    "    product_name STRING,\n",
    "    order_date DATE,\n",
    "    amount DECIMAL(10,2),\n",
    "    status STRING\n",
    ") USING ICEBERG\n",
    "PARTITIONED BY (months(order_date))\n",
    "TBLPROPERTIES (\n",
    "    'write.delete.mode'='copy-on-write',\n",
    "    'write.update.mode'='copy-on-write',\n",
    "    'write.merge.mode'='copy-on-write'\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "print(f\"테이블 생성 완료: {TABLE_NAME}\")\n",
    "\n",
    "# 설정 확인\n",
    "props = spark.sql(f\"SHOW TBLPROPERTIES {TABLE_NAME}\").collect()\n",
    "for row in props:\n",
    "    if 'write' in row['key']:\n",
    "        print(f\"  {row['key']} = {row['value']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c8d9e0",
   "metadata": {},
   "source": [
    "---\n",
    "## 실험 1: INSERT — 초기 데이터 적재\n",
    "\n",
    "100건의 주문 데이터를 삽입하고, 파일 시스템 상태를 관찰합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8d9e0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "INSERT 후 변경 사항:\n",
      "============================================================\n",
      "\n",
      "[+] 추가된 파일 (6개):\n",
      "    + data/order_date_month=2024-01/00000-5-4e878d0d-1aae-4e48-a33b-750726599cef-00001.parquet  (2.5 KB)\n",
      "    + data/order_date_month=2024-02/00000-5-4e878d0d-1aae-4e48-a33b-750726599cef-00002.parquet  (2.5 KB)\n",
      "    + data/order_date_month=2024-03/00000-5-4e878d0d-1aae-4e48-a33b-750726599cef-00003.parquet  (2.4 KB)\n",
      "    + metadata/a5a35bf0-b7da-4b86-ae10-8a16cc3a6f73-m0.avro  (7.3 KB)\n",
      "    + metadata/snap-8931743094173598432-1-a5a35bf0-b7da-4b86-ae10-8a16cc3a6f73.avro  (4.2 KB)\n",
      "    + metadata/v2.metadata.json  (2.7 KB)\n",
      "\n",
      "요약: +6 추가, -0 삭제, ~0 변경\n"
     ]
    }
   ],
   "source": [
    "before_insert = snapshot_tree(TABLE_PATH)\n",
    "\n",
    "# 100건 INSERT\n",
    "orders = generate_orders(num_records=100, seed=42)\n",
    "df = to_spark_df(spark, orders)\n",
    "df.writeTo(TABLE_NAME).append()\n",
    "\n",
    "after_insert = snapshot_tree(TABLE_PATH)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"INSERT 후 변경 사항:\")\n",
    "print(\"=\" * 60)\n",
    "diff_tree(before_insert, after_insert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9e0f1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT 후 테이블 트리 구조:\n",
      "============================================================\n",
      "├── data/\n",
      "│   ├── order_date_month=2024-01/\n",
      "│   │   └── 00000-5-4e878d0d-1aae-4e48-a33b-750726599cef-00001.parquet  (2.5 KB)\n",
      "│   ├── order_date_month=2024-02/\n",
      "│   │   └── 00000-5-4e878d0d-1aae-4e48-a33b-750726599cef-00002.parquet  (2.5 KB)\n",
      "│   └── order_date_month=2024-03/\n",
      "│       └── 00000-5-4e878d0d-1aae-4e48-a33b-750726599cef-00003.parquet  (2.4 KB)\n",
      "└── metadata/\n",
      "    ├── a5a35bf0-b7da-4b86-ae10-8a16cc3a6f73-m0.avro  (7.3 KB)\n",
      "    ├── snap-8931743094173598432-1-a5a35bf0-b7da-4b86-ae10-8a16cc3a6f73.avro  (4.2 KB)\n",
      "    ├── v1.metadata.json  (1.6 KB)\n",
      "    ├── v2.metadata.json  (2.7 KB)\n",
      "    └── version-hint.text  (1 B)\n",
      "\n",
      "파일 수: 3\n",
      "총 크기: 23,667 bytes\n"
     ]
    }
   ],
   "source": [
    "print(\"INSERT 후 테이블 트리 구조:\")\n",
    "print(\"=\" * 60)\n",
    "show_tree(TABLE_PATH)\n",
    "\n",
    "print(f\"\\n파일 수: {count_files(TABLE_PATH)}\")\n",
    "print(f\"총 크기: {total_size(TABLE_PATH):,} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0f1a2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 레코드 수: 100\n",
      "\n",
      "상태별 건수:\n",
      "+----------+---+\n",
      "|    status|cnt|\n",
      "+----------+---+\n",
      "|processing| 24|\n",
      "|   shipped| 22|\n",
      "|   pending| 19|\n",
      "| cancelled| 18|\n",
      "| completed| 17|\n",
      "+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "print(f\"총 레코드 수: {spark.sql(f'SELECT COUNT(*) FROM {TABLE_NAME}').collect()[0][0]}\")\n",
    "print(\"\\n상태별 건수:\")\n",
    "spark.sql(f\"SELECT status, COUNT(*) as cnt FROM {TABLE_NAME} GROUP BY status ORDER BY cnt DESC\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1a2b3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 스냅샷:\n",
      "+----------------------+-------------------+---------+---------+-----------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|committed_at          |snapshot_id        |parent_id|operation|manifest_list                                                                                                                |summary                                                                                                                                                                                                                                                                                             |\n",
      "+----------------------+-------------------+---------+---------+-----------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|2026-02-09 20:10:36.06|8931743094173598432|null     |append   |file:/home/jovyan/data/warehouse/lab/cow_orders/metadata/snap-8931743094173598432-1-a5a35bf0-b7da-4b86-ae10-8a16cc3a6f73.avro|{spark.app.id -> local-1770667830704, added-data-files -> 3, added-records -> 100, added-files-size -> 7530, changed-partition-count -> 3, total-records -> 100, total-files-size -> 7530, total-data-files -> 3, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}|\n",
      "+----------------------+-------------------+---------+---------+-----------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 스냅샷 확인\n",
    "print(\"현재 스냅샷:\")\n",
    "spark.sql(f\"SELECT * FROM {TABLE_NAME}.snapshots\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b3c4d5",
   "metadata": {},
   "source": [
    "### 관찰 포인트 — INSERT\n",
    "\n",
    "- INSERT는 COW/MOR에 관계없이 동일하게 동작합니다\n",
    "- 파티션(months)별로 데이터 파일이 생성되었습니다\n",
    "- 스냅샷이 1개 생성되었습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c4d5e6",
   "metadata": {},
   "source": [
    "---\n",
    "## 실험 2: UPDATE — COW의 핵심 동작 관찰\n",
    "\n",
    "`status='cancelled'`인 주문을 `status='refunded'`로 변경합니다.  \n",
    "COW에서는 변경된 행이 포함된 파티션의 데이터 파일이 **통째로 재작성**됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4d5e6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPDATE 대상 (status='cancelled'): 18건\n",
      "\n",
      "파티션별 분포:\n",
      "+---------------+---+\n",
      "|partition_month|cnt|\n",
      "+---------------+---+\n",
      "|              1|  5|\n",
      "|              2|  6|\n",
      "|              3|  7|\n",
      "+---------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# UPDATE 대상 확인\n",
    "cancelled_count = spark.sql(f\"SELECT COUNT(*) FROM {TABLE_NAME} WHERE status = 'cancelled'\").collect()[0][0]\n",
    "print(f\"UPDATE 대상 (status='cancelled'): {cancelled_count}건\")\n",
    "print(\"\\n파티션별 분포:\")\n",
    "spark.sql(f\"\"\"\n",
    "    SELECT month(order_date) as partition_month, COUNT(*) as cnt\n",
    "    FROM {TABLE_NAME}\n",
    "    WHERE status = 'cancelled'\n",
    "    GROUP BY month(order_date)\n",
    "    ORDER BY partition_month\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5e6f7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "UPDATE 후 변경 사항 (COW):\n",
      "============================================================\n",
      "\n",
      "[+] 추가된 파일 (7개):\n",
      "    + data/order_date_month=2024-01/00000-14-7286ce55-ba45-436b-93be-e0cfe833abee-00001.parquet  (2.5 KB)\n",
      "    + data/order_date_month=2024-02/00000-14-7286ce55-ba45-436b-93be-e0cfe833abee-00002.parquet  (2.5 KB)\n",
      "    + data/order_date_month=2024-03/00000-14-7286ce55-ba45-436b-93be-e0cfe833abee-00003.parquet  (2.4 KB)\n",
      "    + metadata/b41ba155-557d-4f22-9b3e-9e267ff97a5c-m0.avro  (7.3 KB)\n",
      "    + metadata/b41ba155-557d-4f22-9b3e-9e267ff97a5c-m1.avro  (7.3 KB)\n",
      "    + metadata/snap-8596805567379484441-1-b41ba155-557d-4f22-9b3e-9e267ff97a5c.avro  (4.2 KB)\n",
      "    + metadata/v3.metadata.json  (3.8 KB)\n",
      "\n",
      "요약: +7 추가, -0 삭제, ~0 변경\n"
     ]
    }
   ],
   "source": [
    "before_update = snapshot_tree(TABLE_PATH)\n",
    "\n",
    "# UPDATE 실행\n",
    "spark.sql(f\"UPDATE {TABLE_NAME} SET status = 'refunded' WHERE status = 'cancelled'\")\n",
    "\n",
    "after_update = snapshot_tree(TABLE_PATH)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"UPDATE 후 변경 사항 (COW):\")\n",
    "print(\"=\" * 60)\n",
    "diff_tree(before_update, after_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6f7a8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPDATE 후 테이블 트리 구조:\n",
      "============================================================\n",
      "├── data/\n",
      "│   ├── order_date_month=2024-01/\n",
      "│   │   ├── 00000-14-7286ce55-ba45-436b-93be-e0cfe833abee-00001.parquet  (2.5 KB)\n",
      "│   │   └── 00000-5-4e878d0d-1aae-4e48-a33b-750726599cef-00001.parquet  (2.5 KB)\n",
      "│   ├── order_date_month=2024-02/\n",
      "│   │   ├── 00000-14-7286ce55-ba45-436b-93be-e0cfe833abee-00002.parquet  (2.5 KB)\n",
      "│   │   └── 00000-5-4e878d0d-1aae-4e48-a33b-750726599cef-00002.parquet  (2.5 KB)\n",
      "│   └── order_date_month=2024-03/\n",
      "│       ├── 00000-14-7286ce55-ba45-436b-93be-e0cfe833abee-00003.parquet  (2.4 KB)\n",
      "│       └── 00000-5-4e878d0d-1aae-4e48-a33b-750726599cef-00003.parquet  (2.4 KB)\n",
      "└── metadata/\n",
      "    ├── a5a35bf0-b7da-4b86-ae10-8a16cc3a6f73-m0.avro  (7.3 KB)\n",
      "    ├── b41ba155-557d-4f22-9b3e-9e267ff97a5c-m0.avro  (7.3 KB)\n",
      "    ├── b41ba155-557d-4f22-9b3e-9e267ff97a5c-m1.avro  (7.3 KB)\n",
      "    ├── snap-8596805567379484441-1-b41ba155-557d-4f22-9b3e-9e267ff97a5c.avro  (4.2 KB)\n",
      "    ├── snap-8931743094173598432-1-a5a35bf0-b7da-4b86-ae10-8a16cc3a6f73.avro  (4.2 KB)\n",
      "    ├── v1.metadata.json  (1.6 KB)\n",
      "    ├── v2.metadata.json  (2.7 KB)\n",
      "    ├── v3.metadata.json  (3.8 KB)\n",
      "    └── version-hint.text  (1 B)\n",
      "\n",
      "파일 수: 6\n",
      "총 크기: 54,237 bytes\n"
     ]
    }
   ],
   "source": [
    "print(\"UPDATE 후 테이블 트리 구조:\")\n",
    "print(\"=\" * 60)\n",
    "show_tree(TABLE_PATH)\n",
    "\n",
    "print(f\"\\n파일 수: {count_files(TABLE_PATH)}\")\n",
    "print(f\"총 크기: {total_size(TABLE_PATH):,} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qw7q2lmpsbp",
   "metadata": {},
   "source": [
    "### Metadata 계층 구조로 보는 COW UPDATE\n",
    "\n",
    "파일 시스템의 변화를 확인했으니, 이제 Iceberg의 **전체 메타데이터 계층**을 따라가며 UPDATE가 내부적으로 어떻게 기록되는지 확인합니다.\n",
    "\n",
    "```\n",
    "metadata.json   ← 현재 스냅샷 ID를 가리킴\n",
    "│\n",
    "└─▶ snap-*.avro   [Manifest List]  ← 이 스냅샷이 참조하는 Manifest 목록\n",
    "    ├─▶ *-m0.avro  [Manifest File]  ← 새 파일 목록 (ADDED)\n",
    "    │   └── *.parquet               ← 실제 데이터 파일\n",
    "    └─▶ *-m1.avro  [Manifest File]  ← 기존 파일 상태 (DELETED)\n",
    "        └── *.parquet               ← 더 이상 참조되지 않는 파일\n",
    "```\n",
    "\n",
    "각 파일의 상태: **ADDED**(이 스냅샷에서 추가) · **EXISTING**(이전에서 유지) · **DELETED**(이 스냅샷에서 제거)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38x7tpjzl3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v3.metadata.json  (operation: overwrite)\n",
      "│\n",
      "└─▶ snap-8596805567379484441-1-b41ba155-557d-4f22-9b3e-9e267ff97a5c.avro  [Manifest List]\n",
      "    ├─▶ b41ba155-557d-4f22-9b3e-9e267ff97a5c-m1.avro  [Manifest — DATA: 3 ADDED]\n",
      "        │   ├── data/warehouse/lab/cow_orders/data/order_date_month=2024-01/00000-14-7286ce55-ba45-436b-93be-e0cfe833abee-00001.parquet  (38행, ADDED)\n",
      "        │   ├── data/warehouse/lab/cow_orders/data/order_date_month=2024-02/00000-14-7286ce55-ba45-436b-93be-e0cfe833abee-00002.parquet  (32행, ADDED)\n",
      "        │   └── data/warehouse/lab/cow_orders/data/order_date_month=2024-03/00000-14-7286ce55-ba45-436b-93be-e0cfe833abee-00003.parquet  (30행, ADDED)\n",
      "    └─▶ b41ba155-557d-4f22-9b3e-9e267ff97a5c-m0.avro  [Manifest — DATA: 3 DELETED]\n",
      "            ├── data/warehouse/lab/cow_orders/data/order_date_month=2024-01/00000-5-4e878d0d-1aae-4e48-a33b-750726599cef-00001.parquet  (38행, DELETED)\n",
      "            ├── data/warehouse/lab/cow_orders/data/order_date_month=2024-02/00000-5-4e878d0d-1aae-4e48-a33b-750726599cef-00002.parquet  (32행, DELETED)\n",
      "            └── data/warehouse/lab/cow_orders/data/order_date_month=2024-03/00000-5-4e878d0d-1aae-4e48-a33b-750726599cef-00003.parquet  (30행, DELETED)\n"
     ]
    }
   ],
   "source": [
    "# metadata.json → manifest list → manifest file → data file 전체 계층 확인\n",
    "show_metadata_hierarchy(TABLE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7a8b9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일별 레코드 수 확인:\n",
      "+-----------------------------------------------------------------------------------------------------------------------+------------+------------------+\n",
      "|file_path                                                                                                              |record_count|file_size_in_bytes|\n",
      "+-----------------------------------------------------------------------------------------------------------------------+------------+------------------+\n",
      "|data/warehouse/lab/cow_orders/data/order_date_month=2024-01/00000-14-7286ce55-ba45-436b-93be-e0cfe833abee-00001.parquet|38          |2546              |\n",
      "|data/warehouse/lab/cow_orders/data/order_date_month=2024-02/00000-14-7286ce55-ba45-436b-93be-e0cfe833abee-00002.parquet|32          |2520              |\n",
      "|data/warehouse/lab/cow_orders/data/order_date_month=2024-03/00000-14-7286ce55-ba45-436b-93be-e0cfe833abee-00003.parquet|30          |2461              |\n",
      "+-----------------------------------------------------------------------------------------------------------------------+------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 파일 수준에서 비교: 기존 파일 vs 새 파일의 레코드 수\n",
    "print(\"파일별 레코드 수 확인:\")\n",
    "spark.sql(f\"\"\"\n",
    "    SELECT \n",
    "        regexp_replace(file_path, '^file:.*?/(data/)', '$1') as file_path, \n",
    "        record_count, \n",
    "        file_size_in_bytes\n",
    "    FROM {TABLE_NAME}.files\n",
    "    ORDER BY file_path\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8b9c0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 스냅샷:\n",
      "+-----------------------+-------------------+-------------------+---------+-----------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|committed_at           |snapshot_id        |parent_id          |operation|manifest_list                                                                                                                |summary                                                                                                                                                                                                                                                                                                                                                                          |\n",
      "+-----------------------+-------------------+-------------------+---------+-----------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|2026-02-09 20:10:36.06 |8931743094173598432|null               |append   |file:/home/jovyan/data/warehouse/lab/cow_orders/metadata/snap-8931743094173598432-1-a5a35bf0-b7da-4b86-ae10-8a16cc3a6f73.avro|{spark.app.id -> local-1770667830704, added-data-files -> 3, added-records -> 100, added-files-size -> 7530, changed-partition-count -> 3, total-records -> 100, total-files-size -> 7530, total-data-files -> 3, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}                                                                             |\n",
      "|2026-02-09 20:10:38.072|8596805567379484441|8931743094173598432|overwrite|file:/home/jovyan/data/warehouse/lab/cow_orders/metadata/snap-8596805567379484441-1-b41ba155-557d-4f22-9b3e-9e267ff97a5c.avro|{spark.app.id -> local-1770667830704, added-data-files -> 3, deleted-data-files -> 3, added-records -> 100, deleted-records -> 100, added-files-size -> 7527, removed-files-size -> 7530, changed-partition-count -> 3, total-records -> 100, total-files-size -> 7527, total-data-files -> 3, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}|\n",
      "+-----------------------+-------------------+-------------------+---------+-----------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 스냅샷 확인\n",
    "print(\"현재 스냅샷:\")\n",
    "spark.sql(f\"SELECT * FROM {TABLE_NAME}.snapshots\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c0d1e2",
   "metadata": {},
   "source": [
    "### 관찰 포인트 — UPDATE (COW)\n",
    "\n",
    "- `cancelled` 상태의 주문이 포함된 **파티션의 데이터 파일이 통째로 재작성**되었습니다\n",
    "- 새 데이터 파일이 추가되고, 기존 파일은 메타데이터에서 참조가 해제됩니다\n",
    "- **Delete File은 생성되지 않았습니다** — 이것이 COW의 특징입니다\n",
    "- 영향받지 않은 파티션의 파일은 그대로 유지됩니다\n",
    "- 스냅샷이 1개 더 추가되었습니다 (총 2개)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d1e2f3",
   "metadata": {},
   "source": [
    "---\n",
    "## 실험 3: DELETE — 파일 재작성 패턴 재확인\n",
    "\n",
    "`amount < 200`인 주문을 삭제합니다.  \n",
    "DELETE도 UPDATE와 동일하게 파일 전체가 재작성됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1e2f3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DELETE 대상 (amount < 200): 13건\n",
      "DELETE 전 총 레코드 수: 100\n"
     ]
    }
   ],
   "source": [
    "# DELETE 대상 확인\n",
    "delete_count = spark.sql(f\"SELECT COUNT(*) FROM {TABLE_NAME} WHERE amount < 200\").collect()[0][0]\n",
    "print(f\"DELETE 대상 (amount < 200): {delete_count}건\")\n",
    "print(f\"DELETE 전 총 레코드 수: {spark.sql(f'SELECT COUNT(*) FROM {TABLE_NAME}').collect()[0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2f3a4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DELETE 후 변경 사항 (COW):\n",
      "============================================================\n",
      "\n",
      "[+] 추가된 파일 (7개):\n",
      "    + data/order_date_month=2024-01/00000-22-fe7aa32e-536b-43fb-a3b7-7c62a7cf3334-00001.parquet  (2.4 KB)\n",
      "    + data/order_date_month=2024-02/00000-22-fe7aa32e-536b-43fb-a3b7-7c62a7cf3334-00002.parquet  (2.4 KB)\n",
      "    + data/order_date_month=2024-03/00000-22-fe7aa32e-536b-43fb-a3b7-7c62a7cf3334-00003.parquet  (2.4 KB)\n",
      "    + metadata/5cdde880-5fb5-42b5-88a6-174d185ed341-m0.avro  (7.3 KB)\n",
      "    + metadata/5cdde880-5fb5-42b5-88a6-174d185ed341-m1.avro  (7.3 KB)\n",
      "    + metadata/snap-3267856845968573308-1-5cdde880-5fb5-42b5-88a6-174d185ed341.avro  (4.2 KB)\n",
      "    + metadata/v4.metadata.json  (4.8 KB)\n",
      "\n",
      "요약: +7 추가, -0 삭제, ~0 변경\n"
     ]
    }
   ],
   "source": [
    "before_delete = snapshot_tree(TABLE_PATH)\n",
    "\n",
    "# DELETE 실행\n",
    "spark.sql(f\"DELETE FROM {TABLE_NAME} WHERE amount < 200\")\n",
    "\n",
    "after_delete = snapshot_tree(TABLE_PATH)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DELETE 후 변경 사항 (COW):\")\n",
    "print(\"=\" * 60)\n",
    "diff_tree(before_delete, after_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3a4b5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DELETE 후 테이블 트리 구조:\n",
      "============================================================\n",
      "├── data/\n",
      "│   ├── order_date_month=2024-01/\n",
      "│   │   ├── 00000-14-7286ce55-ba45-436b-93be-e0cfe833abee-00001.parquet  (2.5 KB)\n",
      "│   │   ├── 00000-22-fe7aa32e-536b-43fb-a3b7-7c62a7cf3334-00001.parquet  (2.4 KB)\n",
      "│   │   └── 00000-5-4e878d0d-1aae-4e48-a33b-750726599cef-00001.parquet  (2.5 KB)\n",
      "│   ├── order_date_month=2024-02/\n",
      "│   │   ├── 00000-14-7286ce55-ba45-436b-93be-e0cfe833abee-00002.parquet  (2.5 KB)\n",
      "│   │   ├── 00000-22-fe7aa32e-536b-43fb-a3b7-7c62a7cf3334-00002.parquet  (2.4 KB)\n",
      "│   │   └── 00000-5-4e878d0d-1aae-4e48-a33b-750726599cef-00002.parquet  (2.5 KB)\n",
      "│   └── order_date_month=2024-03/\n",
      "│       ├── 00000-14-7286ce55-ba45-436b-93be-e0cfe833abee-00003.parquet  (2.4 KB)\n",
      "│       ├── 00000-22-fe7aa32e-536b-43fb-a3b7-7c62a7cf3334-00003.parquet  (2.4 KB)\n",
      "│       └── 00000-5-4e878d0d-1aae-4e48-a33b-750726599cef-00003.parquet  (2.4 KB)\n",
      "└── metadata/\n",
      "    ├── 5cdde880-5fb5-42b5-88a6-174d185ed341-m0.avro  (7.3 KB)\n",
      "    ├── 5cdde880-5fb5-42b5-88a6-174d185ed341-m1.avro  (7.3 KB)\n",
      "    ├── a5a35bf0-b7da-4b86-ae10-8a16cc3a6f73-m0.avro  (7.3 KB)\n",
      "    ├── b41ba155-557d-4f22-9b3e-9e267ff97a5c-m0.avro  (7.3 KB)\n",
      "    ├── b41ba155-557d-4f22-9b3e-9e267ff97a5c-m1.avro  (7.3 KB)\n",
      "    ├── snap-3267856845968573308-1-5cdde880-5fb5-42b5-88a6-174d185ed341.avro  (4.2 KB)\n",
      "    ├── snap-8596805567379484441-1-b41ba155-557d-4f22-9b3e-9e267ff97a5c.avro  (4.2 KB)\n",
      "    ├── snap-8931743094173598432-1-a5a35bf0-b7da-4b86-ae10-8a16cc3a6f73.avro  (4.2 KB)\n",
      "    ├── v1.metadata.json  (1.6 KB)\n",
      "    ├── v2.metadata.json  (2.7 KB)\n",
      "    ├── v3.metadata.json  (3.8 KB)\n",
      "    ├── v4.metadata.json  (4.8 KB)\n",
      "    └── version-hint.text  (1 B)\n",
      "\n",
      "파일 수: 9\n",
      "총 크기: 85,756 bytes\n",
      "DELETE 후 총 레코드 수: 87\n"
     ]
    }
   ],
   "source": [
    "print(\"DELETE 후 테이블 트리 구조:\")\n",
    "print(\"=\" * 60)\n",
    "show_tree(TABLE_PATH)\n",
    "\n",
    "print(f\"\\n파일 수: {count_files(TABLE_PATH)}\")\n",
    "print(f\"총 크기: {total_size(TABLE_PATH):,} bytes\")\n",
    "print(f\"DELETE 후 총 레코드 수: {spark.sql(f'SELECT COUNT(*) FROM {TABLE_NAME}').collect()[0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "i2cs57ojik8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v4.metadata.json  (operation: overwrite)\n",
      "│\n",
      "└─▶ snap-3267856845968573308-1-5cdde880-5fb5-42b5-88a6-174d185ed341.avro  [Manifest List]\n",
      "    ├─▶ 5cdde880-5fb5-42b5-88a6-174d185ed341-m1.avro  [Manifest — DATA: 3 ADDED]\n",
      "        │   ├── data/warehouse/lab/cow_orders/data/order_date_month=2024-01/00000-22-fe7aa32e-536b-43fb-a3b7-7c62a7cf3334-00001.parquet  (32행, ADDED)\n",
      "        │   ├── data/warehouse/lab/cow_orders/data/order_date_month=2024-02/00000-22-fe7aa32e-536b-43fb-a3b7-7c62a7cf3334-00002.parquet  (28행, ADDED)\n",
      "        │   └── data/warehouse/lab/cow_orders/data/order_date_month=2024-03/00000-22-fe7aa32e-536b-43fb-a3b7-7c62a7cf3334-00003.parquet  (27행, ADDED)\n",
      "    └─▶ 5cdde880-5fb5-42b5-88a6-174d185ed341-m0.avro  [Manifest — DATA: 3 DELETED]\n",
      "            ├── data/warehouse/lab/cow_orders/data/order_date_month=2024-01/00000-14-7286ce55-ba45-436b-93be-e0cfe833abee-00001.parquet  (38행, DELETED)\n",
      "            ├── data/warehouse/lab/cow_orders/data/order_date_month=2024-02/00000-14-7286ce55-ba45-436b-93be-e0cfe833abee-00002.parquet  (32행, DELETED)\n",
      "            └── data/warehouse/lab/cow_orders/data/order_date_month=2024-03/00000-14-7286ce55-ba45-436b-93be-e0cfe833abee-00003.parquet  (30행, DELETED)\n",
      "\n",
      "→ COW에서는 INSERT/UPDATE/DELETE 모두 '파일 전체 재작성' 방식입니다.\n",
      "  Manifest에서 기존 파일은 DELETED, 새 파일은 ADDED로 기록됩니다.\n"
     ]
    }
   ],
   "source": [
    "# DELETE 후에도 동일한 패턴: DELETED + ADDED\n",
    "show_metadata_hierarchy(TABLE_PATH)\n",
    "\n",
    "print(\"\\n→ COW에서는 INSERT/UPDATE/DELETE 모두 '파일 전체 재작성' 방식입니다.\")\n",
    "print(\"  Manifest에서 기존 파일은 DELETED, 새 파일은 ADDED로 기록됩니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4b5c6d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 스냅샷:\n",
      "+-----------------------+-------------------+-------------------+---------+-----------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|committed_at           |snapshot_id        |parent_id          |operation|manifest_list                                                                                                                |summary                                                                                                                                                                                                                                                                                                                                                                          |\n",
      "+-----------------------+-------------------+-------------------+---------+-----------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|2026-02-09 20:10:36.06 |8931743094173598432|null               |append   |file:/home/jovyan/data/warehouse/lab/cow_orders/metadata/snap-8931743094173598432-1-a5a35bf0-b7da-4b86-ae10-8a16cc3a6f73.avro|{spark.app.id -> local-1770667830704, added-data-files -> 3, added-records -> 100, added-files-size -> 7530, changed-partition-count -> 3, total-records -> 100, total-files-size -> 7530, total-data-files -> 3, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}                                                                             |\n",
      "|2026-02-09 20:10:38.072|8596805567379484441|8931743094173598432|overwrite|file:/home/jovyan/data/warehouse/lab/cow_orders/metadata/snap-8596805567379484441-1-b41ba155-557d-4f22-9b3e-9e267ff97a5c.avro|{spark.app.id -> local-1770667830704, added-data-files -> 3, deleted-data-files -> 3, added-records -> 100, deleted-records -> 100, added-files-size -> 7527, removed-files-size -> 7530, changed-partition-count -> 3, total-records -> 100, total-files-size -> 7527, total-data-files -> 3, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}|\n",
      "|2026-02-09 20:10:38.85 |3267856845968573308|8596805567379484441|overwrite|file:/home/jovyan/data/warehouse/lab/cow_orders/metadata/snap-3267856845968573308-1-5cdde880-5fb5-42b5-88a6-174d185ed341.avro|{spark.app.id -> local-1770667830704, added-data-files -> 3, deleted-data-files -> 3, added-records -> 87, deleted-records -> 100, added-files-size -> 7373, removed-files-size -> 7527, changed-partition-count -> 3, total-records -> 87, total-files-size -> 7373, total-data-files -> 3, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}  |\n",
      "+-----------------------+-------------------+-------------------+---------+-----------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 스냅샷 확인\n",
    "print(\"현재 스냅샷:\")\n",
    "spark.sql(f\"SELECT * FROM {TABLE_NAME}.snapshots\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c6d7e8",
   "metadata": {},
   "source": [
    "### 관찰 포인트 — DELETE (COW)\n",
    "\n",
    "- DELETE도 UPDATE와 동일한 패턴: 영향받은 파티션의 **데이터 파일이 통째로 재작성**됩니다\n",
    "- 삭제된 행을 제외한 나머지 행만 포함된 **새 파일**이 생성됩니다\n",
    "- 역시 **Delete File은 생성되지 않았습니다**\n",
    "- 스냅샷이 1개 더 추가되었습니다 (총 3개)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d7e8f9",
   "metadata": {},
   "source": [
    "---\n",
    "## 정리: COW(Copy-on-Write) 핵심 요약\n",
    "\n",
    "| 항목 | 설명 |\n",
    "|------|------|\n",
    "| **쓰기 방식** | 변경된 행이 포함된 데이터 파일 전체를 새로 작성 |\n",
    "| **Delete File** | 생성하지 않음 |\n",
    "| **읽기 성능** | 최적 — 데이터 파일만 읽으면 됨 |\n",
    "| **쓰기 성능** | 느림 — 1건 변경에도 파일 전체 재작성 |\n",
    "| **적합한 워크로드** | 읽기 중심, 업데이트/삭제가 적은 경우 |\n",
    "\n",
    "> **핵심**: COW에서는 **1건만 바꿔도 해당 파티션의 데이터 파일이 통째로 재작성**됩니다.  \n",
    "> 다음 노트북에서 MOR(Merge-on-Read)이 이 문제를 어떻게 해결하는지 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7e8f9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark 세션 종료\n"
     ]
    }
   ],
   "source": [
    "spark.stop()\n",
    "print(\"Spark 세션 종료\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
