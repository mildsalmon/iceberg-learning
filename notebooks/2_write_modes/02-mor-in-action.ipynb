{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0b1c2d3",
   "metadata": {},
   "source": [
    "# MOR(Merge-on-Read) 동작 원리 실습\n",
    "\n",
    "이 노트북에서는 Iceberg의 **Merge-on-Read(MOR)** 전략이 실제로 어떻게 동작하는지 파일 수준에서 관찰합니다.  \n",
    "특히 **Delete File**의 생성과 역할에 집중합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c2d3e4",
   "metadata": {},
   "source": [
    "## MOR(Merge-on-Read)란?\n",
    "\n",
    "MOR은 COW의 \"파일 전체 재작성\" 문제를 해결하기 위한 전략입니다.\n",
    "\n",
    "### 핵심 원리\n",
    "전체 데이터 파일을 다시 쓰는 대신, **삭제 파일(Delete File)**에 어떤 레코드를 무시할지 기록합니다.\n",
    "\n",
    "### 삭제(DELETE) 시 동작\n",
    "- 기존 데이터 파일은 **그대로 유지**\n",
    "- 삭제할 레코드의 위치가 **Delete File**에 기록됨\n",
    "\n",
    "### 업데이트(UPDATE) 시 동작\n",
    "1. 이전 레코드의 위치가 **Delete File**에 추가\n",
    "2. 업데이트된 레코드만 **새 데이터 파일**에 작성\n",
    "\n",
    "### 읽기(READ) 시 동작\n",
    "- 데이터 파일과 Delete File을 **조정(merge)**하여 최종 결과 반환\n",
    "- 즉, 삭제 표시된 레코드를 제외하고 읽음\n",
    "\n",
    "### 장점 vs 단점\n",
    "- **장점**: 쓰기가 빠름 (파일 전체를 재작성하지 않으므로)\n",
    "- **단점**: 읽기가 느림 (Delete File과의 병합 작업 필요)\n",
    "\n",
    "### 운영 전 체크 (멀티 엔진 필수)\n",
    "\n",
    "MOR를 실무에 적용할 때는 사용하는 쿼리 엔진이 **Delete File(특히 positional delete)**을\n",
    "정확히 읽고 merge하는지 반드시 검증해야 합니다.\n",
    "\n",
    "- 체크 대상 예: Spark, Trino, Flink, Athena 등\n",
    "- 확인 항목: read 결과 정합성, UPDATE/DELETE 후 row count 일치, snapshot 해석 일관성\n",
    "- 미지원 엔진에서 MOR 테이블을 읽으면 결과가 누락/불일치할 수 있습니다.\n",
    "\n",
    "```\n",
    "DELETE 시:\n",
    "┌─────────────────┐    ┌─────────────────┐\n",
    "│  데이터 파일       │    │  Delete File     │\n",
    "│  (1000행, 그대로)  │ +  │  (삭제할 행 위치)   │\n",
    "│  ✅ 파일 유지      │    │  ✅ 새로 생성      │\n",
    "└─────────────────┘    └─────────────────┘\n",
    "\n",
    "UPDATE 시:\n",
    "┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐\n",
    "│  기존 데이터 파일   │    │  Delete File     │    │  새 데이터 파일    │\n",
    "│  (그대로 유지)     │ +  │  (기존 행 위치)    │ +  │  (변경된 행만)     │\n",
    "└─────────────────┘    └─────────────────┘    └─────────────────┘\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d3e4f5",
   "metadata": {},
   "source": [
    "## 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3e4f5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.spark_setup import create_spark_session\n",
    "from utils.data_generator import generate_orders, to_spark_df\n",
    "from utils.file_explorer import (\n",
    "    show_tree, snapshot_tree, diff_tree, count_files, total_size,\n",
    "    show_metadata_hierarchy,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4f5a6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark + Iceberg 세션 준비 완료 (warehouse: file:///home/jovyan/data/warehouse)\n"
     ]
    }
   ],
   "source": [
    "spark = create_spark_session()\n",
    "\n",
    "TABLE_NAME = \"demo.lab.mor_orders\"\n",
    "TABLE_PATH = \"/home/jovyan/data/warehouse/lab/mor_orders\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a6b7c8",
   "metadata": {},
   "source": [
    "## MOR 테이블 생성\n",
    "\n",
    "모든 쓰기 모드(delete, update, merge)를 `merge-on-read`로 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6b7c8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테이블 생성 완료: demo.lab.mor_orders\n",
      "  write.delete.mode = merge-on-read\n",
      "  write.merge.mode = merge-on-read\n",
      "  write.parquet.compression-codec = zstd\n",
      "  write.update.mode = merge-on-read\n"
     ]
    }
   ],
   "source": [
    "spark.sql(f\"DROP TABLE IF EXISTS {TABLE_NAME}\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE {TABLE_NAME} (\n",
    "    order_id BIGINT,\n",
    "    customer_id BIGINT,\n",
    "    product_name STRING,\n",
    "    order_date DATE,\n",
    "    amount DECIMAL(10,2),\n",
    "    status STRING\n",
    ") USING ICEBERG\n",
    "PARTITIONED BY (months(order_date))\n",
    "TBLPROPERTIES (\n",
    "    'write.delete.mode'='merge-on-read',\n",
    "    'write.update.mode'='merge-on-read',\n",
    "    'write.merge.mode'='merge-on-read'\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "print(f\"테이블 생성 완료: {TABLE_NAME}\")\n",
    "\n",
    "# 설정 확인\n",
    "props = spark.sql(f\"SHOW TBLPROPERTIES {TABLE_NAME}\").collect()\n",
    "for row in props:\n",
    "    if 'write' in row['key']:\n",
    "        print(f\"  {row['key']} = {row['value']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c8d9e0",
   "metadata": {},
   "source": [
    "---\n",
    "## 실험 1: INSERT — 초기 데이터 적재\n",
    "\n",
    "100건의 주문 데이터를 삽입합니다. INSERT는 COW와 동일하게 동작합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8d9e0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "INSERT 후 변경 사항:\n",
      "============================================================\n",
      "\n",
      "[+] 추가된 파일 (6개):\n",
      "    + data/order_date_month=2024-01/00000-5-4985e73d-07bb-4f48-8126-9e556bdcdbe9-00001.parquet  (2.5 KB)\n",
      "    + data/order_date_month=2024-02/00000-5-4985e73d-07bb-4f48-8126-9e556bdcdbe9-00002.parquet  (2.5 KB)\n",
      "    + data/order_date_month=2024-03/00000-5-4985e73d-07bb-4f48-8126-9e556bdcdbe9-00003.parquet  (2.4 KB)\n",
      "    + metadata/05976910-09f0-4bb2-837b-764e56139454-m0.avro  (7.3 KB)\n",
      "    + metadata/snap-1474401465633457598-1-05976910-09f0-4bb2-837b-764e56139454.avro  (4.2 KB)\n",
      "    + metadata/v2.metadata.json  (2.7 KB)\n",
      "\n",
      "요약: +6 추가, -0 삭제, ~0 변경\n"
     ]
    }
   ],
   "source": [
    "before_insert = snapshot_tree(TABLE_PATH)\n",
    "\n",
    "# 100건 INSERT\n",
    "orders = generate_orders(num_records=100, seed=42)\n",
    "df = to_spark_df(spark, orders)\n",
    "df.writeTo(TABLE_NAME).append()\n",
    "\n",
    "after_insert = snapshot_tree(TABLE_PATH)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"INSERT 후 변경 사항:\")\n",
    "print(\"=\" * 60)\n",
    "diff_tree(before_insert, after_insert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9e0f1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT 후 테이블 트리 구조:\n",
      "============================================================\n",
      "├── data/\n",
      "│   ├── order_date_month=2024-01/\n",
      "│   │   └── 00000-5-4985e73d-07bb-4f48-8126-9e556bdcdbe9-00001.parquet  (2.5 KB)\n",
      "│   ├── order_date_month=2024-02/\n",
      "│   │   └── 00000-5-4985e73d-07bb-4f48-8126-9e556bdcdbe9-00002.parquet  (2.5 KB)\n",
      "│   └── order_date_month=2024-03/\n",
      "│       └── 00000-5-4985e73d-07bb-4f48-8126-9e556bdcdbe9-00003.parquet  (2.4 KB)\n",
      "└── metadata/\n",
      "    ├── 05976910-09f0-4bb2-837b-764e56139454-m0.avro  (7.3 KB)\n",
      "    ├── snap-1474401465633457598-1-05976910-09f0-4bb2-837b-764e56139454.avro  (4.2 KB)\n",
      "    ├── v1.metadata.json  (1.6 KB)\n",
      "    ├── v2.metadata.json  (2.7 KB)\n",
      "    └── version-hint.text  (1 B)\n",
      "\n",
      "파일 수: 3\n",
      "총 크기: 23,667 bytes\n",
      "총 레코드 수: 100\n"
     ]
    }
   ],
   "source": [
    "print(\"INSERT 후 테이블 트리 구조:\")\n",
    "print(\"=\" * 60)\n",
    "show_tree(TABLE_PATH)\n",
    "\n",
    "print(f\"\\n파일 수: {count_files(TABLE_PATH)}\")\n",
    "print(f\"총 크기: {total_size(TABLE_PATH):,} bytes\")\n",
    "print(f\"총 레코드 수: {spark.sql(f'SELECT COUNT(*) FROM {TABLE_NAME}').collect()[0][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f1a2b3",
   "metadata": {},
   "source": [
    "### 관찰 포인트 — INSERT\n",
    "\n",
    "- INSERT는 COW/MOR 구분 없이 동일하게 동작합니다\n",
    "- 데이터 파일만 생성되었고, Delete File은 없습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a2b3c4",
   "metadata": {},
   "source": [
    "---\n",
    "## 실험 2: DELETE — Delete File 생성 관찰\n",
    "\n",
    "`status='cancelled'`인 주문을 삭제합니다.  \n",
    "MOR에서는 데이터 파일을 재작성하지 않고 **Positional Delete File**을 생성합니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2b3c4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DELETE 대상 (status='cancelled'): 18건\n"
     ]
    }
   ],
   "source": [
    "# DELETE 대상 확인\n",
    "cancelled_count = spark.sql(f\"SELECT COUNT(*) FROM {TABLE_NAME} WHERE status = 'cancelled'\").collect()[0][0]\n",
    "print(f\"DELETE 대상 (status='cancelled'): {cancelled_count}건\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3c4d5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DELETE 후 변경 사항 (MOR):\n",
      "============================================================\n",
      "\n",
      "[+] 추가된 파일 (6개):\n",
      "    + data/order_date_month=2024-01/00000-10-d03b1507-b571-4518-83f1-705c9f0bc706-00001-deletes.parquet  (1.6 KB)\n",
      "    + data/order_date_month=2024-02/00000-10-d03b1507-b571-4518-83f1-705c9f0bc706-00002-deletes.parquet  (1.6 KB)\n",
      "    + data/order_date_month=2024-03/00000-10-d03b1507-b571-4518-83f1-705c9f0bc706-00003-deletes.parquet  (1.6 KB)\n",
      "    + metadata/e862486f-fb23-4905-8e63-2a49c647f358-m0.avro  (7.2 KB)\n",
      "    + metadata/snap-8107597961677446822-1-e862486f-fb23-4905-8e63-2a49c647f358.avro  (4.3 KB)\n",
      "    + metadata/v3.metadata.json  (3.7 KB)\n",
      "\n",
      "요약: +6 추가, -0 삭제, ~0 변경\n"
     ]
    }
   ],
   "source": [
    "before_delete = snapshot_tree(TABLE_PATH)\n",
    "\n",
    "# DELETE 실행\n",
    "spark.sql(f\"DELETE FROM {TABLE_NAME} WHERE status = 'cancelled'\")\n",
    "\n",
    "after_delete = snapshot_tree(TABLE_PATH)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DELETE 후 변경 사항 (MOR):\")\n",
    "print(\"=\" * 60)\n",
    "diff_tree(before_delete, after_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4d5e6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DELETE 후 테이블 트리 구조:\n",
      "============================================================\n",
      "├── data/\n",
      "│   ├── order_date_month=2024-01/\n",
      "│   │   ├── 00000-10-d03b1507-b571-4518-83f1-705c9f0bc706-00001-deletes.parquet  (1.6 KB)\n",
      "│   │   └── 00000-5-4985e73d-07bb-4f48-8126-9e556bdcdbe9-00001.parquet  (2.5 KB)\n",
      "│   ├── order_date_month=2024-02/\n",
      "│   │   ├── 00000-10-d03b1507-b571-4518-83f1-705c9f0bc706-00002-deletes.parquet  (1.6 KB)\n",
      "│   │   └── 00000-5-4985e73d-07bb-4f48-8126-9e556bdcdbe9-00002.parquet  (2.5 KB)\n",
      "│   └── order_date_month=2024-03/\n",
      "│       ├── 00000-10-d03b1507-b571-4518-83f1-705c9f0bc706-00003-deletes.parquet  (1.6 KB)\n",
      "│       └── 00000-5-4985e73d-07bb-4f48-8126-9e556bdcdbe9-00003.parquet  (2.4 KB)\n",
      "└── metadata/\n",
      "    ├── 05976910-09f0-4bb2-837b-764e56139454-m0.avro  (7.3 KB)\n",
      "    ├── e862486f-fb23-4905-8e63-2a49c647f358-m0.avro  (7.2 KB)\n",
      "    ├── snap-1474401465633457598-1-05976910-09f0-4bb2-837b-764e56139454.avro  (4.2 KB)\n",
      "    ├── snap-8107597961677446822-1-e862486f-fb23-4905-8e63-2a49c647f358.avro  (4.3 KB)\n",
      "    ├── v1.metadata.json  (1.6 KB)\n",
      "    ├── v2.metadata.json  (2.7 KB)\n",
      "    ├── v3.metadata.json  (3.7 KB)\n",
      "    └── version-hint.text  (1 B)\n",
      "\n",
      "파일 수 (parquet): 6\n",
      "총 크기: 44,138 bytes\n",
      "총 레코드 수: 82\n"
     ]
    }
   ],
   "source": [
    "print(\"DELETE 후 테이블 트리 구조:\")\n",
    "print(\"=\" * 60)\n",
    "show_tree(TABLE_PATH)\n",
    "\n",
    "print(f\"\\n파일 수 (parquet): {count_files(TABLE_PATH)}\")\n",
    "print(f\"총 크기: {total_size(TABLE_PATH):,} bytes\")\n",
    "print(f\"총 레코드 수: {spark.sql(f'SELECT COUNT(*) FROM {TABLE_NAME}').collect()[0][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fkyz2ln8ska",
   "metadata": {},
   "source": [
    "### Metadata 계층 구조로 보는 MOR DELETE\n",
    "\n",
    "COW에서는 Manifest에 **데이터 파일만** 기록되었습니다.  \n",
    "MOR에서는 **데이터 Manifest와 삭제 Manifest가 분리**됩니다. 계층 구조를 확인하여 COW와의 차이를 관찰해봅니다.\n",
    "\n",
    "```\n",
    "metadata.json\n",
    "│\n",
    "└─▶ snap-*.avro  [Manifest List]\n",
    "    ├─▶ *-m0.avro  [Manifest — DELETES]  ← Delete File 전용\n",
    "    │   └── *-deletes.parquet            ← Positional Delete File\n",
    "    └─▶ *-m0.avro  [Manifest — DATA]     ← 기존 데이터 그대로\n",
    "        └── *.parquet  (EXISTING)        ← 재작성 없음!\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3utk58lb5vf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v3.metadata.json  (operation: overwrite)\n",
      "│\n",
      "└─▶ snap-8107597961677446822-1-e862486f-fb23-4905-8e63-2a49c647f358.avro  [Manifest List]\n",
      "    ├─▶ 05976910-09f0-4bb2-837b-764e56139454-m0.avro  [Manifest — DATA: 3 ADDED]\n",
      "        │   ├── data/warehouse/lab/mor_orders/data/order_date_month=2024-01/00000-5-4985e73d-07bb-4f48-8126-9e556bdcdbe9-00001.parquet  (38행, ADDED)\n",
      "        │   ├── data/warehouse/lab/mor_orders/data/order_date_month=2024-02/00000-5-4985e73d-07bb-4f48-8126-9e556bdcdbe9-00002.parquet  (32행, ADDED)\n",
      "        │   └── data/warehouse/lab/mor_orders/data/order_date_month=2024-03/00000-5-4985e73d-07bb-4f48-8126-9e556bdcdbe9-00003.parquet  (30행, ADDED)\n",
      "    └─▶ e862486f-fb23-4905-8e63-2a49c647f358-m0.avro  [Manifest — DELETES: empty]\n",
      "            ├── data/warehouse/lab/mor_orders/data/order_date_month=2024-01/00000-10-d03b1507-b571-4518-83f1-705c9f0bc706-00001-deletes.parquet  (5행, ADDED)  [DELETE FILE]\n",
      "            ├── data/warehouse/lab/mor_orders/data/order_date_month=2024-02/00000-10-d03b1507-b571-4518-83f1-705c9f0bc706-00002-deletes.parquet  (6행, ADDED)  [DELETE FILE]\n",
      "            └── data/warehouse/lab/mor_orders/data/order_date_month=2024-03/00000-10-d03b1507-b571-4518-83f1-705c9f0bc706-00003-deletes.parquet  (7행, ADDED)  [DELETE FILE]\n"
     ]
    }
   ],
   "source": [
    "# metadata.json → manifest list → manifest file → data file 전체 계층 확인\n",
    "show_metadata_hierarchy(TABLE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e6f7a8",
   "metadata": {},
   "source": [
    "### 관찰 포인트 — DELETE (MOR)\n",
    "\n",
    "- **기존 데이터 파일은 그대로** 유지되었습니다!\n",
    "- 대신 **Positional Delete File**이 새로 생성되었습니다\n",
    "- COW였다면 데이터 파일이 통째로 재작성되었을 텐데, MOR은 작은 Delete File만 추가합니다\n",
    "- 이것이 MOR의 쓰기 성능이 빠른 이유입니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f7a8b9",
   "metadata": {},
   "source": [
    "---\n",
    "## 실험 3: UPDATE — Delete File + 새 데이터 파일\n",
    "\n",
    "`status='pending'`인 주문을 `status='refunded'`로 변경합니다.  \n",
    "MOR의 UPDATE는 두 가지를 동시에 수행합니다:\n",
    "1. 기존 행의 위치를 **Delete File**에 기록\n",
    "2. 변경된 행을 **새 데이터 파일**에 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7a8b9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPDATE 대상 (status='pending'): 19건\n"
     ]
    }
   ],
   "source": [
    "# UPDATE 대상 확인\n",
    "pending_count = spark.sql(f\"SELECT COUNT(*) FROM {TABLE_NAME} WHERE status = 'pending'\").collect()[0][0]\n",
    "print(f\"UPDATE 대상 (status='pending'): {pending_count}건\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8b9c0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "UPDATE 후 변경 사항 (MOR):\n",
      "============================================================\n",
      "\n",
      "[+] 추가된 파일 (10개):\n",
      "    + data/order_date_month=2024-01/00000-19-99789f11-fdcd-496c-a12d-f419b5431f9d-00001-deletes.parquet  (1.6 KB)\n",
      "    + data/order_date_month=2024-01/00000-19-99789f11-fdcd-496c-a12d-f419b5431f9d-00001.parquet  (2.0 KB)\n",
      "    + data/order_date_month=2024-02/00000-19-99789f11-fdcd-496c-a12d-f419b5431f9d-00002-deletes.parquet  (1.6 KB)\n",
      "    + data/order_date_month=2024-02/00000-19-99789f11-fdcd-496c-a12d-f419b5431f9d-00002.parquet  (1.9 KB)\n",
      "    + data/order_date_month=2024-03/00000-19-99789f11-fdcd-496c-a12d-f419b5431f9d-00003-deletes.parquet  (1.6 KB)\n",
      "    + data/order_date_month=2024-03/00000-19-99789f11-fdcd-496c-a12d-f419b5431f9d-00003.parquet  (1.9 KB)\n",
      "    + metadata/9c6fc013-6834-45c5-b62b-255502550010-m0.avro  (7.3 KB)\n",
      "    + metadata/9c6fc013-6834-45c5-b62b-255502550010-m1.avro  (7.1 KB)\n",
      "    + metadata/snap-2592521105705844696-1-9c6fc013-6834-45c5-b62b-255502550010.avro  (4.3 KB)\n",
      "    + metadata/v4.metadata.json  (4.8 KB)\n",
      "\n",
      "요약: +10 추가, -0 삭제, ~0 변경\n"
     ]
    }
   ],
   "source": [
    "before_update = snapshot_tree(TABLE_PATH)\n",
    "\n",
    "# UPDATE 실행\n",
    "spark.sql(f\"UPDATE {TABLE_NAME} SET status = 'refunded' WHERE status = 'pending'\")\n",
    "\n",
    "after_update = snapshot_tree(TABLE_PATH)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"UPDATE 후 변경 사항 (MOR):\")\n",
    "print(\"=\" * 60)\n",
    "diff_tree(before_update, after_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9c0d1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPDATE 후 테이블 트리 구조:\n",
      "============================================================\n",
      "├── data/\n",
      "│   ├── order_date_month=2024-01/\n",
      "│   │   ├── 00000-10-d03b1507-b571-4518-83f1-705c9f0bc706-00001-deletes.parquet  (1.6 KB)\n",
      "│   │   ├── 00000-19-99789f11-fdcd-496c-a12d-f419b5431f9d-00001-deletes.parquet  (1.6 KB)\n",
      "│   │   ├── 00000-19-99789f11-fdcd-496c-a12d-f419b5431f9d-00001.parquet  (2.0 KB)\n",
      "│   │   └── 00000-5-4985e73d-07bb-4f48-8126-9e556bdcdbe9-00001.parquet  (2.5 KB)\n",
      "│   ├── order_date_month=2024-02/\n",
      "│   │   ├── 00000-10-d03b1507-b571-4518-83f1-705c9f0bc706-00002-deletes.parquet  (1.6 KB)\n",
      "│   │   ├── 00000-19-99789f11-fdcd-496c-a12d-f419b5431f9d-00002-deletes.parquet  (1.6 KB)\n",
      "│   │   ├── 00000-19-99789f11-fdcd-496c-a12d-f419b5431f9d-00002.parquet  (1.9 KB)\n",
      "│   │   └── 00000-5-4985e73d-07bb-4f48-8126-9e556bdcdbe9-00002.parquet  (2.5 KB)\n",
      "│   └── order_date_month=2024-03/\n",
      "│       ├── 00000-10-d03b1507-b571-4518-83f1-705c9f0bc706-00003-deletes.parquet  (1.6 KB)\n",
      "│       ├── 00000-19-99789f11-fdcd-496c-a12d-f419b5431f9d-00003-deletes.parquet  (1.6 KB)\n",
      "│       ├── 00000-19-99789f11-fdcd-496c-a12d-f419b5431f9d-00003.parquet  (1.9 KB)\n",
      "│       └── 00000-5-4985e73d-07bb-4f48-8126-9e556bdcdbe9-00003.parquet  (2.4 KB)\n",
      "└── metadata/\n",
      "    ├── 05976910-09f0-4bb2-837b-764e56139454-m0.avro  (7.3 KB)\n",
      "    ├── 9c6fc013-6834-45c5-b62b-255502550010-m0.avro  (7.3 KB)\n",
      "    ├── 9c6fc013-6834-45c5-b62b-255502550010-m1.avro  (7.1 KB)\n",
      "    ├── e862486f-fb23-4905-8e63-2a49c647f358-m0.avro  (7.2 KB)\n",
      "    ├── snap-1474401465633457598-1-05976910-09f0-4bb2-837b-764e56139454.avro  (4.2 KB)\n",
      "    ├── snap-2592521105705844696-1-9c6fc013-6834-45c5-b62b-255502550010.avro  (4.3 KB)\n",
      "    ├── snap-8107597961677446822-1-e862486f-fb23-4905-8e63-2a49c647f358.avro  (4.3 KB)\n",
      "    ├── v1.metadata.json  (1.6 KB)\n",
      "    ├── v2.metadata.json  (2.7 KB)\n",
      "    ├── v3.metadata.json  (3.7 KB)\n",
      "    ├── v4.metadata.json  (4.8 KB)\n",
      "    └── version-hint.text  (1 B)\n",
      "\n",
      "파일 수 (parquet): 12\n",
      "총 크기: 79,212 bytes\n"
     ]
    }
   ],
   "source": [
    "print(\"UPDATE 후 테이블 트리 구조:\")\n",
    "print(\"=\" * 60)\n",
    "show_tree(TABLE_PATH)\n",
    "\n",
    "print(f\"\\n파일 수 (parquet): {count_files(TABLE_PATH)}\")\n",
    "print(f\"총 크기: {total_size(TABLE_PATH):,} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "w0wwzuuo2m",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v4.metadata.json  (operation: overwrite)\n",
      "│\n",
      "└─▶ snap-2592521105705844696-1-9c6fc013-6834-45c5-b62b-255502550010.avro  [Manifest List]\n",
      "    ├─▶ 9c6fc013-6834-45c5-b62b-255502550010-m0.avro  [Manifest — DATA: 3 ADDED]\n",
      "        │   ├── data/warehouse/lab/mor_orders/data/order_date_month=2024-01/00000-19-99789f11-fdcd-496c-a12d-f419b5431f9d-00001.parquet  (7행, ADDED)\n",
      "        │   ├── data/warehouse/lab/mor_orders/data/order_date_month=2024-02/00000-19-99789f11-fdcd-496c-a12d-f419b5431f9d-00002.parquet  (7행, ADDED)\n",
      "        │   └── data/warehouse/lab/mor_orders/data/order_date_month=2024-03/00000-19-99789f11-fdcd-496c-a12d-f419b5431f9d-00003.parquet  (5행, ADDED)\n",
      "    ├─▶ 05976910-09f0-4bb2-837b-764e56139454-m0.avro  [Manifest — DATA: 3 ADDED]\n",
      "        │   ├── data/warehouse/lab/mor_orders/data/order_date_month=2024-01/00000-5-4985e73d-07bb-4f48-8126-9e556bdcdbe9-00001.parquet  (38행, ADDED)\n",
      "        │   ├── data/warehouse/lab/mor_orders/data/order_date_month=2024-02/00000-5-4985e73d-07bb-4f48-8126-9e556bdcdbe9-00002.parquet  (32행, ADDED)\n",
      "        │   └── data/warehouse/lab/mor_orders/data/order_date_month=2024-03/00000-5-4985e73d-07bb-4f48-8126-9e556bdcdbe9-00003.parquet  (30행, ADDED)\n",
      "    ├─▶ 9c6fc013-6834-45c5-b62b-255502550010-m1.avro  [Manifest — DELETES: empty]\n",
      "        │   ├── data/warehouse/lab/mor_orders/data/order_date_month=2024-01/00000-19-99789f11-fdcd-496c-a12d-f419b5431f9d-00001-deletes.parquet  (7행, ADDED)  [DELETE FILE]\n",
      "        │   ├── data/warehouse/lab/mor_orders/data/order_date_month=2024-02/00000-19-99789f11-fdcd-496c-a12d-f419b5431f9d-00002-deletes.parquet  (7행, ADDED)  [DELETE FILE]\n",
      "        │   └── data/warehouse/lab/mor_orders/data/order_date_month=2024-03/00000-19-99789f11-fdcd-496c-a12d-f419b5431f9d-00003-deletes.parquet  (5행, ADDED)  [DELETE FILE]\n",
      "    └─▶ e862486f-fb23-4905-8e63-2a49c647f358-m0.avro  [Manifest — DELETES: empty]\n",
      "            ├── data/warehouse/lab/mor_orders/data/order_date_month=2024-01/00000-10-d03b1507-b571-4518-83f1-705c9f0bc706-00001-deletes.parquet  (5행, ADDED)  [DELETE FILE]\n",
      "            ├── data/warehouse/lab/mor_orders/data/order_date_month=2024-02/00000-10-d03b1507-b571-4518-83f1-705c9f0bc706-00002-deletes.parquet  (6행, ADDED)  [DELETE FILE]\n",
      "            └── data/warehouse/lab/mor_orders/data/order_date_month=2024-03/00000-10-d03b1507-b571-4518-83f1-705c9f0bc706-00003-deletes.parquet  (7행, ADDED)  [DELETE FILE]\n",
      "\n",
      "→ MOR UPDATE = Delete File(기존 행 위치) + 새 데이터 파일(변경된 행)\n",
      "  기존 데이터 파일은 여전히 EXISTING — 재작성 없음!\n"
     ]
    }
   ],
   "source": [
    "# UPDATE 후 계층 — Delete File + 새 데이터 파일이 추가됨\n",
    "show_metadata_hierarchy(TABLE_PATH)\n",
    "\n",
    "print(\"\\n→ MOR UPDATE = Delete File(기존 행 위치) + 새 데이터 파일(변경된 행)\")\n",
    "print(\"  기존 데이터 파일은 여전히 EXISTING — 재작성 없음!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d1e2f3",
   "metadata": {},
   "source": [
    "### 관찰 포인트 — UPDATE (MOR)\n",
    "\n",
    "- **Delete File**이 추가 생성되었습니다 (기존 행의 위치 기록)\n",
    "- **새 데이터 파일**도 생성되었습니다 (변경된 행만 포함)\n",
    "- 기존 데이터 파일은 **역시 그대로** 유지됩니다\n",
    "- 즉, UPDATE = Delete File + 새 데이터 파일 조합"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e2f3a4",
   "metadata": {},
   "source": [
    "---\n",
    "## Delete File 상세 분석\n",
    "\n",
    "MOR의 핵심인 Delete File을 자세히 들여다봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2f3a4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 파일 목록 (데이터 + Delete):\n",
      "+-------+-----------------+-------------------------------------------------------------------------------------------------------------------------------+------------+------------------+\n",
      "|content|file_type        |file_path                                                                                                                      |record_count|file_size_in_bytes|\n",
      "+-------+-----------------+-------------------------------------------------------------------------------------------------------------------------------+------------+------------------+\n",
      "|0      |DATA             |data/warehouse/lab/mor_orders/data/order_date_month=2024-01/00000-19-99789f11-fdcd-496c-a12d-f419b5431f9d-00001.parquet        |7           |2038              |\n",
      "|0      |DATA             |data/warehouse/lab/mor_orders/data/order_date_month=2024-01/00000-5-4985e73d-07bb-4f48-8126-9e556bdcdbe9-00001.parquet         |38          |2547              |\n",
      "|0      |DATA             |data/warehouse/lab/mor_orders/data/order_date_month=2024-02/00000-19-99789f11-fdcd-496c-a12d-f419b5431f9d-00002.parquet        |7           |1992              |\n",
      "|0      |DATA             |data/warehouse/lab/mor_orders/data/order_date_month=2024-02/00000-5-4985e73d-07bb-4f48-8126-9e556bdcdbe9-00002.parquet         |32          |2521              |\n",
      "|0      |DATA             |data/warehouse/lab/mor_orders/data/order_date_month=2024-03/00000-19-99789f11-fdcd-496c-a12d-f419b5431f9d-00003.parquet        |5           |1954              |\n",
      "|0      |DATA             |data/warehouse/lab/mor_orders/data/order_date_month=2024-03/00000-5-4985e73d-07bb-4f48-8126-9e556bdcdbe9-00003.parquet         |30          |2462              |\n",
      "|1      |POSITIONAL DELETE|data/warehouse/lab/mor_orders/data/order_date_month=2024-01/00000-10-d03b1507-b571-4518-83f1-705c9f0bc706-00001-deletes.parquet|5           |1662              |\n",
      "|1      |POSITIONAL DELETE|data/warehouse/lab/mor_orders/data/order_date_month=2024-01/00000-19-99789f11-fdcd-496c-a12d-f419b5431f9d-00001-deletes.parquet|7           |1667              |\n",
      "|1      |POSITIONAL DELETE|data/warehouse/lab/mor_orders/data/order_date_month=2024-02/00000-10-d03b1507-b571-4518-83f1-705c9f0bc706-00002-deletes.parquet|6           |1664              |\n",
      "|1      |POSITIONAL DELETE|data/warehouse/lab/mor_orders/data/order_date_month=2024-02/00000-19-99789f11-fdcd-496c-a12d-f419b5431f9d-00002-deletes.parquet|7           |1666              |\n",
      "|1      |POSITIONAL DELETE|data/warehouse/lab/mor_orders/data/order_date_month=2024-03/00000-10-d03b1507-b571-4518-83f1-705c9f0bc706-00003-deletes.parquet|7           |1668              |\n",
      "|1      |POSITIONAL DELETE|data/warehouse/lab/mor_orders/data/order_date_month=2024-03/00000-19-99789f11-fdcd-496c-a12d-f419b5431f9d-00003-deletes.parquet|5           |1663              |\n",
      "+-------+-----------------+-------------------------------------------------------------------------------------------------------------------------------+------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# files 메타데이터 테이블에서 Delete File 확인\n",
    "# content 컬럼: 0=데이터, 1=positional deletes, 2=equality deletes\n",
    "print(\"전체 파일 목록 (데이터 + Delete):\")\n",
    "spark.sql(f\"\"\"\n",
    "    SELECT \n",
    "        content,\n",
    "        CASE content \n",
    "            WHEN 0 THEN 'DATA'\n",
    "            WHEN 1 THEN 'POSITIONAL DELETE'\n",
    "            WHEN 2 THEN 'EQUALITY DELETE'\n",
    "        END as file_type,\n",
    "        regexp_replace(file_path, '^file:.*?/(data/)', '$1') as file_path,\n",
    "        record_count,\n",
    "        file_size_in_bytes\n",
    "    FROM {TABLE_NAME}.files\n",
    "    ORDER BY content, file_path\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3a4b5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delete File 상세:\n",
      "+-----------------+-------------------------------------------------------------------------------------------------------------------------------+------------+------------------+\n",
      "|file_type        |file_path                                                                                                                      |record_count|file_size_in_bytes|\n",
      "+-----------------+-------------------------------------------------------------------------------------------------------------------------------+------------+------------------+\n",
      "|POSITIONAL DELETE|data/warehouse/lab/mor_orders/data/order_date_month=2024-01/00000-19-99789f11-fdcd-496c-a12d-f419b5431f9d-00001-deletes.parquet|7           |1667              |\n",
      "|POSITIONAL DELETE|data/warehouse/lab/mor_orders/data/order_date_month=2024-02/00000-19-99789f11-fdcd-496c-a12d-f419b5431f9d-00002-deletes.parquet|7           |1666              |\n",
      "|POSITIONAL DELETE|data/warehouse/lab/mor_orders/data/order_date_month=2024-03/00000-19-99789f11-fdcd-496c-a12d-f419b5431f9d-00003-deletes.parquet|5           |1663              |\n",
      "|POSITIONAL DELETE|data/warehouse/lab/mor_orders/data/order_date_month=2024-01/00000-10-d03b1507-b571-4518-83f1-705c9f0bc706-00001-deletes.parquet|5           |1662              |\n",
      "|POSITIONAL DELETE|data/warehouse/lab/mor_orders/data/order_date_month=2024-02/00000-10-d03b1507-b571-4518-83f1-705c9f0bc706-00002-deletes.parquet|6           |1664              |\n",
      "|POSITIONAL DELETE|data/warehouse/lab/mor_orders/data/order_date_month=2024-03/00000-10-d03b1507-b571-4518-83f1-705c9f0bc706-00003-deletes.parquet|7           |1668              |\n",
      "+-----------------+-------------------------------------------------------------------------------------------------------------------------------+------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Delete File만 필터링\n",
    "print(\"Delete File 상세:\")\n",
    "delete_files_df = spark.sql(f\"\"\"\n",
    "    SELECT \n",
    "        CASE content \n",
    "            WHEN 0 THEN 'DATA'\n",
    "            WHEN 1 THEN 'POSITIONAL DELETE'\n",
    "            WHEN 2 THEN 'EQUALITY DELETE'\n",
    "        END as file_type,\n",
    "        file_path,\n",
    "        record_count,\n",
    "        file_size_in_bytes\n",
    "    FROM {TABLE_NAME}.files\n",
    "    WHERE content > 0\n",
    "\"\"\")\n",
    "\n",
    "# 경로를 정리하여 표시\n",
    "delete_files_df.selectExpr(\n",
    "    \"file_type\",\n",
    "    \"regexp_replace(file_path, '^file:.*?/(data/)', '$1') as file_path\",\n",
    "    \"record_count\",\n",
    "    \"file_size_in_bytes\"\n",
    ").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a4b5c6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delete File 경로: /home/jovyan/data/warehouse/lab/mor_orders/data/order_date_month=2024-01/00000-19-99789f11-fdcd-496c-a12d-f419b5431f9d-00001-deletes.parquet\n",
      "\n",
      "스키마: file_path: string not null\n",
      "  -- field metadata --\n",
      "  PARQUET:field_id: '2147483546'\n",
      "pos: int64 not null\n",
      "  -- field metadata --\n",
      "  PARQUET:field_id: '2147483545'\n",
      "order_date_month: dictionary<values=string, indices=int32, ordered=0>\n",
      "-- schema metadata --\n",
      "delete-type: 'position'\n",
      "iceberg.schema: '{\"type\":\"struct\",\"schema-id\":0,\"fields\":[{\"id\":214748354' + 231\n",
      "레코드 수: 7\n",
      "\n",
      "내용 (처음 10행):\n",
      "                                                                                                                file_path  \\\n",
      "0  data/warehouse/lab/mor_orders/data/order_date_month=2024-01/00000-5-4985e73d-07bb-4f48-8126-9e556bdcdbe9-00001.parquet   \n",
      "1  data/warehouse/lab/mor_orders/data/order_date_month=2024-01/00000-5-4985e73d-07bb-4f48-8126-9e556bdcdbe9-00001.parquet   \n",
      "2  data/warehouse/lab/mor_orders/data/order_date_month=2024-01/00000-5-4985e73d-07bb-4f48-8126-9e556bdcdbe9-00001.parquet   \n",
      "3  data/warehouse/lab/mor_orders/data/order_date_month=2024-01/00000-5-4985e73d-07bb-4f48-8126-9e556bdcdbe9-00001.parquet   \n",
      "4  data/warehouse/lab/mor_orders/data/order_date_month=2024-01/00000-5-4985e73d-07bb-4f48-8126-9e556bdcdbe9-00001.parquet   \n",
      "5  data/warehouse/lab/mor_orders/data/order_date_month=2024-01/00000-5-4985e73d-07bb-4f48-8126-9e556bdcdbe9-00001.parquet   \n",
      "6  data/warehouse/lab/mor_orders/data/order_date_month=2024-01/00000-5-4985e73d-07bb-4f48-8126-9e556bdcdbe9-00001.parquet   \n",
      "\n",
      "   pos order_date_month  \n",
      "0    1          2024-01  \n",
      "1    4          2024-01  \n",
      "2    8          2024-01  \n",
      "3   14          2024-01  \n",
      "4   25          2024-01  \n",
      "5   27          2024-01  \n",
      "6   28          2024-01  \n"
     ]
    }
   ],
   "source": [
    "# Delete File을 pyarrow로 직접 읽어보기\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "def strip_file_uri(path):\n",
    "    \"\"\"file: URI 스킴을 제거하여 로컬 파일 경로로 변환\"\"\"\n",
    "    return path.replace('file:///', '/').replace('file:/', '/')\n",
    "\n",
    "delete_files = delete_files_df.collect()\n",
    "if delete_files:\n",
    "    local_path = strip_file_uri(delete_files[0]['file_path'])\n",
    "    print(f\"Delete File 경로: {local_path}\\n\")\n",
    "    \n",
    "    try:\n",
    "        table = pq.read_table(local_path)\n",
    "        print(f\"스키마: {table.schema}\")\n",
    "        print(f\"레코드 수: {len(table)}\")\n",
    "        print(f\"\\n내용 (처음 10행):\")\n",
    "        df = table.to_pandas()\n",
    "        # file_path 컬럼의 긴 경로를 정리하여 표시\n",
    "        if 'file_path' in df.columns:\n",
    "            df['file_path'] = df['file_path'].str.replace(\n",
    "                r'^file:.*?/data/', 'data/', regex=True\n",
    "            )\n",
    "        print(df.head(10))\n",
    "    except Exception as e:\n",
    "        print(f\"읽기 실패: {e}\")\n",
    "        print(\"(Delete File 형식이 표준 Parquet과 다를 수 있습니다)\")\n",
    "else:\n",
    "    print(\"Delete File이 없습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c6d7e8",
   "metadata": {},
   "source": [
    "---\n",
    "## Delete File 유형 설명\n",
    "\n",
    "Iceberg에는 두 가지 유형의 Delete File이 있습니다:\n",
    "\n",
    "### 1. Positional Delete (위치 기반 삭제)\n",
    "- **컬럼**: `file_path` + `pos` (행 번호)\n",
    "- **원리**: \"이 파일의 N번째 행을 무시하라\"\n",
    "- **비유**: 영화관 좌석번호로 찾기 — \"3열 5번 좌석의 사람\"\n",
    "- Spark에서 MOR 사용 시 기본적으로 생성되는 유형\n",
    "\n",
    "```\n",
    "Positional Delete File 내용:\n",
    "┌───────────────────────────┬─────┐\n",
    "│ file_path                 │ pos │\n",
    "├───────────────────────────┼─────┤\n",
    "│ data/part-00001.parquet   │  3  │\n",
    "│ data/part-00001.parquet   │  7  │\n",
    "│ data/part-00001.parquet   │ 15  │\n",
    "└───────────────────────────┴─────┘\n",
    "```\n",
    "\n",
    "### 2. Equality Delete (값 기반 삭제)\n",
    "- **컬럼**: 삭제 조건에 해당하는 컬럼값\n",
    "- **원리**: \"이 값과 일치하는 모든 행을 무시하라\"\n",
    "- **비유**: 군중에서 빨간 모자를 쓴 사람 모두 찾기 — \"빨간 모자인 사람\"\n",
    "- Spark에서는 거의 사용되지 않음 (주로 Flink 등에서 활용)\n",
    "\n",
    "```\n",
    "Equality Delete File 내용:\n",
    "┌──────────┐\n",
    "│ order_id │\n",
    "├──────────┤\n",
    "│    42    │\n",
    "│    57    │\n",
    "│    89    │\n",
    "└──────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d7e8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스냅샷 히스토리 확인\n",
    "print(\"전체 스냅샷 히스토리:\")\n",
    "spark.sql(f\"SELECT * FROM {TABLE_NAME}.snapshots\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e8f9a0",
   "metadata": {},
   "source": [
    "---\n",
    "## 정리: MOR(Merge-on-Read) 핵심 요약\n",
    "\n",
    "| 항목 | 설명 |\n",
    "|------|------|\n",
    "| **쓰기 방식** | Delete File에 삭제할 행 위치를 기록, 기존 파일 유지 |\n",
    "| **Delete File** | Positional Delete (file_path + pos) 생성 |\n",
    "| **읽기 성능** | 느림 — 데이터 파일 + Delete File 병합 필요 |\n",
    "| **쓰기 성능** | 빠름 — 파일 전체 재작성 없음 |\n",
    "| **적합한 워크로드** | 쓰기 중심, 업데이트/삭제가 빈번한 경우 |\n",
    "| **멀티 엔진 체크** | 사용하는 엔진이 Delete File을 정확히 읽는지 사전 검증 필수 |\n",
    "\n",
    "> **핵심**: MOR에서는 **Delete File만 추가하고 기존 데이터 파일은 그대로** 유지됩니다.\n",
    "> 읽을 때 데이터 파일과 Delete File을 **병합(merge)**하여 최종 결과를 만듭니다.\n",
    "> 다음 노트북에서 COW와 MOR을 직접 비교해봅니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f9a0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.stop()\n",
    "print(\"Spark 세션 종료\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
