{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "120def1d-9f5a-4c79-8dbb-c001d51c7646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Spark + Iceberg ì„¤ì • ì™„ë£Œ!\n",
      "+-------------+\n",
      "|      catalog|\n",
      "+-------------+\n",
      "|         demo|\n",
      "|spark_catalog|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Spark + Iceberg ì„¤ì •\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"IcebergBlogDemo\") \\\n",
    "    .config(\"spark.jars\", \"/home/jovyan/iceberg-spark.jar\") \\\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n",
    "    .config(\"spark.sql.catalog.demo\", \"org.apache.iceberg.spark.SparkCatalog\") \\\n",
    "    .config(\"spark.sql.catalog.demo.type\", \"hadoop\") \\\n",
    "    .config(\"spark.sql.catalog.demo.warehouse\", \"file:///home/jovyan/data/warehouse\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"âœ… Spark + Iceberg ì„¤ì • ì™„ë£Œ!\")\n",
    "\n",
    "# ì¹´íƒˆë¡œê·¸ í™•ì¸\n",
    "spark.sql(\"SHOW CATALOGS\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27a1d57c-b760-404e-ae7d-93346a223434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± ì™„ë£Œ!\n",
      "âœ… í…Œì´ë¸” ìƒì„± ì™„ë£Œ!\n",
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "|     blog|   orders|      false|\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS demo.blog\")\n",
    "print(\"âœ… ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± ì™„ë£Œ!\")\n",
    "\n",
    "# í…Œì´ë¸” ìƒì„±\n",
    "spark.sql(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS demo.blog.orders (\n",
    "        order_id BIGINT,\n",
    "        customer_id BIGINT,\n",
    "        product_name STRING,\n",
    "        order_date DATE,\n",
    "        amount DECIMAL(10,2),\n",
    "        status STRING\n",
    "    ) USING ICEBERG\n",
    "    PARTITIONED BY (order_date)\n",
    "\"\"\")\n",
    "\n",
    "print(\"âœ… í…Œì´ë¸” ìƒì„± ì™„ë£Œ!\")\n",
    "\n",
    "# í™•ì¸\n",
    "spark.sql(\"SHOW TABLES IN demo.blog\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48e80ad2-9d0a-49e4-bfa0-d099052c227f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ² ëœë¤ ë°ì´í„° 100ê°œ ìƒì„± ì¤‘...\n",
      "âœ… ë°ì´í„° ìƒì„± ì™„ë£Œ!\n",
      "ğŸ“Š ì´ ë ˆì½”ë“œ ìˆ˜: 100\n",
      "ğŸ“… ë‚ ì§œ ë²”ìœ„: 2023-01-01 ~ 2023-03-31\n",
      "ğŸ›ï¸ ìƒí’ˆ ì¢…ë¥˜: 20ê°œ\n",
      "ğŸ‘¥ ê³ ê° ìˆ˜: 93ëª…\n",
      "\n",
      "ğŸ“‹ ìƒ˜í”Œ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:\n",
      "   order_id  customer_id product_name  order_date   amount      status\n",
      "0         1          986      HomePod  2023-03-19   353.81   cancelled\n",
      "1         2          165    iPhone 13  2023-02-19   941.02   completed\n",
      "2         3          515    iPhone SE  2023-02-07   538.77   completed\n",
      "3         4          166     iPad Pro  2023-03-02   782.19   cancelled\n",
      "4         5          731    iPhone 13  2023-02-07   957.03   completed\n",
      "5         6          942      AirPods  2023-02-27   237.44     pending\n",
      "6         7          506    iPhone SE  2023-03-14   455.62   completed\n",
      "7         8          364  Pro Display  2023-02-02  5084.19  processing\n",
      "8         9          102  Magic Mouse  2023-02-22    89.64   completed\n",
      "9        10          152  Pro Display  2023-02-19  6660.17     shipped\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ëœë¤ ë°ì´í„° ìƒì„±\n",
    "def generate_sample_data(num_records=100):\n",
    "    # ìƒí’ˆ ëª©ë¡\n",
    "    products = [\n",
    "        'iPhone 14', 'iPhone 14 Pro', 'MacBook Pro', 'MacBook Air', 'iPad Air', \n",
    "        'iPad Pro', 'AirPods', 'AirPods Pro', 'Apple Watch', 'Magic Mouse',\n",
    "        'Magic Keyboard', 'iMac', 'Mac Studio', 'Apple TV', 'HomePod',\n",
    "        'iPhone 13', 'iPhone SE', 'Mac Mini', 'Studio Display', 'Pro Display'\n",
    "    ]\n",
    "    \n",
    "    # ê°€ê²© ë§¤í•‘\n",
    "    prices = {\n",
    "        'iPhone 14': 999.99, 'iPhone 14 Pro': 1199.99, 'MacBook Pro': 1999.99,\n",
    "        'MacBook Air': 1299.99, 'iPad Air': 649.99, 'iPad Pro': 899.99,\n",
    "        'AirPods': 199.99, 'AirPods Pro': 299.99, 'Apple Watch': 399.99,\n",
    "        'Magic Mouse': 99.99, 'Magic Keyboard': 199.99, 'iMac': 1499.99,\n",
    "        'Mac Studio': 2199.99, 'Apple TV': 149.99, 'HomePod': 349.99,\n",
    "        'iPhone 13': 799.99, 'iPhone SE': 449.99, 'Mac Mini': 799.99,\n",
    "        'Studio Display': 1799.99, 'Pro Display': 5999.99\n",
    "    }\n",
    "    \n",
    "    # ìƒíƒœ ëª©ë¡\n",
    "    statuses = ['completed', 'pending', 'shipped', 'cancelled', 'processing']\n",
    "    \n",
    "    # ë‚ ì§œ ë²”ìœ„ (3ê°œì›”)\n",
    "    start_date = datetime(2023, 1, 1)\n",
    "    end_date = datetime(2023, 3, 31)\n",
    "    \n",
    "    data = []\n",
    "    for i in range(1, num_records + 1):\n",
    "        # ëœë¤ ë‚ ì§œ ìƒì„±\n",
    "        random_days = random.randint(0, (end_date - start_date).days)\n",
    "        order_date = start_date + timedelta(days=random_days)\n",
    "        \n",
    "        # ëœë¤ ìƒí’ˆ\n",
    "        product = random.choice(products)\n",
    "        base_price = prices[product]\n",
    "        \n",
    "        # ê°€ê²©ì— ì•½ê°„ì˜ ë³€ë™ ì¶”ê°€ (í• ì¸/í• ì¦)\n",
    "        price_variation = random.uniform(0.8, 1.2)\n",
    "        final_price = round(base_price * price_variation, 2)\n",
    "        \n",
    "        data.append({\n",
    "            'order_id': i,\n",
    "            'customer_id': random.randint(100, 999),\n",
    "            'product_name': product,\n",
    "            'order_date': order_date.strftime('%Y-%m-%d'),\n",
    "            'amount': final_price,\n",
    "            'status': random.choice(statuses)\n",
    "        })\n",
    "    \n",
    "    return data\n",
    "\n",
    "# 100ê°œ ë°ì´í„° ìƒì„±\n",
    "print(\"ğŸ² ëœë¤ ë°ì´í„° 100ê°œ ìƒì„± ì¤‘...\")\n",
    "sample_data = generate_sample_data(100)\n",
    "\n",
    "# Pandas DataFrame ìƒì„±\n",
    "df_pandas = pd.DataFrame(sample_data)\n",
    "\n",
    "print(\"âœ… ë°ì´í„° ìƒì„± ì™„ë£Œ!\")\n",
    "print(f\"ğŸ“Š ì´ ë ˆì½”ë“œ ìˆ˜: {len(df_pandas)}\")\n",
    "print(f\"ğŸ“… ë‚ ì§œ ë²”ìœ„: {df_pandas['order_date'].min()} ~ {df_pandas['order_date'].max()}\")\n",
    "print(f\"ğŸ›ï¸ ìƒí’ˆ ì¢…ë¥˜: {df_pandas['product_name'].nunique()}ê°œ\")\n",
    "print(f\"ğŸ‘¥ ê³ ê° ìˆ˜: {df_pandas['customer_id'].nunique()}ëª…\")\n",
    "\n",
    "# ìƒ˜í”Œ ë¯¸ë¦¬ë³´ê¸°\n",
    "print(\"\\nğŸ“‹ ìƒ˜í”Œ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:\")\n",
    "print(df_pandas.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6e8b103-7af2-41b2-919a-64fb5e8883ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Spark DataFrame ìŠ¤í‚¤ë§ˆ:\n",
      "root\n",
      " |-- order_id: long (nullable = true)\n",
      " |-- customer_id: long (nullable = true)\n",
      " |-- product_name: string (nullable = true)\n",
      " |-- order_date: date (nullable = true)\n",
      " |-- amount: double (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      "\n",
      "âœ… 100ê°œ ë°ì´í„° ì‚½ì… ì™„ë£Œ!\n",
      "\n",
      "ğŸ“ˆ ì‚½ì… ê²°ê³¼:\n",
      "+------------+\n",
      "|total_orders|\n",
      "+------------+\n",
      "|         100|\n",
      "+------------+\n",
      "\n",
      "+-------+-----------+------------+\n",
      "|  month|order_count|total_amount|\n",
      "+-------+-----------+------------+\n",
      "|2023-01|         27|    28530.90|\n",
      "|2023-02|         27|    39775.69|\n",
      "|2023-03|         46|    46657.86|\n",
      "+-------+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Spark DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "df_spark = spark.createDataFrame(df_pandas)\n",
    "\n",
    "# ë°ì´í„° íƒ€ì… ë³€í™˜\n",
    "df_spark = df_spark.withColumn(\"order_date\", col(\"order_date\").cast(\"date\"))\n",
    "\n",
    "print(\"ğŸ“Š Spark DataFrame ìŠ¤í‚¤ë§ˆ:\")\n",
    "df_spark.printSchema()\n",
    "\n",
    "# ê¸°ì¡´ ë°ì´í„° ì‚­ì œ (í•„ìš”ì‹œ)\n",
    "spark.sql(\"DELETE FROM demo.blog.orders\")\n",
    "\n",
    "# ìƒˆ ë°ì´í„° ì‚½ì…\n",
    "df_spark.write \\\n",
    "    .format(\"iceberg\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .saveAsTable(\"demo.blog.orders\")\n",
    "\n",
    "print(\"âœ… 100ê°œ ë°ì´í„° ì‚½ì… ì™„ë£Œ!\")\n",
    "\n",
    "# ê²°ê³¼ í™•ì¸\n",
    "print(\"\\nğŸ“ˆ ì‚½ì… ê²°ê³¼:\")\n",
    "spark.sql(\"SELECT COUNT(*) as total_orders FROM demo.blog.orders\").show()\n",
    "\n",
    "# ì›”ë³„ ë¶„í¬ í™•ì¸\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        DATE_FORMAT(order_date, 'yyyy-MM') as month,\n",
    "        COUNT(*) as order_count,\n",
    "        ROUND(SUM(amount), 2) as total_amount\n",
    "    FROM demo.blog.orders \n",
    "    GROUP BY DATE_FORMAT(order_date, 'yyyy-MM')\n",
    "    ORDER BY month\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd595e4b-ca25-4ed1-89e6-b0a42c8c1544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ 100ê°œ ë°ì´í„° ì‚½ì… í›„ íŒŒì¼ êµ¬ì¡°:\n",
      "â””â”€â”€ blog\n",
      "    â””â”€â”€ orders\n",
      "        â”œâ”€â”€ data\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-01-01\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-01-08\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-01-09\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-01-11\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-01-14\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-01-15\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-01-16\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-01-17\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-01-18\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-01-19\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-01-20\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-01-21\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-01-22\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-01-24\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-01-25\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-01-26\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-01-27\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-01-28\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-01-29\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-01-30\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-01-31\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-02-01\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-02-02\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-02-04\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-02-06\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-02-07\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-02-08\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-02-09\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-02-10\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-02-11\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-02-12\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-02-15\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-02-17\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-02-19\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-02-21\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-02-22\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-02-23\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-02-26\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-02-27\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-03-01\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-03-02\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-03-04\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-03-05\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-03-06\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-03-07\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-03-08\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-03-09\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-03-12\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-03-14\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-03-16\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-03-17\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-03-18\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-03-19\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-03-20\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-03-21\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-03-23\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-03-25\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-03-26\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-03-27\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-03-29\n",
      "        â”‚   â”œâ”€â”€ order_date=2023-03-30\n",
      "        â”‚   â””â”€â”€ order_date=2023-03-31\n",
      "        â””â”€â”€ metadata\n",
      "            â”œâ”€â”€ 195d7f08-e6a8-4894-b87f-0ce600273072-m0.avro (7.3 KB)\n",
      "            â”œâ”€â”€ 89f5ff69-005a-454c-bc9f-fea036b65e18-m0.avro (7.3 KB)\n",
      "            â”œâ”€â”€ e3ddb96d-a3c5-4c3f-8b8e-629803f98ae9-m0.avro (9.7 KB)\n",
      "            â”œâ”€â”€ snap-3619668723289457015-1-89f5ff69-005a-454c-bc9f-fea036b65e18.avro (4.2 KB)\n",
      "            â”œâ”€â”€ snap-6172479582435102822-1-e3ddb96d-a3c5-4c3f-8b8e-629803f98ae9.avro (4.2 KB)\n",
      "            â”œâ”€â”€ snap-7748433326136419833-1-195d7f08-e6a8-4894-b87f-0ce600273072.avro (4.2 KB)\n",
      "            â”œâ”€â”€ snap-7751379435523918486-1-0e4581dc-677c-48fc-93da-9c6cbdc0b5d9.avro (4.0 KB)\n",
      "            â”œâ”€â”€ v1.metadata.json (1.5 KB)\n",
      "            â”œâ”€â”€ v2.metadata.json (2.4 KB)\n",
      "            â”œâ”€â”€ v3.metadata.json (3.4 KB)\n",
      "            â”œâ”€â”€ v4.metadata.json (4.4 KB)\n",
      "            â”œâ”€â”€ v5.metadata.json (5.3 KB)\n",
      "            â””â”€â”€ version-hint.text (1 bytes)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def show_detailed_tree(path, prefix=\"\", max_depth=4, current_depth=0):\n",
    "    if current_depth >= max_depth:\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        items = sorted([item for item in os.listdir(path) if not item.startswith('.')])\n",
    "        for i, item in enumerate(items):\n",
    "            item_path = os.path.join(path, item)\n",
    "            is_last = i == len(items) - 1\n",
    "            \n",
    "            # íŒŒì¼ í¬ê¸° ì •ë³´ ì¶”ê°€\n",
    "            size_info = \"\"\n",
    "            if os.path.isfile(item_path):\n",
    "                size = os.path.getsize(item_path)\n",
    "                if size > 1024 * 1024:\n",
    "                    size_info = f\" ({size / 1024 / 1024:.1f} MB)\"\n",
    "                elif size > 1024:\n",
    "                    size_info = f\" ({size / 1024:.1f} KB)\"\n",
    "                else:\n",
    "                    size_info = f\" ({size} bytes)\"\n",
    "            \n",
    "            print(f\"{prefix}{'â””â”€â”€ ' if is_last else 'â”œâ”€â”€ '}{item}{size_info}\")\n",
    "            \n",
    "            if os.path.isdir(item_path):\n",
    "                next_prefix = prefix + (\"    \" if is_last else \"â”‚   \")\n",
    "                show_detailed_tree(item_path, next_prefix, max_depth, current_depth + 1)\n",
    "    except PermissionError:\n",
    "        pass\n",
    "\n",
    "print(\"ğŸ“ 100ê°œ ë°ì´í„° ì‚½ì… í›„ íŒŒì¼ êµ¬ì¡°:\")\n",
    "warehouse_path = \"/home/jovyan/data/warehouse\"\n",
    "show_detailed_tree(warehouse_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb24bf3c-5c6b-4642-8799-7efe6331603d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ›ï¸ ì¸ê¸° ìƒí’ˆ TOP 10:\n",
      "+--------------+-----------+---------+-------------+\n",
      "|  product_name|order_count|avg_price|total_revenue|\n",
      "+--------------+-----------+---------+-------------+\n",
      "|Studio Display|         10|  1925.70|     19256.98|\n",
      "|       HomePod|          9|   344.33|      3098.94|\n",
      "|   MacBook Air|          8|  1283.51|     10268.07|\n",
      "|Magic Keyboard|          6|   213.53|      1281.17|\n",
      "|      Mac Mini|          6|   735.51|      4413.06|\n",
      "|     iPhone SE|          6|   477.67|      2866.03|\n",
      "|       AirPods|          6|   209.44|      1256.64|\n",
      "|     iPhone 13|          6|   868.72|      5212.34|\n",
      "|   Pro Display|          5|  5755.54|     28777.69|\n",
      "|      iPad Pro|          5|   881.49|      4407.44|\n",
      "+--------------+-----------+---------+-------------+\n",
      "\n",
      "\n",
      "ğŸ“… ìµœê·¼ 10ì¼ ì£¼ë¬¸ í˜„í™©:\n",
      "+----------+------+-------+\n",
      "|order_date|orders|revenue|\n",
      "+----------+------+-------+\n",
      "|2023-03-31|     2|2618.96|\n",
      "|2023-03-30|     2|1708.35|\n",
      "|2023-03-29|     2|2467.18|\n",
      "|2023-03-27|     3|9165.16|\n",
      "|2023-03-26|     2|1375.61|\n",
      "|2023-03-25|     1| 415.71|\n",
      "|2023-03-23|     1| 652.41|\n",
      "|2023-03-21|     2| 318.97|\n",
      "|2023-03-20|     2| 885.78|\n",
      "|2023-03-19|     5|5077.32|\n",
      "+----------+------+-------+\n",
      "\n",
      "\n",
      "ğŸ—‚ï¸ íŒŒí‹°ì…˜ë³„ ì •ë³´:\n",
      "+---------------+------------+\n",
      "|partition_month|record_count|\n",
      "+---------------+------------+\n",
      "|        2023-01|          27|\n",
      "|        2023-02|          27|\n",
      "|        2023-03|          46|\n",
      "+---------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ìƒìœ„ ìƒí’ˆ ë¶„ì„\n",
    "print(\"ğŸ›ï¸ ì¸ê¸° ìƒí’ˆ TOP 10:\")\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        product_name,\n",
    "        COUNT(*) as order_count,\n",
    "        ROUND(AVG(amount), 2) as avg_price,\n",
    "        ROUND(SUM(amount), 2) as total_revenue\n",
    "    FROM demo.blog.orders \n",
    "    GROUP BY product_name\n",
    "    ORDER BY order_count DESC\n",
    "    LIMIT 10\n",
    "\"\"\").show()\n",
    "\n",
    "# ì¼ë³„ ì£¼ë¬¸ í˜„í™©\n",
    "print(\"\\nğŸ“… ìµœê·¼ 10ì¼ ì£¼ë¬¸ í˜„í™©:\")\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        order_date,\n",
    "        COUNT(*) as orders,\n",
    "        ROUND(SUM(amount), 2) as revenue\n",
    "    FROM demo.blog.orders \n",
    "    GROUP BY order_date\n",
    "    ORDER BY order_date DESC\n",
    "    LIMIT 10\n",
    "\"\"\").show()\n",
    "\n",
    "# íŒŒí‹°ì…˜ë³„ íŒŒì¼ ì •ë³´\n",
    "print(\"\\nğŸ—‚ï¸ íŒŒí‹°ì…˜ë³„ ì •ë³´:\")\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        DATE_FORMAT(order_date, 'yyyy-MM') as partition_month,\n",
    "        COUNT(*) as record_count\n",
    "    FROM demo.blog.orders \n",
    "    GROUP BY DATE_FORMAT(order_date, 'yyyy-MM')\n",
    "    ORDER BY partition_month\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8187bb44-7a33-40db-a21f-492d7b23ffe7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
