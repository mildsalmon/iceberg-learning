{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1000001",
   "metadata": {},
   "source": [
    "# Table Maintenance — 스냅샷 만료, 고아 파일 정리, Manifest 재작성\n",
    "\n",
    "이 노트북에서는 Iceberg 테이블의 **유지보수 작업**을 실습합니다.\n",
    "\n",
    "Iceberg는 Time Travel을 위해 과거 스냅샷과 데이터 파일을 보관하지만, 무한히 쌓이면 스토리지 비용과 메타데이터 크기가 증가합니다. 주기적으로 정리해야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000002",
   "metadata": {},
   "source": [
    "## 3가지 유지보수 작업\n",
    "\n",
    "| 작업 | 대상 | 효과 |\n",
    "|------|------|------|\n",
    "| **Expire Snapshots** | 오래된 스냅샷 | 스냅샷 메타데이터 + 그 스냅샷만 참조하던 데이터 파일 삭제 |\n",
    "| **Remove Orphan Files** | 어떤 스냅샷도 참조하지 않는 파일 | 실패한 작업의 잔해(고아 파일) 삭제 |\n",
    "| **Rewrite Manifests** | manifest 파일 | 작은 manifest들을 병합하여 쿼리 계획 최적화 |\n",
    "\n",
    "### 권장 실행 순서\n",
    "\n",
    "```\n",
    "1. Compaction (rewrite_data_files)  — 데이터 파일 정리\n",
    "2. Expire Snapshots                — 오래된 스냅샷 제거\n",
    "3. Remove Orphan Files             — 잔여 파일 정리\n",
    "```\n",
    "\n",
    "> 이 순서가 중요합니다: Compaction이 새 파일을 생성하므로, 이후에 Expire Snapshots로 이전 파일을 정리하고, 마지막에 Orphan Files로 잔여물을 청소합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000003",
   "metadata": {},
   "source": [
    "## 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1000004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import time\n",
    "import json\n",
    "import glob as glob_mod\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from utils.spark_setup import create_spark_session\n",
    "from utils.data_generator import generate_orders, to_spark_df\n",
    "from utils.file_explorer import show_tree, snapshot_tree, diff_tree, count_files, total_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1000005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark + Iceberg 세션 준비 완료 (warehouse: file:///home/jovyan/data/warehouse)\n"
     ]
    }
   ],
   "source": [
    "spark = create_spark_session()\n",
    "\n",
    "TABLE_NAME = \"demo.lab.maintenance_orders\"\n",
    "TABLE_PATH = \"/home/jovyan/data/warehouse/lab/maintenance_orders\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000006",
   "metadata": {},
   "source": [
    "---\n",
    "## 준비: 여러 스냅샷이 쌓인 테이블 만들기\n",
    "\n",
    "유지보수의 효과를 관찰하기 위해, 여러 번의 INSERT/UPDATE/DELETE로 다수의 스냅샷을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1000007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 1/5 완료 (50건 삽입)\n",
      "배치 2/5 완료 (50건 삽입)\n",
      "배치 3/5 완료 (50건 삽입)\n",
      "배치 4/5 완료 (50건 삽입)\n",
      "배치 5/5 완료 (50건 삽입)\n",
      "UPDATE 완료: pending → shipped\n",
      "DELETE 완료: cancelled 삭제\n",
      "\n",
      "최종 레코드 수: 214\n"
     ]
    }
   ],
   "source": [
    "spark.sql(f\"DROP TABLE IF EXISTS {TABLE_NAME}\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE {TABLE_NAME} (\n",
    "    order_id BIGINT,\n",
    "    customer_id BIGINT,\n",
    "    product_name STRING,\n",
    "    order_date DATE,\n",
    "    amount DECIMAL(10,2),\n",
    "    status STRING\n",
    ") USING ICEBERG\n",
    "PARTITIONED BY (months(order_date))\n",
    "\"\"\")\n",
    "\n",
    "# 여러 배치로 데이터 삽입 → 스냅샷 누적\n",
    "for i in range(5):\n",
    "    orders = generate_orders(num_records=50, seed=i, id_offset=i*50+1)\n",
    "    df = to_spark_df(spark, orders)\n",
    "    df.writeTo(TABLE_NAME).append()\n",
    "    print(f\"배치 {i+1}/5 완료 (50건 삽입)\")\n",
    "\n",
    "# UPDATE로 추가 스냅샷 생성\n",
    "spark.sql(f\"UPDATE {TABLE_NAME} SET status = 'shipped' WHERE status = 'pending'\")\n",
    "print(\"UPDATE 완료: pending → shipped\")\n",
    "\n",
    "# DELETE로 추가 스냅샷 생성\n",
    "spark.sql(f\"DELETE FROM {TABLE_NAME} WHERE status = 'cancelled'\")\n",
    "print(\"DELETE 완료: cancelled 삭제\")\n",
    "\n",
    "total_records = spark.sql(f\"SELECT COUNT(*) FROM {TABLE_NAME}\").collect()[0][0]\n",
    "print(f\"\\n최종 레코드 수: {total_records}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1000008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 스냅샷 히스토리 ===\n",
      "+-------------------+-----------------------+---------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|snapshot_id        |committed_at           |operation|summary                                                                                                                                                                                                                                                                                                                                                                            |\n",
      "+-------------------+-----------------------+---------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|7790559439042743626|2026-02-16 01:31:36.087|append   |{spark.app.id -> local-1771205490031, added-data-files -> 3, added-records -> 50, added-files-size -> 6829, changed-partition-count -> 3, total-records -> 50, total-files-size -> 6829, total-data-files -> 3, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}                                                                                 |\n",
      "|1755617737309160667|2026-02-16 01:31:36.774|append   |{spark.app.id -> local-1771205490031, added-data-files -> 3, added-records -> 50, added-files-size -> 6888, changed-partition-count -> 3, total-records -> 100, total-files-size -> 13717, total-data-files -> 6, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}                                                                               |\n",
      "|4507459426958292902|2026-02-16 01:31:37.232|append   |{spark.app.id -> local-1771205490031, added-data-files -> 3, added-records -> 50, added-files-size -> 6865, changed-partition-count -> 3, total-records -> 150, total-files-size -> 20582, total-data-files -> 9, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}                                                                               |\n",
      "|7817925038715658925|2026-02-16 01:31:37.839|append   |{spark.app.id -> local-1771205490031, added-data-files -> 3, added-records -> 50, added-files-size -> 6833, changed-partition-count -> 3, total-records -> 200, total-files-size -> 27415, total-data-files -> 12, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}                                                                              |\n",
      "|7959743550447581514|2026-02-16 01:31:38.318|append   |{spark.app.id -> local-1771205490031, added-data-files -> 3, added-records -> 50, added-files-size -> 6882, changed-partition-count -> 3, total-records -> 250, total-files-size -> 34297, total-data-files -> 15, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}                                                                              |\n",
      "|5205081193672702338|2026-02-16 01:31:39.508|overwrite|{spark.app.id -> local-1771205490031, added-data-files -> 3, deleted-data-files -> 15, added-records -> 250, deleted-records -> 250, added-files-size -> 8685, removed-files-size -> 34297, changed-partition-count -> 3, total-records -> 250, total-files-size -> 8685, total-data-files -> 3, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}|\n",
      "|6012371302795639709|2026-02-16 01:31:39.946|overwrite|{spark.app.id -> local-1771205490031, added-data-files -> 3, deleted-data-files -> 3, added-records -> 214, deleted-records -> 250, added-files-size -> 8326, removed-files-size -> 8685, changed-partition-count -> 3, total-records -> 214, total-files-size -> 8326, total-data-files -> 3, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}  |\n",
      "+-------------------+-----------------------+---------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 현재 스냅샷 히스토리 확인\n",
    "print(\"=== 스냅샷 히스토리 ===\")\n",
    "spark.sql(f\"\"\"\n",
    "SELECT snapshot_id, committed_at, operation, summary\n",
    "FROM {TABLE_NAME}.snapshots\n",
    "ORDER BY committed_at\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1000009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유지보수 전 파일 구조:\n",
      "============================================================\n",
      "├── data/\n",
      "│   ├── order_date_month=2024-01/\n",
      "│   │   ├── 00000-11-e4fbefe7-e540-4d00-b9ae-0d6bd0427c78-00001.parquet  (2.3 KB)\n",
      "│   │   ├── 00000-17-c01ab0e2-ec20-4329-83a7-81ccb36271c8-00001.parquet  (2.3 KB)\n",
      "│   │   ├── 00000-23-b526cea2-e088-4791-8d7a-8a52edfaca3c-00001.parquet  (2.2 KB)\n",
      "│   │   ├── 00000-29-c308ab1e-7ae9-48d0-bc9c-1c9ef2f28828-00001.parquet  (2.2 KB)\n",
      "│   │   ├── 00000-39-3131023a-84ec-4af4-b510-267eb815f90c-00001.parquet  (2.9 KB)\n",
      "│   │   ├── 00000-42-c30e5d0c-8565-4ace-9fc7-8411932f883a-00001.parquet  (2.8 KB)\n",
      "│   │   └── 00000-5-aa006506-c1c2-4ccf-aa26-6c1fc78265cf-00001.parquet  (2.2 KB)\n",
      "│   ├── order_date_month=2024-02/\n",
      "│   │   ├── 00000-11-e4fbefe7-e540-4d00-b9ae-0d6bd0427c78-00002.parquet  (2.1 KB)\n",
      "│   │   ├── 00000-17-c01ab0e2-ec20-4329-83a7-81ccb36271c8-00002.parquet  (2.3 KB)\n",
      "│   │   ├── 00000-23-b526cea2-e088-4791-8d7a-8a52edfaca3c-00002.parquet  (2.2 KB)\n",
      "│   │   ├── 00000-29-c308ab1e-7ae9-48d0-bc9c-1c9ef2f28828-00002.parquet  (2.3 KB)\n",
      "│   │   ├── 00000-39-3131023a-84ec-4af4-b510-267eb815f90c-00002.parquet  (2.8 KB)\n",
      "│   │   ├── 00000-42-c30e5d0c-8565-4ace-9fc7-8411932f883a-00002.parquet  (2.7 KB)\n",
      "│   │   └── 00000-5-aa006506-c1c2-4ccf-aa26-6c1fc78265cf-00002.parquet  (2.2 KB)\n",
      "│   └── order_date_month=2024-03/\n",
      "│       ├── 00000-11-e4fbefe7-e540-4d00-b9ae-0d6bd0427c78-00003.parquet  (2.3 KB)\n",
      "│       ├── 00000-17-c01ab0e2-ec20-4329-83a7-81ccb36271c8-00003.parquet  (2.2 KB)\n",
      "│       ├── 00000-23-b526cea2-e088-4791-8d7a-8a52edfaca3c-00003.parquet  (2.2 KB)\n",
      "│       ├── 00000-29-c308ab1e-7ae9-48d0-bc9c-1c9ef2f28828-00003.parquet  (2.2 KB)\n",
      "│       ├── 00000-39-3131023a-84ec-4af4-b510-267eb815f90c-00003.parquet  (2.8 KB)\n",
      "│       ├── 00000-42-c30e5d0c-8565-4ace-9fc7-8411932f883a-00003.parquet  (2.7 KB)\n",
      "│       └── 00000-5-aa006506-c1c2-4ccf-aa26-6c1fc78265cf-00003.parquet  (2.3 KB)\n",
      "└── metadata/\n",
      "    ├── 7493155a-587f-4ee0-a0e7-ef8de910b226-m0.avro  (7.3 KB)\n",
      "    ├── 7e57e882-7faa-4163-8a7b-9b2e731b7411-m0.avro  (7.3 KB)\n",
      "    ├── b526bd3d-e3c5-49b2-9ebf-e45faba88a20-m0.avro  (7.3 KB)\n",
      "    ├── b526bd3d-e3c5-49b2-9ebf-e45faba88a20-m1.avro  (7.3 KB)\n",
      "    ├── b526bd3d-e3c5-49b2-9ebf-e45faba88a20-m2.avro  (7.3 KB)\n",
      "    ├── b526bd3d-e3c5-49b2-9ebf-e45faba88a20-m3.avro  (7.3 KB)\n",
      "    ├── b526bd3d-e3c5-49b2-9ebf-e45faba88a20-m4.avro  (7.3 KB)\n",
      "    ├── b526bd3d-e3c5-49b2-9ebf-e45faba88a20-m5.avro  (7.3 KB)\n",
      "    ├── c8d738e9-ca93-413b-a8c1-afccfd3c88f8-m0.avro  (7.3 KB)\n",
      "    ├── c8d738e9-ca93-413b-a8c1-afccfd3c88f8-m1.avro  (7.3 KB)\n",
      "    ├── da546293-6a02-419e-813f-79e8e6a8cff1-m0.avro  (7.3 KB)\n",
      "    ├── e0b4302c-0a82-471b-86e7-6a5df6eb9a01-m0.avro  (7.3 KB)\n",
      "    ├── e7dfce03-a759-4861-96fa-5a892dab034d-m0.avro  (7.3 KB)\n",
      "    ├── snap-1755617737309160667-1-7493155a-587f-4ee0-a0e7-ef8de910b226.avro  (4.3 KB)\n",
      "    ├── snap-4507459426958292902-1-7e57e882-7faa-4163-8a7b-9b2e731b7411.avro  (4.3 KB)\n",
      "    ├── snap-5205081193672702338-1-b526bd3d-e3c5-49b2-9ebf-e45faba88a20.avro  (4.3 KB)\n",
      "    ├── snap-6012371302795639709-1-c8d738e9-ca93-413b-a8c1-afccfd3c88f8.avro  (4.2 KB)\n",
      "    ├── snap-7790559439042743626-1-e7dfce03-a759-4861-96fa-5a892dab034d.avro  (4.2 KB)\n",
      "    ├── snap-7817925038715658925-1-e0b4302c-0a82-471b-86e7-6a5df6eb9a01.avro  (4.3 KB)\n",
      "    ├── snap-7959743550447581514-1-da546293-6a02-419e-813f-79e8e6a8cff1.avro  (4.4 KB)\n",
      "    ├── v1.metadata.json  (1.5 KB)\n",
      "    ├── v2.metadata.json  (2.6 KB)\n",
      "    ├── v3.metadata.json  (3.6 KB)\n",
      "    ├── v4.metadata.json  (4.5 KB)\n",
      "    ├── v5.metadata.json  (5.5 KB)\n",
      "    ├── v6.metadata.json  (6.5 KB)\n",
      "    ├── v7.metadata.json  (7.6 KB)\n",
      "    ├── v8.metadata.json  (8.7 KB)\n",
      "    └── version-hint.text  (1 B)\n",
      "\n",
      "Parquet 파일 수: 21\n",
      "총 크기: 220,445 bytes\n"
     ]
    }
   ],
   "source": [
    "# 현재 파일 상태\n",
    "print(\"유지보수 전 파일 구조:\")\n",
    "print(\"=\" * 60)\n",
    "show_tree(TABLE_PATH, max_depth=3)\n",
    "\n",
    "print(f\"\\nParquet 파일 수: {count_files(TABLE_PATH)}\")\n",
    "print(f\"총 크기: {total_size(TABLE_PATH):,} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000010",
   "metadata": {},
   "source": [
    "---\n",
    "## 실험 1: Expire Snapshots — 오래된 스냅샷 제거\n",
    "\n",
    "`expire_snapshots`는 지정 시간보다 오래된 스냅샷을 삭제합니다.\n",
    "\n",
    "삭제된 스냅샷이 **유일하게 참조하던** 데이터 파일도 함께 삭제됩니다.\n",
    "\n",
    "### 주요 옵션\n",
    "\n",
    "| 옵션 | 설명 |\n",
    "|------|------|\n",
    "| `older_than` | 이 시간보다 오래된 스냅샷 삭제 |\n",
    "| `retain_last` | 최소 N개 스냅샷 유지 (기본값: 1) |\n",
    "\n",
    "> **주의**: 스냅샷을 삭제하면 해당 시점으로 **Time Travel이 불가능**해집니다. 운영 환경에서는 적절한 보존 기간을 설정하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1000011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "만료 전 스냅샷 수: 7\n",
      "만료 전 Parquet 파일 수: 21\n"
     ]
    }
   ],
   "source": [
    "# 스냅샷 만료 전 상태 기록\n",
    "before_snapshots = spark.sql(f\"SELECT * FROM {TABLE_NAME}.snapshots\").collect()\n",
    "before = snapshot_tree(TABLE_PATH)\n",
    "\n",
    "print(f\"만료 전 스냅샷 수: {len(before_snapshots)}\")\n",
    "print(f\"만료 전 Parquet 파일 수: {count_files(TABLE_PATH)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1000012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스냅샷 만료 기준(older_than): 2026-02-16 01:31:40\n",
      "+------------------------+-----------------------------------+-----------------------------------+----------------------------+----------------------------+------------------------------+\n",
      "|deleted_data_files_count|deleted_position_delete_files_count|deleted_equality_delete_files_count|deleted_manifest_files_count|deleted_manifest_lists_count|deleted_statistics_files_count|\n",
      "+------------------------+-----------------------------------+-----------------------------------+----------------------------+----------------------------+------------------------------+\n",
      "|18                      |0                                  |0                                  |11                          |6                           |0                             |\n",
      "+------------------------+-----------------------------------+-----------------------------------+----------------------------+----------------------------+------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Expire Snapshots — 실습을 위해 현재 스냅샷들 중 최근 1개만 유지\n",
    "# retain_last만 지정하면 기본 older_than(보통 now - 5 days) 때문에 방금 만든 스냅샷은 만료되지 않을 수 있음\n",
    "max_committed_at = spark.sql(f\"SELECT MAX(committed_at) AS ts FROM {TABLE_NAME}.snapshots\").collect()[0][\"ts\"]\n",
    "expire_cutoff = (max_committed_at + timedelta(seconds=1)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "print(f\"스냅샷 만료 기준(older_than): {expire_cutoff}\")\n",
    "spark.sql(f\"\"\"\n",
    "CALL demo.system.expire_snapshots(\n",
    "    table => '{TABLE_NAME}',\n",
    "    older_than => TIMESTAMP '{expire_cutoff}',\n",
    "    retain_last => 1\n",
    ")\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1000013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스냅샷 수: 7 → 1\n",
      "Parquet 파일 수: 3\n",
      "\n",
      "파일 변경 사항:\n",
      "\n",
      "[+] 추가된 파일 (1개):\n",
      "    + metadata/v9.metadata.json  (3.7 KB)\n",
      "\n",
      "[-] 삭제된 파일 (35개):\n",
      "    - data/order_date_month=2024-01/00000-11-e4fbefe7-e540-4d00-b9ae-0d6bd0427c78-00001.parquet\n",
      "    - data/order_date_month=2024-01/00000-17-c01ab0e2-ec20-4329-83a7-81ccb36271c8-00001.parquet\n",
      "    - data/order_date_month=2024-01/00000-23-b526cea2-e088-4791-8d7a-8a52edfaca3c-00001.parquet\n",
      "    - data/order_date_month=2024-01/00000-29-c308ab1e-7ae9-48d0-bc9c-1c9ef2f28828-00001.parquet\n",
      "    - data/order_date_month=2024-01/00000-39-3131023a-84ec-4af4-b510-267eb815f90c-00001.parquet\n",
      "    - data/order_date_month=2024-01/00000-5-aa006506-c1c2-4ccf-aa26-6c1fc78265cf-00001.parquet\n",
      "    - data/order_date_month=2024-02/00000-11-e4fbefe7-e540-4d00-b9ae-0d6bd0427c78-00002.parquet\n",
      "    - data/order_date_month=2024-02/00000-17-c01ab0e2-ec20-4329-83a7-81ccb36271c8-00002.parquet\n",
      "    - data/order_date_month=2024-02/00000-23-b526cea2-e088-4791-8d7a-8a52edfaca3c-00002.parquet\n",
      "    - data/order_date_month=2024-02/00000-29-c308ab1e-7ae9-48d0-bc9c-1c9ef2f28828-00002.parquet\n",
      "    - data/order_date_month=2024-02/00000-39-3131023a-84ec-4af4-b510-267eb815f90c-00002.parquet\n",
      "    - data/order_date_month=2024-02/00000-5-aa006506-c1c2-4ccf-aa26-6c1fc78265cf-00002.parquet\n",
      "    - data/order_date_month=2024-03/00000-11-e4fbefe7-e540-4d00-b9ae-0d6bd0427c78-00003.parquet\n",
      "    - data/order_date_month=2024-03/00000-17-c01ab0e2-ec20-4329-83a7-81ccb36271c8-00003.parquet\n",
      "    - data/order_date_month=2024-03/00000-23-b526cea2-e088-4791-8d7a-8a52edfaca3c-00003.parquet\n",
      "    - data/order_date_month=2024-03/00000-29-c308ab1e-7ae9-48d0-bc9c-1c9ef2f28828-00003.parquet\n",
      "    - data/order_date_month=2024-03/00000-39-3131023a-84ec-4af4-b510-267eb815f90c-00003.parquet\n",
      "    - data/order_date_month=2024-03/00000-5-aa006506-c1c2-4ccf-aa26-6c1fc78265cf-00003.parquet\n",
      "    - metadata/7493155a-587f-4ee0-a0e7-ef8de910b226-m0.avro\n",
      "    - metadata/7e57e882-7faa-4163-8a7b-9b2e731b7411-m0.avro\n",
      "    - metadata/b526bd3d-e3c5-49b2-9ebf-e45faba88a20-m0.avro\n",
      "    - metadata/b526bd3d-e3c5-49b2-9ebf-e45faba88a20-m1.avro\n",
      "    - metadata/b526bd3d-e3c5-49b2-9ebf-e45faba88a20-m2.avro\n",
      "    - metadata/b526bd3d-e3c5-49b2-9ebf-e45faba88a20-m3.avro\n",
      "    - metadata/b526bd3d-e3c5-49b2-9ebf-e45faba88a20-m4.avro\n",
      "    - metadata/b526bd3d-e3c5-49b2-9ebf-e45faba88a20-m5.avro\n",
      "    - metadata/da546293-6a02-419e-813f-79e8e6a8cff1-m0.avro\n",
      "    - metadata/e0b4302c-0a82-471b-86e7-6a5df6eb9a01-m0.avro\n",
      "    - metadata/e7dfce03-a759-4861-96fa-5a892dab034d-m0.avro\n",
      "    - metadata/snap-1755617737309160667-1-7493155a-587f-4ee0-a0e7-ef8de910b226.avro\n",
      "    - metadata/snap-4507459426958292902-1-7e57e882-7faa-4163-8a7b-9b2e731b7411.avro\n",
      "    - metadata/snap-5205081193672702338-1-b526bd3d-e3c5-49b2-9ebf-e45faba88a20.avro\n",
      "    - metadata/snap-7790559439042743626-1-e7dfce03-a759-4861-96fa-5a892dab034d.avro\n",
      "    - metadata/snap-7817925038715658925-1-e0b4302c-0a82-471b-86e7-6a5df6eb9a01.avro\n",
      "    - metadata/snap-7959743550447581514-1-da546293-6a02-419e-813f-79e8e6a8cff1.avro\n",
      "\n",
      "요약: +1 추가, -35 삭제, ~0 변경\n"
     ]
    }
   ],
   "source": [
    "# 만료 후 상태 확인\n",
    "after_snapshots = spark.sql(f\"SELECT * FROM {TABLE_NAME}.snapshots\").collect()\n",
    "after = snapshot_tree(TABLE_PATH)\n",
    "\n",
    "print(f\"스냅샷 수: {len(before_snapshots)} → {len(after_snapshots)}\")\n",
    "print(f\"Parquet 파일 수: {count_files(TABLE_PATH)}\")\n",
    "\n",
    "print(\"\\n파일 변경 사항:\")\n",
    "diff_tree(before, after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1000014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 만료 후 스냅샷 ===\n",
      "+-------------------+-----------------------+---------+\n",
      "|snapshot_id        |committed_at           |operation|\n",
      "+-------------------+-----------------------+---------+\n",
      "|6012371302795639709|2026-02-16 01:31:39.946|overwrite|\n",
      "+-------------------+-----------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 남은 스냅샷 확인\n",
    "print(\"=== 만료 후 스냅샷 ===\")\n",
    "spark.sql(f\"\"\"\n",
    "SELECT snapshot_id, committed_at, operation\n",
    "FROM {TABLE_NAME}.snapshots\n",
    "ORDER BY committed_at\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000015",
   "metadata": {},
   "source": [
    "### 관찰 포인트 — Expire Snapshots\n",
    "\n",
    "- `older_than` + `retain_last => 1` 조합으로 **최근 1개 스냅샷만 남도록** 만료를 수행했습니다\n",
    "- `retain_last`만 지정하면 기본 `older_than`(환경/설정에 따라 대개 최근 며칠) 때문에 방금 생성된 스냅샷은 남을 수 있습니다\n",
    "- 만료된 스냅샷이 유일하게 참조하던 데이터 파일이 있다면 함께 삭제되어 **스토리지 절약**\n",
    "- 이전 스냅샷으로의 Time Travel은 더 이상 불가능합니다\n",
    "- 운영 환경에서는 `older_than`으로 시간 기반 만료를 설정하는 것이 일반적입니다:\n",
    "  ```sql\n",
    "  CALL system.expire_snapshots(\n",
    "      table => 'my_table',\n",
    "      older_than => TIMESTAMP '2024-01-01 00:00:00'\n",
    "  )\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000016",
   "metadata": {},
   "source": [
    "---\n",
    "## 실험 2: Remove Orphan Files — 고아 파일 정리\n",
    "\n",
    "**고아 파일(Orphan Files)**은 어떤 스냅샷의 메타데이터에도 참조되지 않는 파일입니다.\n",
    "\n",
    "### 고아 파일이 생기는 원인\n",
    "- 실패한 Spark 작업이 중간에 파일을 생성한 경우\n",
    "- 커밋 실패 후 롤백되었지만 물리 파일은 남은 경우\n",
    "- 외부 도구가 잘못 파일을 생성한 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1000017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "고아 파일 시뮬레이션 생성: /home/jovyan/data/warehouse/lab/maintenance_orders/data/orphan-fake-file.parquet\n",
      "파일 크기: 1700 bytes\n",
      "파일 수정시각 조정: 2026-02-09 01:31:44 (7일 전)\n"
     ]
    }
   ],
   "source": [
    "# 고아 파일 시뮬레이션: 테이블 디렉토리에 가짜 파일 생성\n",
    "import os\n",
    "\n",
    "data_dir = os.path.join(TABLE_PATH, \"data\")\n",
    "if not os.path.exists(data_dir):\n",
    "    # 파티션 디렉토리 중 하나를 사용\n",
    "    for d in os.listdir(TABLE_PATH):\n",
    "        full = os.path.join(TABLE_PATH, d)\n",
    "        if os.path.isdir(full) and d != \"metadata\":\n",
    "            data_dir = full\n",
    "            break\n",
    "\n",
    "orphan_path = os.path.join(data_dir, \"orphan-fake-file.parquet\")\n",
    "with open(orphan_path, \"wb\") as f:\n",
    "    f.write(b\"fake orphan data \" * 100)\n",
    "\n",
    "# remove_orphan_files(SQL)는 older_than이 현재 시각보다 최소 24시간 이전이어야 함\n",
    "# 실습에서 바로 탐지되도록 파일 수정시각을 과거로 조정\n",
    "orphan_mtime = datetime.now() - timedelta(days=7)\n",
    "os.utime(orphan_path, (orphan_mtime.timestamp(), orphan_mtime.timestamp()))\n",
    "\n",
    "print(f\"고아 파일 시뮬레이션 생성: {orphan_path}\")\n",
    "print(f\"파일 크기: {os.path.getsize(orphan_path)} bytes\")\n",
    "print(f\"파일 수정시각 조정: {orphan_mtime.strftime('%Y-%m-%d %H:%M:%S')} (7일 전)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1000018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "고아 파일 탐색 (older_than: 2026-02-14 01:31:44)\n",
      "+-------------------------------------------------------------------------------------+\n",
      "|orphan_file_location                                                                 |\n",
      "+-------------------------------------------------------------------------------------+\n",
      "|file:/home/jovyan/data/warehouse/lab/maintenance_orders/data/orphan-fake-file.parquet|\n",
      "+-------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "before = snapshot_tree(TABLE_PATH)\n",
    "\n",
    "# Remove Orphan Files — dry_run으로 먼저 확인\n",
    "# SQL 프로시저 제약: older_than은 현재 시각보다 최소 24시간 이상 과거여야 함\n",
    "orphan_cutoff = (datetime.now() - timedelta(days=2)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "print(f\"고아 파일 탐색 (older_than: {orphan_cutoff})\")\n",
    "spark.sql(f\"\"\"\n",
    "CALL demo.system.remove_orphan_files(\n",
    "    table => '{TABLE_NAME}',\n",
    "    older_than => TIMESTAMP '{orphan_cutoff}',\n",
    "    dry_run => true\n",
    ")\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1000019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------+\n",
      "|orphan_file_location                                                                 |\n",
      "+-------------------------------------------------------------------------------------+\n",
      "|file:/home/jovyan/data/warehouse/lab/maintenance_orders/data/orphan-fake-file.parquet|\n",
      "+-------------------------------------------------------------------------------------+\n",
      "\n",
      "\n",
      "파일 변경 사항:\n",
      "\n",
      "[-] 삭제된 파일 (1개):\n",
      "    - data/orphan-fake-file.parquet\n",
      "\n",
      "요약: +0 추가, -1 삭제, ~0 변경\n",
      "\n",
      "고아 파일 존재 여부: False\n"
     ]
    }
   ],
   "source": [
    "# 실제로 고아 파일 삭제\n",
    "spark.sql(f\"\"\"\n",
    "CALL demo.system.remove_orphan_files(\n",
    "    table => '{TABLE_NAME}',\n",
    "    older_than => TIMESTAMP '{orphan_cutoff}'\n",
    ")\n",
    "\"\"\").show(truncate=False)\n",
    "\n",
    "after = snapshot_tree(TABLE_PATH)\n",
    "\n",
    "print(\"\\n파일 변경 사항:\")\n",
    "diff_tree(before, after)\n",
    "\n",
    "# 고아 파일이 삭제되었는지 확인\n",
    "print(f\"\\n고아 파일 존재 여부: {os.path.exists(orphan_path)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000020",
   "metadata": {},
   "source": [
    "### 관찰 포인트 — Remove Orphan Files\n",
    "\n",
    "- `dry_run => true`로 **먼저 삭제 대상을 확인**한 후 실제 삭제를 수행했습니다\n",
    "- 시뮬레이션으로 생성한 가짜 파일의 수정시각을 과거로 조정하여, dry run/실삭제에서 고아로 감지되게 했습니다\n",
    "- SQL 프로시저는 `older_than`이 **현재 시각보다 최소 24시간 이전**이어야 실행됩니다\n",
    "- 운영 환경에서는 `older_than`을 현재 시각에서 며칠 전으로 설정하세요:\n",
    "  ```sql\n",
    "  CALL system.remove_orphan_files(\n",
    "      table => 'my_table',\n",
    "      older_than => TIMESTAMP '2024-01-01 00:00:00'\n",
    "  )\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000021",
   "metadata": {},
   "source": [
    "---\n",
    "## 실험 3: Rewrite Manifests — Manifest 파일 병합\n",
    "\n",
    "**Manifest 파일**은 데이터 파일의 위치, 크기, 통계 정보를 담고 있습니다.\n",
    "\n",
    "INSERT가 반복되면 manifest 파일도 늘어나는데, 이를 병합하면:\n",
    "- 쿼리 계획 시 읽어야 할 manifest 수 감소\n",
    "- 파티션 프루닝 효율 향상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1000022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Rewrite 전 Manifest 목록 ===\n",
      "+-------+-------------------------------------------------------------------------------------------------------------+------+-----------------+-------------------+----------------------+-------------------------+------------------------+------------------------+---------------------------+--------------------------+----------------------------------+\n",
      "|content|path                                                                                                         |length|partition_spec_id|added_snapshot_id  |added_data_files_count|existing_data_files_count|deleted_data_files_count|added_delete_files_count|existing_delete_files_count|deleted_delete_files_count|partition_summaries               |\n",
      "+-------+-------------------------------------------------------------------------------------------------------------+------+-----------------+-------------------+----------------------+-------------------------+------------------------+------------------------+---------------------------+--------------------------+----------------------------------+\n",
      "|0      |file:/home/jovyan/data/warehouse/lab/maintenance_orders/metadata/c8d738e9-ca93-413b-a8c1-afccfd3c88f8-m1.avro|7456  |0                |6012371302795639709|3                     |0                        |0                       |0                       |0                          |0                         |[{false, false, 2024-01, 2024-03}]|\n",
      "|0      |file:/home/jovyan/data/warehouse/lab/maintenance_orders/metadata/c8d738e9-ca93-413b-a8c1-afccfd3c88f8-m0.avro|7457  |0                |6012371302795639709|0                     |0                        |3                       |0                       |0                          |0                         |[{false, false, 2024-01, 2024-03}]|\n",
      "+-------+-------------------------------------------------------------------------------------------------------------+------+-----------------+-------------------+----------------------+-------------------------+------------------------+------------------------+---------------------------+--------------------------+----------------------------------+\n",
      "\n",
      "Manifest 파일 수: 2\n"
     ]
    }
   ],
   "source": [
    "# 현재 manifest 상태\n",
    "print(\"=== Rewrite 전 Manifest 목록 ===\")\n",
    "manifests_before = spark.sql(f\"SELECT * FROM {TABLE_NAME}.manifests\")\n",
    "manifests_before.show(truncate=False)\n",
    "manifest_count_before = manifests_before.count()\n",
    "print(f\"Manifest 파일 수: {manifest_count_before}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1000023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+---------------------+\n",
      "|rewritten_manifests_count|added_manifests_count|\n",
      "+-------------------------+---------------------+\n",
      "|2                        |1                    |\n",
      "+-------------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rewrite Manifests 실행\n",
    "spark.sql(f\"\"\"\n",
    "CALL demo.system.rewrite_manifests(\n",
    "    table => '{TABLE_NAME}'\n",
    ")\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1000024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Rewrite 후 Manifest 목록 ===\n",
      "+-------+-------------------------------------------------------------------------------------------------------------+------+-----------------+-------------------+----------------------+-------------------------+------------------------+------------------------+---------------------------+--------------------------+----------------------------------+\n",
      "|content|path                                                                                                         |length|partition_spec_id|added_snapshot_id  |added_data_files_count|existing_data_files_count|deleted_data_files_count|added_delete_files_count|existing_delete_files_count|deleted_delete_files_count|partition_summaries               |\n",
      "+-------+-------------------------------------------------------------------------------------------------------------+------+-----------------+-------------------+----------------------+-------------------------+------------------------+------------------------+---------------------------+--------------------------+----------------------------------+\n",
      "|0      |file:/home/jovyan/data/warehouse/lab/maintenance_orders/metadata/d3012e1a-f1a0-4541-a7da-dab07ed9d921-m0.avro|7458  |0                |5644225777905057074|0                     |3                        |0                       |0                       |0                          |0                         |[{false, false, 2024-01, 2024-03}]|\n",
      "+-------+-------------------------------------------------------------------------------------------------------------+------+-----------------+-------------------+----------------------+-------------------------+------------------------+------------------------+---------------------------+--------------------------+----------------------------------+\n",
      "\n",
      "\n",
      "Manifest 파일 수: 2 → 1\n"
     ]
    }
   ],
   "source": [
    "# Rewrite 후 manifest 상태\n",
    "print(\"=== Rewrite 후 Manifest 목록 ===\")\n",
    "manifests_after = spark.sql(f\"SELECT * FROM {TABLE_NAME}.manifests\")\n",
    "manifests_after.show(truncate=False)\n",
    "manifest_count_after = manifests_after.count()\n",
    "\n",
    "print(f\"\\nManifest 파일 수: {manifest_count_before} → {manifest_count_after}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000025",
   "metadata": {},
   "source": [
    "### 관찰 포인트 — Rewrite Manifests\n",
    "\n",
    "- 여러 개의 작은 manifest 파일이 **더 적은 수의 큰 manifest로 병합**되었습니다\n",
    "- 쿼리 계획 시 읽어야 할 manifest 수가 줄어 **계획 수립 속도 향상**\n",
    "- manifest 내 파티션 통계도 최적화되어 **프루닝 효율 개선**\n",
    "- 이 작업은 데이터 파일 자체는 변경하지 않습니다 — **메타데이터만 재작성**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000026",
   "metadata": {},
   "source": [
    "---\n",
    "## 유지보수 자동화 가이드\n",
    "\n",
    "### 권장 실행 주기\n",
    "\n",
    "| 작업 | 주기 | 이유 |\n",
    "|------|------|------|\n",
    "| **Compaction** | 매시간 ~ 매일 | 스트리밍 수집 시 Small File Problem 방지 |\n",
    "| **Expire Snapshots** | 매일 ~ 매주 | 스토리지 절약, 보존 기간에 따라 조정 |\n",
    "| **Remove Orphan Files** | 매주 ~ 매월 | 빈도 낮아도 됨, dry_run 먼저 권장 |\n",
    "| **Rewrite Manifests** | 매일 ~ 매주 | Compaction 후 실행하면 효과적 |\n",
    "\n",
    "### Airflow DAG 예시 (의사 코드)\n",
    "\n",
    "```python\n",
    "# 매일 실행되는 유지보수 DAG\n",
    "with DAG('iceberg_maintenance', schedule='@daily'):\n",
    "    \n",
    "    compact = SparkSubmitOperator(\n",
    "        sql=\"CALL system.rewrite_data_files(table => 'my_table', strategy => 'sort')\"\n",
    "    )\n",
    "    \n",
    "    expire = SparkSubmitOperator(\n",
    "        sql=\"CALL system.expire_snapshots(table => 'my_table', older_than => now() - INTERVAL 7 DAYS)\"\n",
    "    )\n",
    "    \n",
    "    orphan = SparkSubmitOperator(\n",
    "        sql=\"CALL system.remove_orphan_files(table => 'my_table', older_than => now() - INTERVAL 3 DAYS)\"\n",
    "    )\n",
    "    \n",
    "    rewrite = SparkSubmitOperator(\n",
    "        sql=\"CALL system.rewrite_manifests(table => 'my_table')\"\n",
    "    )\n",
    "    \n",
    "    compact >> expire >> orphan >> rewrite\n",
    "```\n",
    "\n",
    "### Time Travel과의 트레이드오프\n",
    "\n",
    "```\n",
    "스냅샷 보존 기간 ↑  →  스토리지 비용 ↑  +  Time Travel 범위 ↑\n",
    "스냅샷 보존 기간 ↓  →  스토리지 비용 ↓  +  Time Travel 범위 ↓\n",
    "```\n",
    "\n",
    "운영 환경에서는 보통 **7일 보존**이 적절한 균형점입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1000027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark 세션 종료\n"
     ]
    }
   ],
   "source": [
    "spark.stop()\n",
    "print(\"Spark 세션 종료\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
