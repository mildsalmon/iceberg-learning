{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1000001",
   "metadata": {},
   "source": [
    "# Table Maintenance — 스냅샷 만료, 고아 파일 정리, Manifest 재작성\n",
    "\n",
    "이 노트북에서는 Iceberg 테이블의 **유지보수 작업**을 실습합니다.\n",
    "\n",
    "Iceberg는 Time Travel을 위해 과거 스냅샷과 데이터 파일을 보관하지만, 무한히 쌓이면 스토리지 비용과 메타데이터 크기가 증가합니다. 주기적으로 정리해야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000002",
   "metadata": {},
   "source": [
    "## 3가지 유지보수 작업\n",
    "\n",
    "| 작업 | 대상 | 효과 |\n",
    "|------|------|------|\n",
    "| **Expire Snapshots** | 오래된 스냅샷 | 스냅샷 메타데이터 + 그 스냅샷만 참조하던 데이터 파일 삭제 |\n",
    "| **Remove Orphan Files** | 어떤 스냅샷도 참조하지 않는 파일 | 실패한 작업의 잔해(고아 파일) 삭제 |\n",
    "| **Rewrite Manifests** | manifest 파일 | 작은 manifest들을 병합하여 쿼리 계획 최적화 |\n",
    "\n",
    "### 권장 실행 순서\n",
    "\n",
    "```\n",
    "1. Compaction (rewrite_data_files)  — 데이터 파일 정리\n",
    "2. Expire Snapshots                — 오래된 스냅샷 제거\n",
    "3. Remove Orphan Files             — 잔여 파일 정리\n",
    "```\n",
    "\n",
    "> 이 순서가 중요합니다: Compaction이 새 파일을 생성하므로, 이후에 Expire Snapshots로 이전 파일을 정리하고, 마지막에 Orphan Files로 잔여물을 청소합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000003",
   "metadata": {},
   "source": [
    "## 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1000004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import time\n",
    "import json\n",
    "import glob as glob_mod\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from utils.spark_setup import create_spark_session\n",
    "from utils.data_generator import generate_orders, to_spark_df\n",
    "from utils.file_explorer import show_tree, snapshot_tree, diff_tree, count_files, total_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1000005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark + Iceberg 세션 준비 완료 (warehouse: file:///home/jovyan/data/warehouse)\n"
     ]
    }
   ],
   "source": [
    "spark = create_spark_session()\n",
    "\n",
    "TABLE_NAME = \"demo.lab.maintenance_orders\"\n",
    "TABLE_PATH = \"/home/jovyan/data/warehouse/lab/maintenance_orders\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000006",
   "metadata": {},
   "source": [
    "---\n",
    "## 준비: 여러 스냅샷이 쌓인 테이블 만들기\n",
    "\n",
    "유지보수의 효과를 관찰하기 위해, 여러 번의 INSERT/UPDATE/DELETE로 다수의 스냅샷을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1000007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 1/5 완료 (50건 삽입)\n",
      "배치 2/5 완료 (50건 삽입)\n",
      "배치 3/5 완료 (50건 삽입)\n",
      "배치 4/5 완료 (50건 삽입)\n",
      "배치 5/5 완료 (50건 삽입)\n",
      "UPDATE 완료: pending → shipped\n",
      "DELETE 완료: cancelled 삭제\n",
      "\n",
      "최종 레코드 수: 214\n"
     ]
    }
   ],
   "source": [
    "spark.sql(f\"DROP TABLE IF EXISTS {TABLE_NAME}\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE {TABLE_NAME} (\n",
    "    order_id BIGINT,\n",
    "    customer_id BIGINT,\n",
    "    product_name STRING,\n",
    "    order_date DATE,\n",
    "    amount DECIMAL(10,2),\n",
    "    status STRING\n",
    ") USING ICEBERG\n",
    "PARTITIONED BY (months(order_date))\n",
    "\"\"\")\n",
    "\n",
    "# 여러 배치로 데이터 삽입 → 스냅샷 누적\n",
    "for i in range(5):\n",
    "    orders = generate_orders(num_records=50, seed=i, id_offset=i*50+1)\n",
    "    df = to_spark_df(spark, orders)\n",
    "    df.writeTo(TABLE_NAME).append()\n",
    "    print(f\"배치 {i+1}/5 완료 (50건 삽입)\")\n",
    "\n",
    "# UPDATE로 추가 스냅샷 생성\n",
    "spark.sql(f\"UPDATE {TABLE_NAME} SET status = 'shipped' WHERE status = 'pending'\")\n",
    "print(\"UPDATE 완료: pending → shipped\")\n",
    "\n",
    "# DELETE로 추가 스냅샷 생성\n",
    "spark.sql(f\"DELETE FROM {TABLE_NAME} WHERE status = 'cancelled'\")\n",
    "print(\"DELETE 완료: cancelled 삭제\")\n",
    "\n",
    "total_records = spark.sql(f\"SELECT COUNT(*) FROM {TABLE_NAME}\").collect()[0][0]\n",
    "print(f\"\\n최종 레코드 수: {total_records}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1000008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 스냅샷 히스토리 ===\n",
      "+-------------------+-----------------------+---------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|snapshot_id        |committed_at           |operation|summary                                                                                                                                                                                                                                                                                                                                                                            |\n",
      "+-------------------+-----------------------+---------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|4321806129274557610|2026-02-16 00:28:26.294|append   |{spark.app.id -> local-1771201699557, added-data-files -> 3, added-records -> 50, added-files-size -> 6829, changed-partition-count -> 3, total-records -> 50, total-files-size -> 6829, total-data-files -> 3, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}                                                                                 |\n",
      "|5674535073278867874|2026-02-16 00:28:26.797|append   |{spark.app.id -> local-1771201699557, added-data-files -> 3, added-records -> 50, added-files-size -> 6888, changed-partition-count -> 3, total-records -> 100, total-files-size -> 13717, total-data-files -> 6, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}                                                                               |\n",
      "|3488607360154086524|2026-02-16 00:28:27.336|append   |{spark.app.id -> local-1771201699557, added-data-files -> 3, added-records -> 50, added-files-size -> 6865, changed-partition-count -> 3, total-records -> 150, total-files-size -> 20582, total-data-files -> 9, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}                                                                               |\n",
      "|5383124651053872159|2026-02-16 00:28:27.711|append   |{spark.app.id -> local-1771201699557, added-data-files -> 3, added-records -> 50, added-files-size -> 6833, changed-partition-count -> 3, total-records -> 200, total-files-size -> 27415, total-data-files -> 12, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}                                                                              |\n",
      "|2883403130684589755|2026-02-16 00:28:28.12 |append   |{spark.app.id -> local-1771201699557, added-data-files -> 3, added-records -> 50, added-files-size -> 6882, changed-partition-count -> 3, total-records -> 250, total-files-size -> 34297, total-data-files -> 15, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}                                                                              |\n",
      "|6435014045981612168|2026-02-16 00:28:29.257|overwrite|{spark.app.id -> local-1771201699557, added-data-files -> 3, deleted-data-files -> 15, added-records -> 250, deleted-records -> 250, added-files-size -> 8679, removed-files-size -> 34297, changed-partition-count -> 3, total-records -> 250, total-files-size -> 8679, total-data-files -> 3, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}|\n",
      "|3126682812475079692|2026-02-16 00:28:29.684|overwrite|{spark.app.id -> local-1771201699557, added-data-files -> 3, deleted-data-files -> 3, added-records -> 214, deleted-records -> 250, added-files-size -> 8335, removed-files-size -> 8679, changed-partition-count -> 3, total-records -> 214, total-files-size -> 8335, total-data-files -> 3, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}  |\n",
      "+-------------------+-----------------------+---------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 현재 스냅샷 히스토리 확인\n",
    "print(\"=== 스냅샷 히스토리 ===\")\n",
    "spark.sql(f\"\"\"\n",
    "SELECT snapshot_id, committed_at, operation, summary\n",
    "FROM {TABLE_NAME}.snapshots\n",
    "ORDER BY committed_at\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1000009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유지보수 전 파일 구조:\n",
      "============================================================\n",
      "├── data/\n",
      "│   ├── order_date_month=2024-01/\n",
      "│   │   ├── 00000-11-1eac623a-b970-43b2-a96f-8018fd9e9666-00001.parquet  (2.3 KB)\n",
      "│   │   ├── 00000-17-5ff81d03-99ad-42da-9845-0a3b5e715967-00001.parquet  (2.3 KB)\n",
      "│   │   ├── 00000-23-c2c2d837-3fbc-4d54-86e9-f0bde8c8f770-00001.parquet  (2.2 KB)\n",
      "│   │   ├── 00000-29-6e3eebf4-48bd-43ef-ba78-252f07e33b9f-00001.parquet  (2.2 KB)\n",
      "│   │   ├── 00000-39-785dae90-87fb-42db-946f-808c9703754e-00001.parquet  (2.9 KB)\n",
      "│   │   ├── 00000-42-cbe6e704-901a-41d0-8b6c-8529864ab4c3-00001.parquet  (2.8 KB)\n",
      "│   │   └── 00000-5-c3442cda-6d72-48ec-92fa-9037a4e25244-00001.parquet  (2.2 KB)\n",
      "│   ├── order_date_month=2024-02/\n",
      "│   │   ├── 00000-11-1eac623a-b970-43b2-a96f-8018fd9e9666-00002.parquet  (2.1 KB)\n",
      "│   │   ├── 00000-17-5ff81d03-99ad-42da-9845-0a3b5e715967-00002.parquet  (2.3 KB)\n",
      "│   │   ├── 00000-23-c2c2d837-3fbc-4d54-86e9-f0bde8c8f770-00002.parquet  (2.2 KB)\n",
      "│   │   ├── 00000-29-6e3eebf4-48bd-43ef-ba78-252f07e33b9f-00002.parquet  (2.3 KB)\n",
      "│   │   ├── 00000-39-785dae90-87fb-42db-946f-808c9703754e-00002.parquet  (2.8 KB)\n",
      "│   │   ├── 00000-42-cbe6e704-901a-41d0-8b6c-8529864ab4c3-00002.parquet  (2.7 KB)\n",
      "│   │   └── 00000-5-c3442cda-6d72-48ec-92fa-9037a4e25244-00002.parquet  (2.2 KB)\n",
      "│   └── order_date_month=2024-03/\n",
      "│       ├── 00000-11-1eac623a-b970-43b2-a96f-8018fd9e9666-00003.parquet  (2.3 KB)\n",
      "│       ├── 00000-17-5ff81d03-99ad-42da-9845-0a3b5e715967-00003.parquet  (2.2 KB)\n",
      "│       ├── 00000-23-c2c2d837-3fbc-4d54-86e9-f0bde8c8f770-00003.parquet  (2.2 KB)\n",
      "│       ├── 00000-29-6e3eebf4-48bd-43ef-ba78-252f07e33b9f-00003.parquet  (2.2 KB)\n",
      "│       ├── 00000-39-785dae90-87fb-42db-946f-808c9703754e-00003.parquet  (2.8 KB)\n",
      "│       ├── 00000-42-cbe6e704-901a-41d0-8b6c-8529864ab4c3-00003.parquet  (2.7 KB)\n",
      "│       └── 00000-5-c3442cda-6d72-48ec-92fa-9037a4e25244-00003.parquet  (2.3 KB)\n",
      "└── metadata/\n",
      "    ├── 5592a4c2-4fd7-41f6-8375-5c367c5e0d77-m0.avro  (7.3 KB)\n",
      "    ├── 7f10223d-65e1-4e0d-960f-90f535560adc-m0.avro  (7.3 KB)\n",
      "    ├── 7f10223d-65e1-4e0d-960f-90f535560adc-m1.avro  (7.3 KB)\n",
      "    ├── 7f10223d-65e1-4e0d-960f-90f535560adc-m2.avro  (7.3 KB)\n",
      "    ├── 7f10223d-65e1-4e0d-960f-90f535560adc-m3.avro  (7.3 KB)\n",
      "    ├── 7f10223d-65e1-4e0d-960f-90f535560adc-m4.avro  (7.3 KB)\n",
      "    ├── 7f10223d-65e1-4e0d-960f-90f535560adc-m5.avro  (7.3 KB)\n",
      "    ├── 9fa7f693-b35c-44c9-b85b-498231dd293a-m0.avro  (7.3 KB)\n",
      "    ├── bdf424f0-9c9c-4dba-a006-9c7ed7f314ad-m0.avro  (7.2 KB)\n",
      "    ├── d2f08378-5f47-4d32-9efc-e82d56f30a9a-m0.avro  (7.3 KB)\n",
      "    ├── d2f08378-5f47-4d32-9efc-e82d56f30a9a-m1.avro  (7.3 KB)\n",
      "    ├── d729b4f5-3b0c-463f-bdf4-015ba70e2b76-m0.avro  (7.3 KB)\n",
      "    ├── efc11d64-064b-427e-936c-2bbd395d80fb-m0.avro  (7.3 KB)\n",
      "    ├── snap-2883403130684589755-1-bdf424f0-9c9c-4dba-a006-9c7ed7f314ad.avro  (4.4 KB)\n",
      "    ├── snap-3126682812475079692-1-d2f08378-5f47-4d32-9efc-e82d56f30a9a.avro  (4.2 KB)\n",
      "    ├── snap-3488607360154086524-1-5592a4c2-4fd7-41f6-8375-5c367c5e0d77.avro  (4.3 KB)\n",
      "    ├── snap-4321806129274557610-1-9fa7f693-b35c-44c9-b85b-498231dd293a.avro  (4.2 KB)\n",
      "    ├── snap-5383124651053872159-1-efc11d64-064b-427e-936c-2bbd395d80fb.avro  (4.3 KB)\n",
      "    ├── snap-5674535073278867874-1-d729b4f5-3b0c-463f-bdf4-015ba70e2b76.avro  (4.3 KB)\n",
      "    ├── snap-6435014045981612168-1-7f10223d-65e1-4e0d-960f-90f535560adc.avro  (4.3 KB)\n",
      "    ├── v1.metadata.json  (1.5 KB)\n",
      "    ├── v2.metadata.json  (2.6 KB)\n",
      "    ├── v3.metadata.json  (3.6 KB)\n",
      "    ├── v4.metadata.json  (4.5 KB)\n",
      "    ├── v5.metadata.json  (5.5 KB)\n",
      "    ├── v6.metadata.json  (6.5 KB)\n",
      "    ├── v7.metadata.json  (7.6 KB)\n",
      "    ├── v8.metadata.json  (8.7 KB)\n",
      "    └── version-hint.text  (1 B)\n",
      "\n",
      "Parquet 파일 수: 21\n",
      "총 크기: 220,472 bytes\n"
     ]
    }
   ],
   "source": [
    "# 현재 파일 상태\n",
    "print(\"유지보수 전 파일 구조:\")\n",
    "print(\"=\" * 60)\n",
    "show_tree(TABLE_PATH, max_depth=3)\n",
    "\n",
    "print(f\"\\nParquet 파일 수: {count_files(TABLE_PATH)}\")\n",
    "print(f\"총 크기: {total_size(TABLE_PATH):,} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000010",
   "metadata": {},
   "source": [
    "---\n",
    "## 실험 1: Expire Snapshots — 오래된 스냅샷 제거\n",
    "\n",
    "`expire_snapshots`는 지정 시간보다 오래된 스냅샷을 삭제합니다.\n",
    "\n",
    "삭제된 스냅샷이 **유일하게 참조하던** 데이터 파일도 함께 삭제됩니다.\n",
    "\n",
    "### 주요 옵션\n",
    "\n",
    "| 옵션 | 설명 |\n",
    "|------|------|\n",
    "| `older_than` | 이 시간보다 오래된 스냅샷 삭제 |\n",
    "| `retain_last` | 최소 N개 스냅샷 유지 (기본값: 1) |\n",
    "\n",
    "> **주의**: 스냅샷을 삭제하면 해당 시점으로 **Time Travel이 불가능**해집니다. 운영 환경에서는 적절한 보존 기간을 설정하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1000011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "만료 전 스냅샷 수: 7\n",
      "만료 전 Parquet 파일 수: 21\n"
     ]
    }
   ],
   "source": [
    "# 스냅샷 만료 전 상태 기록\n",
    "before_snapshots = spark.sql(f\"SELECT * FROM {TABLE_NAME}.snapshots\").collect()\n",
    "before = snapshot_tree(TABLE_PATH)\n",
    "\n",
    "print(f\"만료 전 스냅샷 수: {len(before_snapshots)}\")\n",
    "print(f\"만료 전 Parquet 파일 수: {count_files(TABLE_PATH)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1000012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스냅샷 만료 기준(older_than): 2026-02-16 00:28:30\n",
      "+------------------------+-----------------------------------+-----------------------------------+----------------------------+----------------------------+------------------------------+\n",
      "|deleted_data_files_count|deleted_position_delete_files_count|deleted_equality_delete_files_count|deleted_manifest_files_count|deleted_manifest_lists_count|deleted_statistics_files_count|\n",
      "+------------------------+-----------------------------------+-----------------------------------+----------------------------+----------------------------+------------------------------+\n",
      "|18                      |0                                  |0                                  |11                          |6                           |0                             |\n",
      "+------------------------+-----------------------------------+-----------------------------------+----------------------------+----------------------------+------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Expire Snapshots — 실습을 위해 현재 스냅샷들 중 최근 1개만 유지\n",
    "# retain_last만 지정하면 기본 older_than(보통 now - 5 days) 때문에 방금 만든 스냅샷은 만료되지 않을 수 있음\n",
    "max_committed_at = spark.sql(f\"SELECT MAX(committed_at) AS ts FROM {TABLE_NAME}.snapshots\").collect()[0][\"ts\"]\n",
    "expire_cutoff = (max_committed_at + timedelta(seconds=1)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "print(f\"스냅샷 만료 기준(older_than): {expire_cutoff}\")\n",
    "spark.sql(f\"\"\"\n",
    "CALL demo.system.expire_snapshots(\n",
    "    table => '{TABLE_NAME}',\n",
    "    older_than => TIMESTAMP '{expire_cutoff}',\n",
    "    retain_last => 1\n",
    ")\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1000013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스냅샷 수: 7 → 1\n",
      "Parquet 파일 수: 3\n",
      "\n",
      "파일 변경 사항:\n",
      "\n",
      "[+] 추가된 파일 (1개):\n",
      "    + metadata/v9.metadata.json  (3.7 KB)\n",
      "\n",
      "[-] 삭제된 파일 (35개):\n",
      "    - data/order_date_month=2024-01/00000-11-1eac623a-b970-43b2-a96f-8018fd9e9666-00001.parquet\n",
      "    - data/order_date_month=2024-01/00000-17-5ff81d03-99ad-42da-9845-0a3b5e715967-00001.parquet\n",
      "    - data/order_date_month=2024-01/00000-23-c2c2d837-3fbc-4d54-86e9-f0bde8c8f770-00001.parquet\n",
      "    - data/order_date_month=2024-01/00000-29-6e3eebf4-48bd-43ef-ba78-252f07e33b9f-00001.parquet\n",
      "    - data/order_date_month=2024-01/00000-39-785dae90-87fb-42db-946f-808c9703754e-00001.parquet\n",
      "    - data/order_date_month=2024-01/00000-5-c3442cda-6d72-48ec-92fa-9037a4e25244-00001.parquet\n",
      "    - data/order_date_month=2024-02/00000-11-1eac623a-b970-43b2-a96f-8018fd9e9666-00002.parquet\n",
      "    - data/order_date_month=2024-02/00000-17-5ff81d03-99ad-42da-9845-0a3b5e715967-00002.parquet\n",
      "    - data/order_date_month=2024-02/00000-23-c2c2d837-3fbc-4d54-86e9-f0bde8c8f770-00002.parquet\n",
      "    - data/order_date_month=2024-02/00000-29-6e3eebf4-48bd-43ef-ba78-252f07e33b9f-00002.parquet\n",
      "    - data/order_date_month=2024-02/00000-39-785dae90-87fb-42db-946f-808c9703754e-00002.parquet\n",
      "    - data/order_date_month=2024-02/00000-5-c3442cda-6d72-48ec-92fa-9037a4e25244-00002.parquet\n",
      "    - data/order_date_month=2024-03/00000-11-1eac623a-b970-43b2-a96f-8018fd9e9666-00003.parquet\n",
      "    - data/order_date_month=2024-03/00000-17-5ff81d03-99ad-42da-9845-0a3b5e715967-00003.parquet\n",
      "    - data/order_date_month=2024-03/00000-23-c2c2d837-3fbc-4d54-86e9-f0bde8c8f770-00003.parquet\n",
      "    - data/order_date_month=2024-03/00000-29-6e3eebf4-48bd-43ef-ba78-252f07e33b9f-00003.parquet\n",
      "    - data/order_date_month=2024-03/00000-39-785dae90-87fb-42db-946f-808c9703754e-00003.parquet\n",
      "    - data/order_date_month=2024-03/00000-5-c3442cda-6d72-48ec-92fa-9037a4e25244-00003.parquet\n",
      "    - metadata/5592a4c2-4fd7-41f6-8375-5c367c5e0d77-m0.avro\n",
      "    - metadata/7f10223d-65e1-4e0d-960f-90f535560adc-m0.avro\n",
      "    - metadata/7f10223d-65e1-4e0d-960f-90f535560adc-m1.avro\n",
      "    - metadata/7f10223d-65e1-4e0d-960f-90f535560adc-m2.avro\n",
      "    - metadata/7f10223d-65e1-4e0d-960f-90f535560adc-m3.avro\n",
      "    - metadata/7f10223d-65e1-4e0d-960f-90f535560adc-m4.avro\n",
      "    - metadata/7f10223d-65e1-4e0d-960f-90f535560adc-m5.avro\n",
      "    - metadata/9fa7f693-b35c-44c9-b85b-498231dd293a-m0.avro\n",
      "    - metadata/bdf424f0-9c9c-4dba-a006-9c7ed7f314ad-m0.avro\n",
      "    - metadata/d729b4f5-3b0c-463f-bdf4-015ba70e2b76-m0.avro\n",
      "    - metadata/efc11d64-064b-427e-936c-2bbd395d80fb-m0.avro\n",
      "    - metadata/snap-2883403130684589755-1-bdf424f0-9c9c-4dba-a006-9c7ed7f314ad.avro\n",
      "    - metadata/snap-3488607360154086524-1-5592a4c2-4fd7-41f6-8375-5c367c5e0d77.avro\n",
      "    - metadata/snap-4321806129274557610-1-9fa7f693-b35c-44c9-b85b-498231dd293a.avro\n",
      "    - metadata/snap-5383124651053872159-1-efc11d64-064b-427e-936c-2bbd395d80fb.avro\n",
      "    - metadata/snap-5674535073278867874-1-d729b4f5-3b0c-463f-bdf4-015ba70e2b76.avro\n",
      "    - metadata/snap-6435014045981612168-1-7f10223d-65e1-4e0d-960f-90f535560adc.avro\n",
      "\n",
      "요약: +1 추가, -35 삭제, ~0 변경\n"
     ]
    }
   ],
   "source": [
    "# 만료 후 상태 확인\n",
    "after_snapshots = spark.sql(f\"SELECT * FROM {TABLE_NAME}.snapshots\").collect()\n",
    "after = snapshot_tree(TABLE_PATH)\n",
    "\n",
    "print(f\"스냅샷 수: {len(before_snapshots)} → {len(after_snapshots)}\")\n",
    "print(f\"Parquet 파일 수: {count_files(TABLE_PATH)}\")\n",
    "\n",
    "print(\"\\n파일 변경 사항:\")\n",
    "diff_tree(before, after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1000014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 만료 후 스냅샷 ===\n",
      "+-------------------+-----------------------+---------+\n",
      "|snapshot_id        |committed_at           |operation|\n",
      "+-------------------+-----------------------+---------+\n",
      "|3126682812475079692|2026-02-16 00:28:29.684|overwrite|\n",
      "+-------------------+-----------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 남은 스냅샷 확인\n",
    "print(\"=== 만료 후 스냅샷 ===\")\n",
    "spark.sql(f\"\"\"\n",
    "SELECT snapshot_id, committed_at, operation\n",
    "FROM {TABLE_NAME}.snapshots\n",
    "ORDER BY committed_at\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000015",
   "metadata": {},
   "source": [
    "### 관찰 포인트 — Expire Snapshots\n",
    "\n",
    "- `older_than` + `retain_last => 1` 조합으로 **최근 1개 스냅샷만 남도록** 만료를 수행했습니다\n",
    "- `retain_last`만 지정하면 기본 `older_than`(환경/설정에 따라 대개 최근 며칠) 때문에 방금 생성된 스냅샷은 남을 수 있습니다\n",
    "- 만료된 스냅샷이 유일하게 참조하던 데이터 파일이 있다면 함께 삭제되어 **스토리지 절약**\n",
    "- 이전 스냅샷으로의 Time Travel은 더 이상 불가능합니다\n",
    "- 운영 환경에서는 `older_than`으로 시간 기반 만료를 설정하는 것이 일반적입니다:\n",
    "  ```sql\n",
    "  CALL system.expire_snapshots(\n",
    "      table => 'my_table',\n",
    "      older_than => TIMESTAMP '2024-01-01 00:00:00'\n",
    "  )\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000016",
   "metadata": {},
   "source": [
    "---\n",
    "## 실험 2: Remove Orphan Files — 고아 파일 정리\n",
    "\n",
    "**고아 파일(Orphan Files)**은 어떤 스냅샷의 메타데이터에도 참조되지 않는 파일입니다.\n",
    "\n",
    "### 고아 파일이 생기는 원인\n",
    "- 실패한 Spark 작업이 중간에 파일을 생성한 경우\n",
    "- 커밋 실패 후 롤백되었지만 물리 파일은 남은 경우\n",
    "- 외부 도구가 잘못 파일을 생성한 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1000017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "고아 파일 시뮬레이션 생성: /home/jovyan/data/warehouse/lab/maintenance_orders/data/orphan-fake-file.parquet\n",
      "파일 크기: 1700 bytes\n"
     ]
    }
   ],
   "source": [
    "# 고아 파일 시뮬레이션: 테이블 디렉토리에 가짜 파일 생성\n",
    "import os\n",
    "\n",
    "data_dir = os.path.join(TABLE_PATH, \"data\")\n",
    "if not os.path.exists(data_dir):\n",
    "    # 파티션 디렉토리 중 하나를 사용\n",
    "    for d in os.listdir(TABLE_PATH):\n",
    "        full = os.path.join(TABLE_PATH, d)\n",
    "        if os.path.isdir(full) and d != \"metadata\":\n",
    "            data_dir = full\n",
    "            break\n",
    "\n",
    "orphan_path = os.path.join(data_dir, \"orphan-fake-file.parquet\")\n",
    "with open(orphan_path, \"wb\") as f:\n",
    "    f.write(b\"fake orphan data \" * 100)\n",
    "\n",
    "print(f\"고아 파일 시뮬레이션 생성: {orphan_path}\")\n",
    "print(f\"파일 크기: {os.path.getsize(orphan_path)} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1000018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "고아 파일 탐색 (older_than: 2026-02-17 00:28:35)\n"
     ]
    },
    {
     "ename": "IllegalArgumentException",
     "evalue": "Cannot remove orphan files with an interval less than 24 hours. Executing this procedure with a short interval may corrupt the table if other operations are happening at the same time. If you are absolutely confident that no concurrent operations will be affected by removing orphan files with such a short interval, you can use the Action API to remove orphan files with an arbitrary interval.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m future_ts \u001b[38;5;241m=\u001b[39m (datetime\u001b[38;5;241m.\u001b[39mnow() \u001b[38;5;241m+\u001b[39m timedelta(days\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m고아 파일 탐색 (older_than: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuture_ts\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;43mCALL demo.system.remove_orphan_files(\u001b[39;49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;43m    table => \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mTABLE_NAME\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;43m    older_than => TIMESTAMP \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfuture_ts\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;43m    dry_run => true\u001b[39;49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;43m)\u001b[39;49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshow(truncate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py:1440\u001b[0m, in \u001b[0;36mSparkSession.sql\u001b[0;34m(self, sqlQuery, args, **kwargs)\u001b[0m\n\u001b[1;32m   1438\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1439\u001b[0m     litArgs \u001b[38;5;241m=\u001b[39m {k: _to_java_column(lit(v)) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m (args \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m-> 1440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlitArgs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1442\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/errors/exceptions/captured.py:175\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    171\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: Cannot remove orphan files with an interval less than 24 hours. Executing this procedure with a short interval may corrupt the table if other operations are happening at the same time. If you are absolutely confident that no concurrent operations will be affected by removing orphan files with such a short interval, you can use the Action API to remove orphan files with an arbitrary interval."
     ]
    }
   ],
   "source": [
    "before = snapshot_tree(TABLE_PATH)\n",
    "\n",
    "# Remove Orphan Files — dry_run으로 먼저 확인\n",
    "# 주의: Iceberg는 기본적으로 3일 이내 파일은 고아로 판단하지 않음 (진행 중인 작업 보호)\n",
    "# 실습에서는 older_than을 현재 시간 이후로 설정하여 강제 실행\n",
    "from pyspark.sql.functions import current_timestamp, expr\n",
    "\n",
    "future_ts = (datetime.now() + timedelta(days=1)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "print(f\"고아 파일 탐색 (older_than: {future_ts})\")\n",
    "spark.sql(f\"\"\"\n",
    "CALL demo.system.remove_orphan_files(\n",
    "    table => '{TABLE_NAME}',\n",
    "    older_than => TIMESTAMP '{future_ts}',\n",
    "    dry_run => true\n",
    ")\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제로 고아 파일 삭제\n",
    "spark.sql(f\"\"\"\n",
    "CALL demo.system.remove_orphan_files(\n",
    "    table => '{TABLE_NAME}',\n",
    "    older_than => TIMESTAMP '{future_ts}'\n",
    ")\n",
    "\"\"\").show(truncate=False)\n",
    "\n",
    "after = snapshot_tree(TABLE_PATH)\n",
    "\n",
    "print(\"\\n파일 변경 사항:\")\n",
    "diff_tree(before, after)\n",
    "\n",
    "# 고아 파일이 삭제되었는지 확인\n",
    "print(f\"\\n고아 파일 존재 여부: {os.path.exists(orphan_path)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000020",
   "metadata": {},
   "source": [
    "### 관찰 포인트 — Remove Orphan Files\n",
    "\n",
    "- `dry_run => true`로 **먼저 삭제 대상을 확인**한 후 실제 삭제를 수행했습니다\n",
    "- 시뮬레이션으로 생성한 가짜 파일이 고아로 감지되어 삭제되었습니다\n",
    "- 기본적으로 **3일 이내 파일은 보호**됩니다 (진행 중인 작업의 파일일 수 있으므로)\n",
    "- 운영 환경에서는 `older_than`을 현재 시각에서 며칠 전으로 설정하세요:\n",
    "  ```sql\n",
    "  CALL system.remove_orphan_files(\n",
    "      table => 'my_table',\n",
    "      older_than => TIMESTAMP '2024-01-01 00:00:00'\n",
    "  )\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000021",
   "metadata": {},
   "source": [
    "---\n",
    "## 실험 3: Rewrite Manifests — Manifest 파일 병합\n",
    "\n",
    "**Manifest 파일**은 데이터 파일의 위치, 크기, 통계 정보를 담고 있습니다.\n",
    "\n",
    "INSERT가 반복되면 manifest 파일도 늘어나는데, 이를 병합하면:\n",
    "- 쿼리 계획 시 읽어야 할 manifest 수 감소\n",
    "- 파티션 프루닝 효율 향상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재 manifest 상태\n",
    "print(\"=== Rewrite 전 Manifest 목록 ===\")\n",
    "manifests_before = spark.sql(f\"SELECT * FROM {TABLE_NAME}.manifests\")\n",
    "manifests_before.show(truncate=False)\n",
    "manifest_count_before = manifests_before.count()\n",
    "print(f\"Manifest 파일 수: {manifest_count_before}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewrite Manifests 실행\n",
    "spark.sql(f\"\"\"\n",
    "CALL demo.system.rewrite_manifests(\n",
    "    table => '{TABLE_NAME}'\n",
    ")\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewrite 후 manifest 상태\n",
    "print(\"=== Rewrite 후 Manifest 목록 ===\")\n",
    "manifests_after = spark.sql(f\"SELECT * FROM {TABLE_NAME}.manifests\")\n",
    "manifests_after.show(truncate=False)\n",
    "manifest_count_after = manifests_after.count()\n",
    "\n",
    "print(f\"\\nManifest 파일 수: {manifest_count_before} → {manifest_count_after}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000025",
   "metadata": {},
   "source": [
    "### 관찰 포인트 — Rewrite Manifests\n",
    "\n",
    "- 여러 개의 작은 manifest 파일이 **더 적은 수의 큰 manifest로 병합**되었습니다\n",
    "- 쿼리 계획 시 읽어야 할 manifest 수가 줄어 **계획 수립 속도 향상**\n",
    "- manifest 내 파티션 통계도 최적화되어 **프루닝 효율 개선**\n",
    "- 이 작업은 데이터 파일 자체는 변경하지 않습니다 — **메타데이터만 재작성**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000026",
   "metadata": {},
   "source": [
    "---\n",
    "## 유지보수 자동화 가이드\n",
    "\n",
    "### 권장 실행 주기\n",
    "\n",
    "| 작업 | 주기 | 이유 |\n",
    "|------|------|------|\n",
    "| **Compaction** | 매시간 ~ 매일 | 스트리밍 수집 시 Small File Problem 방지 |\n",
    "| **Expire Snapshots** | 매일 ~ 매주 | 스토리지 절약, 보존 기간에 따라 조정 |\n",
    "| **Remove Orphan Files** | 매주 ~ 매월 | 빈도 낮아도 됨, dry_run 먼저 권장 |\n",
    "| **Rewrite Manifests** | 매일 ~ 매주 | Compaction 후 실행하면 효과적 |\n",
    "\n",
    "### Airflow DAG 예시 (의사 코드)\n",
    "\n",
    "```python\n",
    "# 매일 실행되는 유지보수 DAG\n",
    "with DAG('iceberg_maintenance', schedule='@daily'):\n",
    "    \n",
    "    compact = SparkSubmitOperator(\n",
    "        sql=\"CALL system.rewrite_data_files(table => 'my_table', strategy => 'sort')\"\n",
    "    )\n",
    "    \n",
    "    expire = SparkSubmitOperator(\n",
    "        sql=\"CALL system.expire_snapshots(table => 'my_table', older_than => now() - INTERVAL 7 DAYS)\"\n",
    "    )\n",
    "    \n",
    "    orphan = SparkSubmitOperator(\n",
    "        sql=\"CALL system.remove_orphan_files(table => 'my_table', older_than => now() - INTERVAL 3 DAYS)\"\n",
    "    )\n",
    "    \n",
    "    rewrite = SparkSubmitOperator(\n",
    "        sql=\"CALL system.rewrite_manifests(table => 'my_table')\"\n",
    "    )\n",
    "    \n",
    "    compact >> expire >> orphan >> rewrite\n",
    "```\n",
    "\n",
    "### Time Travel과의 트레이드오프\n",
    "\n",
    "```\n",
    "스냅샷 보존 기간 ↑  →  스토리지 비용 ↑  +  Time Travel 범위 ↑\n",
    "스냅샷 보존 기간 ↓  →  스토리지 비용 ↓  +  Time Travel 범위 ↓\n",
    "```\n",
    "\n",
    "운영 환경에서는 보통 **7일 보존**이 적절한 균형점입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000027",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()\n",
    "print(\"Spark 세션 종료\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
