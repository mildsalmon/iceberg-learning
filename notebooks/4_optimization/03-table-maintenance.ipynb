{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1000001",
   "metadata": {},
   "source": [
    "# Table Maintenance — 스냅샷 만료, 고아 파일 정리, Manifest 재작성\n",
    "\n",
    "이 노트북에서는 Iceberg 테이블의 **유지보수 작업**을 실습합니다.\n",
    "\n",
    "Iceberg는 Time Travel을 위해 과거 스냅샷과 데이터 파일을 보관하지만, 무한히 쌓이면 스토리지 비용과 메타데이터 크기가 증가합니다. 주기적으로 정리해야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000002",
   "metadata": {},
   "source": [
    "## 3가지 유지보수 작업\n",
    "\n",
    "| 작업 | 대상 | 효과 |\n",
    "|------|------|------|\n",
    "| **Expire Snapshots** | 오래된 스냅샷 | 스냅샷 메타데이터 + 그 스냅샷만 참조하던 데이터 파일 삭제 |\n",
    "| **Remove Orphan Files** | 어떤 스냅샷도 참조하지 않는 파일 | 실패한 작업의 잔해(고아 파일) 삭제 |\n",
    "| **Rewrite Manifests** | manifest 파일 | 작은 manifest들을 병합하여 쿼리 계획 최적화 |\n",
    "\n",
    "### 권장 실행 순서\n",
    "\n",
    "```\n",
    "1. Compaction (rewrite_data_files)  — 데이터 파일 정리\n",
    "2. Expire Snapshots                — 오래된 스냅샷 제거\n",
    "3. Remove Orphan Files             — 잔여 파일 정리\n",
    "```\n",
    "\n",
    "> 이 순서가 중요합니다: Compaction이 새 파일을 생성하므로, 이후에 Expire Snapshots로 이전 파일을 정리하고, 마지막에 Orphan Files로 잔여물을 청소합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000003",
   "metadata": {},
   "source": [
    "## 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import time\n",
    "import json\n",
    "import glob as glob_mod\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from utils.spark_setup import create_spark_session\n",
    "from utils.data_generator import generate_orders, to_spark_df\n",
    "from utils.file_explorer import show_tree, snapshot_tree, diff_tree, count_files, total_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000005",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = create_spark_session()\n",
    "\n",
    "TABLE_NAME = \"demo.lab.maintenance_orders\"\n",
    "TABLE_PATH = \"/home/jovyan/data/warehouse/lab/maintenance_orders\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000006",
   "metadata": {},
   "source": [
    "---\n",
    "## 준비: 여러 스냅샷이 쌓인 테이블 만들기\n",
    "\n",
    "유지보수의 효과를 관찰하기 위해, 여러 번의 INSERT/UPDATE/DELETE로 다수의 스냅샷을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000007",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"DROP TABLE IF EXISTS {TABLE_NAME}\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE {TABLE_NAME} (\n",
    "    order_id BIGINT,\n",
    "    customer_id BIGINT,\n",
    "    product_name STRING,\n",
    "    order_date DATE,\n",
    "    amount DECIMAL(10,2),\n",
    "    status STRING\n",
    ") USING ICEBERG\n",
    "PARTITIONED BY (months(order_date))\n",
    "\"\"\")\n",
    "\n",
    "# 여러 배치로 데이터 삽입 → 스냅샷 누적\n",
    "for i in range(5):\n",
    "    orders = generate_orders(num_records=50, seed=i, id_offset=i*50+1)\n",
    "    df = to_spark_df(spark, orders)\n",
    "    df.writeTo(TABLE_NAME).append()\n",
    "    print(f\"배치 {i+1}/5 완료 (50건 삽입)\")\n",
    "\n",
    "# UPDATE로 추가 스냅샷 생성\n",
    "spark.sql(f\"UPDATE {TABLE_NAME} SET status = 'shipped' WHERE status = 'pending'\")\n",
    "print(\"UPDATE 완료: pending → shipped\")\n",
    "\n",
    "# DELETE로 추가 스냅샷 생성\n",
    "spark.sql(f\"DELETE FROM {TABLE_NAME} WHERE status = 'cancelled'\")\n",
    "print(\"DELETE 완료: cancelled 삭제\")\n",
    "\n",
    "total_records = spark.sql(f\"SELECT COUNT(*) FROM {TABLE_NAME}\").collect()[0][0]\n",
    "print(f\"\\n최종 레코드 수: {total_records}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재 스냅샷 히스토리 확인\n",
    "print(\"=== 스냅샷 히스토리 ===\")\n",
    "spark.sql(f\"\"\"\n",
    "SELECT snapshot_id, committed_at, operation, summary\n",
    "FROM {TABLE_NAME}.snapshots\n",
    "ORDER BY committed_at\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재 파일 상태\n",
    "print(\"유지보수 전 파일 구조:\")\n",
    "print(\"=\" * 60)\n",
    "show_tree(TABLE_PATH, max_depth=3)\n",
    "\n",
    "print(f\"\\nParquet 파일 수: {count_files(TABLE_PATH)}\")\n",
    "print(f\"총 크기: {total_size(TABLE_PATH):,} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000010",
   "metadata": {},
   "source": [
    "---\n",
    "## 실험 1: Expire Snapshots — 오래된 스냅샷 제거\n",
    "\n",
    "`expire_snapshots`는 지정 시간보다 오래된 스냅샷을 삭제합니다.\n",
    "\n",
    "삭제된 스냅샷이 **유일하게 참조하던** 데이터 파일도 함께 삭제됩니다.\n",
    "\n",
    "### 주요 옵션\n",
    "\n",
    "| 옵션 | 설명 |\n",
    "|------|------|\n",
    "| `older_than` | 이 시간보다 오래된 스냅샷 삭제 |\n",
    "| `retain_last` | 최소 N개 스냅샷 유지 (기본값: 1) |\n",
    "\n",
    "> **주의**: 스냅샷을 삭제하면 해당 시점으로 **Time Travel이 불가능**해집니다. 운영 환경에서는 적절한 보존 기간을 설정하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스냅샷 만료 전 상태 기록\n",
    "before_snapshots = spark.sql(f\"SELECT * FROM {TABLE_NAME}.snapshots\").collect()\n",
    "before = snapshot_tree(TABLE_PATH)\n",
    "\n",
    "print(f\"만료 전 스냅샷 수: {len(before_snapshots)}\")\n",
    "print(f\"만료 전 Parquet 파일 수: {count_files(TABLE_PATH)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expire Snapshots — 최근 1개만 유지\n",
    "spark.sql(f\"\"\"\n",
    "CALL demo.system.expire_snapshots(\n",
    "    table => '{TABLE_NAME}',\n",
    "    retain_last => 1\n",
    ")\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 만료 후 상태 확인\n",
    "after_snapshots = spark.sql(f\"SELECT * FROM {TABLE_NAME}.snapshots\").collect()\n",
    "after = snapshot_tree(TABLE_PATH)\n",
    "\n",
    "print(f\"스냅샷 수: {len(before_snapshots)} → {len(after_snapshots)}\")\n",
    "print(f\"Parquet 파일 수: {count_files(TABLE_PATH)}\")\n",
    "\n",
    "print(\"\\n파일 변경 사항:\")\n",
    "diff_tree(before, after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 남은 스냅샷 확인\n",
    "print(\"=== 만료 후 스냅샷 ===\")\n",
    "spark.sql(f\"\"\"\n",
    "SELECT snapshot_id, committed_at, operation\n",
    "FROM {TABLE_NAME}.snapshots\n",
    "ORDER BY committed_at\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000015",
   "metadata": {},
   "source": [
    "### 관찰 포인트 — Expire Snapshots\n",
    "\n",
    "- `retain_last => 1`로 **최근 1개 스냅샷만 남기고** 나머지를 삭제했습니다\n",
    "- 삭제된 스냅샷이 유일하게 참조하던 데이터 파일도 함께 삭제되어 **스토리지 절약**\n",
    "- 이전 스냅샷으로의 Time Travel은 더 이상 불가능합니다\n",
    "- 운영 환경에서는 `older_than`으로 시간 기반 만료를 설정하는 것이 일반적입니다:\n",
    "  ```sql\n",
    "  CALL system.expire_snapshots(\n",
    "      table => 'my_table',\n",
    "      older_than => TIMESTAMP '2024-01-01 00:00:00'\n",
    "  )\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000016",
   "metadata": {},
   "source": [
    "---\n",
    "## 실험 2: Remove Orphan Files — 고아 파일 정리\n",
    "\n",
    "**고아 파일(Orphan Files)**은 어떤 스냅샷의 메타데이터에도 참조되지 않는 파일입니다.\n",
    "\n",
    "### 고아 파일이 생기는 원인\n",
    "- 실패한 Spark 작업이 중간에 파일을 생성한 경우\n",
    "- 커밋 실패 후 롤백되었지만 물리 파일은 남은 경우\n",
    "- 외부 도구가 잘못 파일을 생성한 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 고아 파일 시뮬레이션: 테이블 디렉토리에 가짜 파일 생성\n",
    "import os\n",
    "\n",
    "data_dir = os.path.join(TABLE_PATH, \"data\")\n",
    "if not os.path.exists(data_dir):\n",
    "    # 파티션 디렉토리 중 하나를 사용\n",
    "    for d in os.listdir(TABLE_PATH):\n",
    "        full = os.path.join(TABLE_PATH, d)\n",
    "        if os.path.isdir(full) and d != \"metadata\":\n",
    "            data_dir = full\n",
    "            break\n",
    "\n",
    "orphan_path = os.path.join(data_dir, \"orphan-fake-file.parquet\")\n",
    "with open(orphan_path, \"wb\") as f:\n",
    "    f.write(b\"fake orphan data \" * 100)\n",
    "\n",
    "print(f\"고아 파일 시뮬레이션 생성: {orphan_path}\")\n",
    "print(f\"파일 크기: {os.path.getsize(orphan_path)} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000018",
   "metadata": {},
   "outputs": [],
   "source": [
    "before = snapshot_tree(TABLE_PATH)\n",
    "\n",
    "# Remove Orphan Files — dry_run으로 먼저 확인\n",
    "# 주의: Iceberg는 기본적으로 3일 이내 파일은 고아로 판단하지 않음 (진행 중인 작업 보호)\n",
    "# 실습에서는 older_than을 현재 시간 이후로 설정하여 강제 실행\n",
    "from pyspark.sql.functions import current_timestamp, expr\n",
    "\n",
    "future_ts = (datetime.now() + timedelta(days=1)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "print(f\"고아 파일 탐색 (older_than: {future_ts})\")\n",
    "spark.sql(f\"\"\"\n",
    "CALL demo.system.remove_orphan_files(\n",
    "    table => '{TABLE_NAME}',\n",
    "    older_than => TIMESTAMP '{future_ts}',\n",
    "    dry_run => true\n",
    ")\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제로 고아 파일 삭제\n",
    "spark.sql(f\"\"\"\n",
    "CALL demo.system.remove_orphan_files(\n",
    "    table => '{TABLE_NAME}',\n",
    "    older_than => TIMESTAMP '{future_ts}'\n",
    ")\n",
    "\"\"\").show(truncate=False)\n",
    "\n",
    "after = snapshot_tree(TABLE_PATH)\n",
    "\n",
    "print(\"\\n파일 변경 사항:\")\n",
    "diff_tree(before, after)\n",
    "\n",
    "# 고아 파일이 삭제되었는지 확인\n",
    "print(f\"\\n고아 파일 존재 여부: {os.path.exists(orphan_path)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000020",
   "metadata": {},
   "source": [
    "### 관찰 포인트 — Remove Orphan Files\n",
    "\n",
    "- `dry_run => true`로 **먼저 삭제 대상을 확인**한 후 실제 삭제를 수행했습니다\n",
    "- 시뮬레이션으로 생성한 가짜 파일이 고아로 감지되어 삭제되었습니다\n",
    "- 기본적으로 **3일 이내 파일은 보호**됩니다 (진행 중인 작업의 파일일 수 있으므로)\n",
    "- 운영 환경에서는 `older_than`을 현재 시각에서 며칠 전으로 설정하세요:\n",
    "  ```sql\n",
    "  CALL system.remove_orphan_files(\n",
    "      table => 'my_table',\n",
    "      older_than => TIMESTAMP '2024-01-01 00:00:00'\n",
    "  )\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000021",
   "metadata": {},
   "source": [
    "---\n",
    "## 실험 3: Rewrite Manifests — Manifest 파일 병합\n",
    "\n",
    "**Manifest 파일**은 데이터 파일의 위치, 크기, 통계 정보를 담고 있습니다.\n",
    "\n",
    "INSERT가 반복되면 manifest 파일도 늘어나는데, 이를 병합하면:\n",
    "- 쿼리 계획 시 읽어야 할 manifest 수 감소\n",
    "- 파티션 프루닝 효율 향상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재 manifest 상태\n",
    "print(\"=== Rewrite 전 Manifest 목록 ===\")\n",
    "manifests_before = spark.sql(f\"SELECT * FROM {TABLE_NAME}.manifests\")\n",
    "manifests_before.show(truncate=False)\n",
    "manifest_count_before = manifests_before.count()\n",
    "print(f\"Manifest 파일 수: {manifest_count_before}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewrite Manifests 실행\n",
    "spark.sql(f\"\"\"\n",
    "CALL demo.system.rewrite_manifests(\n",
    "    table => '{TABLE_NAME}'\n",
    ")\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewrite 후 manifest 상태\n",
    "print(\"=== Rewrite 후 Manifest 목록 ===\")\n",
    "manifests_after = spark.sql(f\"SELECT * FROM {TABLE_NAME}.manifests\")\n",
    "manifests_after.show(truncate=False)\n",
    "manifest_count_after = manifests_after.count()\n",
    "\n",
    "print(f\"\\nManifest 파일 수: {manifest_count_before} → {manifest_count_after}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000025",
   "metadata": {},
   "source": [
    "### 관찰 포인트 — Rewrite Manifests\n",
    "\n",
    "- 여러 개의 작은 manifest 파일이 **더 적은 수의 큰 manifest로 병합**되었습니다\n",
    "- 쿼리 계획 시 읽어야 할 manifest 수가 줄어 **계획 수립 속도 향상**\n",
    "- manifest 내 파티션 통계도 최적화되어 **프루닝 효율 개선**\n",
    "- 이 작업은 데이터 파일 자체는 변경하지 않습니다 — **메타데이터만 재작성**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000026",
   "metadata": {},
   "source": [
    "---\n",
    "## 유지보수 자동화 가이드\n",
    "\n",
    "### 권장 실행 주기\n",
    "\n",
    "| 작업 | 주기 | 이유 |\n",
    "|------|------|------|\n",
    "| **Compaction** | 매시간 ~ 매일 | 스트리밍 수집 시 Small File Problem 방지 |\n",
    "| **Expire Snapshots** | 매일 ~ 매주 | 스토리지 절약, 보존 기간에 따라 조정 |\n",
    "| **Remove Orphan Files** | 매주 ~ 매월 | 빈도 낮아도 됨, dry_run 먼저 권장 |\n",
    "| **Rewrite Manifests** | 매일 ~ 매주 | Compaction 후 실행하면 효과적 |\n",
    "\n",
    "### Airflow DAG 예시 (의사 코드)\n",
    "\n",
    "```python\n",
    "# 매일 실행되는 유지보수 DAG\n",
    "with DAG('iceberg_maintenance', schedule='@daily'):\n",
    "    \n",
    "    compact = SparkSubmitOperator(\n",
    "        sql=\"CALL system.rewrite_data_files(table => 'my_table', strategy => 'sort')\"\n",
    "    )\n",
    "    \n",
    "    expire = SparkSubmitOperator(\n",
    "        sql=\"CALL system.expire_snapshots(table => 'my_table', older_than => now() - INTERVAL 7 DAYS)\"\n",
    "    )\n",
    "    \n",
    "    orphan = SparkSubmitOperator(\n",
    "        sql=\"CALL system.remove_orphan_files(table => 'my_table', older_than => now() - INTERVAL 3 DAYS)\"\n",
    "    )\n",
    "    \n",
    "    rewrite = SparkSubmitOperator(\n",
    "        sql=\"CALL system.rewrite_manifests(table => 'my_table')\"\n",
    "    )\n",
    "    \n",
    "    compact >> expire >> orphan >> rewrite\n",
    "```\n",
    "\n",
    "### Time Travel과의 트레이드오프\n",
    "\n",
    "```\n",
    "스냅샷 보존 기간 ↑  →  스토리지 비용 ↑  +  Time Travel 범위 ↑\n",
    "스냅샷 보존 기간 ↓  →  스토리지 비용 ↓  +  Time Travel 범위 ↓\n",
    "```\n",
    "\n",
    "운영 환경에서는 보통 **7일 보존**이 적절한 균형점입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000027",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()\n",
    "print(\"Spark 세션 종료\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}