{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1000001",
   "metadata": {},
   "source": [
    "# 03. Metadata Layer Deep Dive\n",
    "\n",
    "Iceberg 테이블의 **Metadata Layer**를 구성하는 metadata.json, Manifest List, Manifest File을 직접 읽어보며 그 내부 구조를 분석합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1000002",
   "metadata": {},
   "source": [
    "## Metadata Layer 구조\n",
    "\n",
    "Iceberg의 Metadata Layer는 **3단계 계층 구조**로 이루어져 있습니다.\n",
    "\n",
    "```\n",
    "metadata.json (Table Metadata)\n",
    "  │\n",
    "  │  current-snapshot-id 로 현재 스냅샷을 가리킴\n",
    "  │\n",
    "  ├─▶ snap-{id}.avro (Manifest List)\n",
    "  │     │\n",
    "  │     │  각 manifest file의 경로와 요약 통계\n",
    "  │     │\n",
    "  │     ├─▶ {hash}.avro (Manifest File)\n",
    "  │     │     └─ data file 경로, record_count, column_sizes,\n",
    "  │     │        value_counts, null_value_counts,\n",
    "  │     │        lower_bounds, upper_bounds\n",
    "  │     │\n",
    "  │     └─▶ {hash}.avro (Manifest File)\n",
    "  │           └─ ...\n",
    "  │\n",
    "  └─▶ (이전 스냅샷의 manifest list)\n",
    "```\n",
    "\n",
    "### 각 파일의 역할\n",
    "\n",
    "| 파일 | 포맷 | 내용 |\n",
    "|------|------|------|\n",
    "| **metadata.json** | JSON | 테이블의 전체 상태: 스키마, 파티션 스펙, 스냅샷 목록, 현재 스냅샷 ID |\n",
    "| **snap-*.avro** | Avro | Manifest List: 이 스냅샷에 포함되는 manifest file 목록 + 파티션 요약 통계 |\n",
    "| **\\*.avro** | Avro | Manifest File: 데이터 파일별 상세 정보 (경로, 레코드 수, 컬럼 통계 등) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1000003",
   "metadata": {},
   "source": [
    "## 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1000004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.spark_setup import create_spark_session\n",
    "from utils.data_generator import generate_orders, to_spark_df\n",
    "from utils.file_explorer import show_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1000005",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = create_spark_session(\"MetadataDeepDive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1000006",
   "metadata": {},
   "source": [
    "## 테이블 생성 및 여러 스냅샷 만들기\n",
    "\n",
    "INSERT → UPDATE → INSERT 순으로 작업하여 **3개의 스냅샷**을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1000007",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS demo.lab\")\n",
    "spark.sql(\"DROP TABLE IF EXISTS demo.lab.meta_orders\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    CREATE TABLE demo.lab.meta_orders (\n",
    "        order_id     BIGINT,\n",
    "        customer_id  BIGINT,\n",
    "        product_name STRING,\n",
    "        order_date   DATE,\n",
    "        amount       DOUBLE,\n",
    "        status       STRING\n",
    "    )\n",
    "    USING iceberg\n",
    "    PARTITIONED BY (months(order_date))\n",
    "\"\"\")\n",
    "\n",
    "print(\"테이블 생성 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1000008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snapshot 1: 100건 삽입\n",
    "orders1 = generate_orders(num_records=100, seed=42)\n",
    "df1 = to_spark_df(spark, orders1)\n",
    "df1.writeTo(\"demo.lab.meta_orders\").append()\n",
    "print(\"Snapshot 1: 100건 INSERT 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1000009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snapshot 2: 10건 UPDATE\n",
    "spark.sql(\"\"\"\n",
    "    UPDATE demo.lab.meta_orders\n",
    "    SET status = 'cancelled', amount = 0.0\n",
    "    WHERE order_id <= 10\n",
    "\"\"\")\n",
    "print(\"Snapshot 2: 10건 UPDATE 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c100000a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snapshot 3: 50건 추가 삽입\n",
    "orders2 = generate_orders(num_records=50, id_offset=101, seed=99)\n",
    "df2 = to_spark_df(spark, orders2)\n",
    "df2.writeTo(\"demo.lab.meta_orders\").append()\n",
    "print(\"Snapshot 3: 50건 INSERT 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c100000b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재 상태 확인\n",
    "count = spark.sql(\"SELECT COUNT(*) AS cnt FROM demo.lab.meta_orders\").collect()[0][\"cnt\"]\n",
    "print(f\"현재 총 레코드: {count}건\")\n",
    "\n",
    "spark.sql(\"SELECT * FROM demo.lab.meta_orders.snapshots\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c100000c",
   "metadata": {},
   "source": [
    "## metadata/ 디렉토리 구조 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c100000d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TABLE_PATH = \"/home/jovyan/data/warehouse/lab/meta_orders\"\n",
    "METADATA_PATH = f\"{TABLE_PATH}/metadata\"\n",
    "\n",
    "show_tree(METADATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c100000e",
   "metadata": {},
   "source": [
    "## 1단계: metadata.json 분석\n",
    "\n",
    "`metadata.json`은 테이블의 **전체 상태**를 담고 있는 핵심 파일입니다.  \n",
    "가장 최신 버전의 metadata.json을 직접 읽어봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c100000f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# 가장 최신 metadata.json 찾기\n",
    "metadata_files = sorted(glob.glob(f\"{METADATA_PATH}/v*.metadata.json\"))\n",
    "latest_metadata = metadata_files[-1]\n",
    "print(f\"최신 metadata 파일: {os.path.basename(latest_metadata)}\")\n",
    "print(f\"전체 metadata 파일 수: {len(metadata_files)}개 (= 스냅샷 수 + 테이블 생성)\")\n",
    "\n",
    "with open(latest_metadata) as f:\n",
    "    meta = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1000010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주요 최상위 필드\n",
    "print(\"[ metadata.json 최상위 필드 ]\\n\")\n",
    "print(f\"  format-version:      {meta['format-version']}\")\n",
    "print(f\"  table-uuid:          {meta['table-uuid']}\")\n",
    "print(f\"  location:            {meta['location']}\")\n",
    "print(f\"  current-schema-id:   {meta.get('current-schema-id', 'N/A')}\")\n",
    "print(f\"  current-snapshot-id: {meta.get('current-snapshot-id', 'N/A')}\")\n",
    "print(f\"  스키마 버전 수:      {len(meta.get('schemas', []))}\")\n",
    "print(f\"  스냅샷 수:           {len(meta.get('snapshots', []))}\")\n",
    "print(f\"  파티션 스펙 수:      {len(meta.get('partition-specs', []))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1000011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스키마 정보\n",
    "print(\"[ schemas ]\\n\")\n",
    "for schema in meta.get('schemas', []):\n",
    "    print(f\"  Schema ID: {schema['schema-id']}\")\n",
    "    for field in schema['fields']:\n",
    "        print(f\"    - id={field['id']}, name={field['name']}, type={field['type']}, required={field['required']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1000012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파티션 스펙\n",
    "print(\"[ partition-specs ]\\n\")\n",
    "for spec in meta.get('partition-specs', []):\n",
    "    print(f\"  Spec ID: {spec['spec-id']}\")\n",
    "    for field in spec['fields']:\n",
    "        print(f\"    - source-id={field['source-id']}, name={field['name']}, transform={field['transform']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1000013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스냅샷 목록\n",
    "print(\"[ snapshots ]\\n\")\n",
    "for snap in meta.get('snapshots', []):\n",
    "    print(f\"  Snapshot ID:   {snap['snapshot-id']}\")\n",
    "    print(f\"  Timestamp:     {snap['timestamp-ms']}\")\n",
    "    print(f\"  Operation:     {snap.get('summary', {}).get('operation', 'N/A')}\")\n",
    "    print(f\"  Manifest List: {os.path.basename(snap['manifest-list'])}\")\n",
    "    summary = snap.get('summary', {})\n",
    "    print(f\"  Summary:       added-files={summary.get('added-data-files-count', '?')}, \"\n",
    "          f\"total-records={summary.get('total-records-count', '?')}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1000014",
   "metadata": {},
   "source": [
    "## 2단계: Manifest List (snap-*.avro) 분석\n",
    "\n",
    "Manifest List는 스냅샷에 포함되는 **manifest file들의 목록**을 담고 있습니다.  \n",
    "`fastavro`를 사용하여 직접 읽어봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1000015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastavro\n",
    "\n",
    "# 현재 스냅샷의 manifest list 찾기\n",
    "current_snap = None\n",
    "current_snap_id = meta.get('current-snapshot-id')\n",
    "for snap in meta.get('snapshots', []):\n",
    "    if snap['snapshot-id'] == current_snap_id:\n",
    "        current_snap = snap\n",
    "        break\n",
    "\n",
    "manifest_list_path = current_snap['manifest-list']\n",
    "print(f\"현재 스냅샷의 Manifest List: {os.path.basename(manifest_list_path)}\\n\")\n",
    "\n",
    "with open(manifest_list_path, 'rb') as f:\n",
    "    reader = fastavro.reader(f)\n",
    "    manifest_list_records = list(reader)\n",
    "\n",
    "print(f\"Manifest 파일 수: {len(manifest_list_records)}개\\n\")\n",
    "\n",
    "for i, record in enumerate(manifest_list_records):\n",
    "    print(f\"  [{i}] Manifest File\")\n",
    "    print(f\"      path:                  {os.path.basename(record['manifest_path'])}\")\n",
    "    print(f\"      manifest_length:       {record.get('manifest_length', 'N/A')} bytes\")\n",
    "    print(f\"      added_data_files_count:   {record.get('added_data_files_count', 'N/A')}\")\n",
    "    print(f\"      existing_data_files_count: {record.get('existing_data_files_count', 'N/A')}\")\n",
    "    print(f\"      deleted_data_files_count:  {record.get('deleted_data_files_count', 'N/A')}\")\n",
    "    \n",
    "    partitions = record.get('partitions', [])\n",
    "    if partitions:\n",
    "        print(f\"      partition_summaries:\")\n",
    "        for ps in partitions:\n",
    "            print(f\"        contains_null={ps.get('contains_null')}, \"\n",
    "                  f\"lower_bound={ps.get('lower_bound')}, upper_bound={ps.get('upper_bound')}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1000016",
   "metadata": {},
   "source": [
    "## 3단계: Manifest File (*.avro) 분석\n",
    "\n",
    "Manifest File은 개별 **데이터 파일의 상세 정보**를 담고 있습니다.  \n",
    "여기에 **컬럼 수준 통계**(min/max, null count 등)가 저장됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1000017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫 번째 manifest file 읽기\n",
    "manifest_path = manifest_list_records[0]['manifest_path']\n",
    "print(f\"Manifest File: {os.path.basename(manifest_path)}\\n\")\n",
    "\n",
    "with open(manifest_path, 'rb') as f:\n",
    "    reader = fastavro.reader(f)\n",
    "    manifest_records = list(reader)\n",
    "\n",
    "print(f\"데이터 파일 엔트리 수: {len(manifest_records)}개\\n\")\n",
    "\n",
    "# 첫 번째 엔트리 상세 분석\n",
    "entry = manifest_records[0]\n",
    "df_info = entry.get('data_file', entry)  # 구조에 따라 다를 수 있음\n",
    "\n",
    "print(\"[ 데이터 파일 엔트리 키 목록 ]\")\n",
    "if isinstance(df_info, dict):\n",
    "    for key in sorted(df_info.keys()):\n",
    "        val = df_info[key]\n",
    "        if isinstance(val, dict) and len(str(val)) > 100:\n",
    "            print(f\"  {key}: (dict, {len(val)} entries)\")\n",
    "        elif isinstance(val, bytes) and len(val) > 50:\n",
    "            print(f\"  {key}: (bytes, {len(val)} bytes)\")\n",
    "        else:\n",
    "            print(f\"  {key}: {val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1000018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 데이터 파일 엔트리의 주요 정보 출력\n",
    "print(\"[ 모든 데이터 파일 상세 ]\\n\")\n",
    "\n",
    "for i, entry in enumerate(manifest_records[:10]):  # 최대 10개만\n",
    "    df_info = entry.get('data_file', entry)\n",
    "    if isinstance(df_info, dict):\n",
    "        file_path = df_info.get('file_path', 'N/A')\n",
    "        record_count = df_info.get('record_count', 'N/A')\n",
    "        file_size = df_info.get('file_size_in_bytes', 'N/A')\n",
    "        \n",
    "        print(f\"  [{i}] {os.path.basename(str(file_path))}\")\n",
    "        print(f\"      record_count:     {record_count}\")\n",
    "        print(f\"      file_size:        {file_size} bytes\")\n",
    "        \n",
    "        # column_sizes\n",
    "        col_sizes = df_info.get('column_sizes', {})\n",
    "        if col_sizes:\n",
    "            print(f\"      column_sizes:     {col_sizes}\")\n",
    "        \n",
    "        # value_counts\n",
    "        val_counts = df_info.get('value_counts', {})\n",
    "        if val_counts:\n",
    "            print(f\"      value_counts:     {val_counts}\")\n",
    "        \n",
    "        # null_value_counts\n",
    "        null_counts = df_info.get('null_value_counts', {})\n",
    "        if null_counts:\n",
    "            print(f\"      null_value_counts: {null_counts}\")\n",
    "        \n",
    "        # lower_bounds / upper_bounds\n",
    "        lower = df_info.get('lower_bounds', {})\n",
    "        upper = df_info.get('upper_bounds', {})\n",
    "        if lower:\n",
    "            print(f\"      lower_bounds:     {lower}\")\n",
    "        if upper:\n",
    "            print(f\"      upper_bounds:     {upper}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1000019",
   "metadata": {},
   "source": [
    "## Column-level Statistics와 쿼리 최적화\n",
    "\n",
    "Manifest File에 저장된 `lower_bounds`와 `upper_bounds`는 **파일 프루닝(File Pruning)**에 사용됩니다.\n",
    "\n",
    "예를 들어, 다음 쿼리를 실행할 때:\n",
    "\n",
    "```sql\n",
    "SELECT * FROM orders WHERE amount > 5000\n",
    "```\n",
    "\n",
    "Iceberg는 각 데이터 파일의 `amount` 컬럼 `upper_bounds`를 확인하여:\n",
    "- `upper_bounds(amount) < 5000`인 파일은 **읽지 않고 건너뜁니다**\n",
    "- 이를 통해 불필요한 I/O를 줄이고 쿼리 성능을 향상시킵니다\n",
    "\n",
    "```\n",
    "파일 A: amount lower=100, upper=3000  → ❌ SKIP (max < 5000)\n",
    "파일 B: amount lower=200, upper=6000  → ✅ READ (max >= 5000)\n",
    "파일 C: amount lower=5500, upper=8000 → ✅ READ (max >= 5000)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c100001a",
   "metadata": {},
   "source": [
    "## Snapshot 체인 시각화\n",
    "\n",
    "여러 작업을 거치면서 스냅샷이 어떻게 쌓이는지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c100001b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "snapshots = meta.get('snapshots', [])\n",
    "\n",
    "print(\"Snapshot 체인:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, snap in enumerate(snapshots):\n",
    "    snap_id = snap['snapshot-id']\n",
    "    ts = datetime.fromtimestamp(snap['timestamp-ms'] / 1000).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    op = snap.get('summary', {}).get('operation', '?')\n",
    "    total_records = snap.get('summary', {}).get('total-records-count', '?')\n",
    "    is_current = \" ◀ CURRENT\" if snap_id == current_snap_id else \"\"\n",
    "    \n",
    "    if i > 0:\n",
    "        print(\"     │\")\n",
    "        print(\"     ▼\")\n",
    "    \n",
    "    print(f\"  ┌─── Snapshot v{i+1}{is_current}\")\n",
    "    print(f\"  │ ID:        {snap_id}\")\n",
    "    print(f\"  │ Time:      {ts}\")\n",
    "    print(f\"  │ Operation: {op}\")\n",
    "    print(f\"  │ Records:   {total_records}\")\n",
    "    print(f\"  └───\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c100001c",
   "metadata": {},
   "source": [
    "## 관찰 포인트\n",
    "\n",
    "### Metadata Layer의 핵심 역할\n",
    "\n",
    "1. **metadata.json**: 테이블의 \"전체 역사\"를 담는 파일\n",
    "   - 모든 스냅샷 목록과 현재 스냅샷 ID를 관리\n",
    "   - 스키마 변경 이력, 파티션 스펙 등을 추적\n",
    "\n",
    "2. **Manifest List (snap-*.avro)**: 스냅샷의 \"목차\"\n",
    "   - 어떤 manifest file들이 이 스냅샷에 포함되는지\n",
    "   - 파티션별 요약 통계로 빠른 필터링 가능\n",
    "\n",
    "3. **Manifest File (*.avro)**: 데이터 파일의 \"상세 카탈로그\"\n",
    "   - 파일별 레코드 수, 크기, 컬럼 통계\n",
    "   - `lower_bounds`/`upper_bounds`로 파일 프루닝 지원\n",
    "   - `null_value_counts`로 NULL 관련 쿼리 최적화\n",
    "\n",
    "### Metadata가 쿼리에 미치는 영향\n",
    "\n",
    "- Manifest List의 파티션 요약 → **파티션 프루닝**\n",
    "- Manifest File의 min/max 통계 → **파일 프루닝**\n",
    "- 이 두 단계를 거쳐 **실제로 읽어야 할 데이터 파일 수를 최소화**합니다\n",
    "\n",
    "### 스냅샷 체인\n",
    "\n",
    "- 각 작업(INSERT, UPDATE, DELETE)마다 새로운 스냅샷이 생성됩니다\n",
    "- 이전 스냅샷은 그대로 유지되어 **Time Travel**이 가능합니다\n",
    "- 이 스냅샷 기반 버전 관리를 다음 `3_features/01-time-travel.ipynb`에서 활용합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c100001d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()\n",
    "print(\"Spark 세션 종료\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}