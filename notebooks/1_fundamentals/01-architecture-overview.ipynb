{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "# 01. Apache Iceberg 아키텍처 개요\n",
    "\n",
    "이 노트북에서는 Apache Iceberg의 **3-Layer 아키텍처**를 실제 파일 구조를 통해 확인합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d5",
   "metadata": {},
   "source": [
    "## Iceberg 3-Layer 아키텍처\n",
    "\n",
    "Apache Iceberg 테이블은 세 개의 계층으로 구성됩니다.\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────┐\n",
    "│         Catalog Layer           │\n",
    "│  (테이블 이름 → 현재 metadata   │\n",
    "│   파일 위치를 가리키는 포인터)    │\n",
    "└──────────────┬──────────────────┘\n",
    "               │\n",
    "               ▼\n",
    "┌─────────────────────────────────┐\n",
    "│        Metadata Layer           │\n",
    "│  metadata.json → manifest list  │\n",
    "│  → manifest files               │\n",
    "│  (스냅샷, 스키마, 파티션 정보,   │\n",
    "│   파일 수준 통계 등)             │\n",
    "└──────────────┬──────────────────┘\n",
    "               │\n",
    "               ▼\n",
    "┌─────────────────────────────────┐\n",
    "│          Data Layer             │\n",
    "│  실제 데이터가 저장된            │\n",
    "│  Parquet / ORC / Avro 파일들    │\n",
    "└─────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### 각 계층의 역할\n",
    "\n",
    "| 계층 | 구성 요소 | 역할 |\n",
    "|------|-----------|------|\n",
    "| **Catalog Layer** | Hadoop FS / Hive Metastore / REST 등 | 테이블 이름을 현재 metadata.json 파일 경로로 매핑 |\n",
    "| **Metadata Layer** | metadata.json, snap-*.avro, manifest-*.avro | 테이블 스냅샷, 스키마, 파티션 정보, 파일 수준 통계 관리 |\n",
    "| **Data Layer** | .parquet 파일들 | 실제 레코드가 저장된 데이터 파일 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d6",
   "metadata": {},
   "source": [
    "## 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2c3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.spark_setup import create_spark_session\n",
    "from utils.data_generator import generate_orders, to_spark_df\n",
    "from utils.file_explorer import show_tree, count_files, total_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2c3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = create_spark_session(\"ArchOverview\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d9",
   "metadata": {},
   "source": [
    "## 테이블 생성\n",
    "\n",
    "`PARTITIONED BY (months(order_date))`를 사용하여 월 단위 파티션을 설정합니다.  \n",
    "이것은 Iceberg의 **Hidden Partitioning** 기능으로, 사용자가 파티션 컬럼을 직접 관리할 필요가 없습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2c3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS demo.lab\")\n",
    "spark.sql(\"DROP TABLE IF EXISTS demo.lab.arch_orders\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    CREATE TABLE demo.lab.arch_orders (\n",
    "        order_id     BIGINT,\n",
    "        customer_id  BIGINT,\n",
    "        product_name STRING,\n",
    "        order_date   DATE,\n",
    "        amount       DOUBLE,\n",
    "        status       STRING\n",
    "    )\n",
    "    USING iceberg\n",
    "    PARTITIONED BY (months(order_date))\n",
    "\"\"\")\n",
    "\n",
    "print(\"테이블 생성 완료: demo.lab.arch_orders\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3db",
   "metadata": {},
   "source": [
    "## 데이터 삽입\n",
    "\n",
    "100건의 랜덤 주문 데이터를 생성하여 Iceberg 테이블에 삽입합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2c3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = generate_orders(num_records=100, seed=42)\n",
    "df = to_spark_df(spark, orders)\n",
    "\n",
    "df.writeTo(\"demo.lab.arch_orders\").append()\n",
    "\n",
    "count = spark.sql(\"SELECT COUNT(*) AS cnt FROM demo.lab.arch_orders\").collect()[0][\"cnt\"]\n",
    "print(f\"삽입 완료: {count}건\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3dd",
   "metadata": {},
   "source": [
    "## Warehouse 디렉토리 구조 탐색\n",
    "\n",
    "`show_tree`로 Iceberg 테이블이 파일 시스템에 어떤 구조로 저장되는지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2c3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "TABLE_PATH = \"/home/jovyan/data/warehouse/lab/arch_orders\"\n",
    "\n",
    "show_tree(TABLE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3df",
   "metadata": {},
   "source": [
    "## 파일 통계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2c3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_count = count_files(TABLE_PATH, ext=\".parquet\")\n",
    "json_count = count_files(TABLE_PATH, ext=\".json\")\n",
    "avro_count = count_files(TABLE_PATH, ext=\".avro\")\n",
    "total = total_size(TABLE_PATH)\n",
    "\n",
    "print(f\"Parquet 파일 (Data Layer):    {parquet_count}개\")\n",
    "print(f\"JSON 파일 (Metadata Layer):   {json_count}개\")\n",
    "print(f\"Avro 파일 (Metadata Layer):   {avro_count}개\")\n",
    "print(f\"전체 크기:                    {total / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3e1",
   "metadata": {},
   "source": [
    "## 관찰 포인트\n",
    "\n",
    "디렉토리 구조를 보면 크게 두 영역으로 나뉩니다:\n",
    "\n",
    "### Data Layer (`data/` 디렉토리)\n",
    "- `data/` 안에 파티션 디렉토리들이 존재 (예: `order_date_month=2024-01/`)\n",
    "- 각 파티션 안에 `.parquet` 파일 = **실제 데이터**\n",
    "- Parquet는 **컬럼 기반(columnar)** 포맷으로, 분석 쿼리에 최적화\n",
    "\n",
    "### Metadata Layer (`metadata/` 디렉토리)\n",
    "- `metadata.json` = 테이블의 **현재 상태** (스키마, 파티션 스펙, 스냅샷 목록 등)\n",
    "- `snap-*.avro` = **Manifest List** (어떤 manifest 파일이 이 스냅샷에 포함되는지)\n",
    "- `*.avro` (snap- 접두어 없음) = **Manifest File** (어떤 data 파일이 포함되는지 + 통계)\n",
    "\n",
    "### Catalog Layer\n",
    "- Hadoop catalog의 경우, `version-hint.text` 파일이 현재 metadata.json의 버전을 가리킵니다\n",
    "- 이것이 Catalog Layer의 \"포인터\" 역할을 합니다\n",
    "\n",
    "---\n",
    "\n",
    "**다음 노트북에서 이 파일들의 내부를 분석합니다.** Data Layer의 Parquet 파일 내부 구조와 Metadata Layer의 JSON/Avro 파일 내용을 직접 읽어보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2c3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()\n",
    "print(\"Spark 세션 종료\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}