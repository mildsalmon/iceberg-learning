{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "# 01. Apache Iceberg 아키텍처 개요\n",
    "\n",
    "이 노트북에서는 Apache Iceberg의 **3-Layer 아키텍처**를 실제 파일 구조를 통해 확인합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d5",
   "metadata": {},
   "source": [
    "## Iceberg 3-Layer 아키텍처\n",
    "\n",
    "Apache Iceberg 테이블은 세 개의 계층으로 구성됩니다.\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────┐\n",
    "│         Catalog Layer           │\n",
    "│  (테이블 이름 → 현재 metadata   │\n",
    "│   파일 위치를 가리키는 포인터)    │\n",
    "└──────────────┬──────────────────┘\n",
    "               │\n",
    "               ▼\n",
    "┌─────────────────────────────────┐\n",
    "│        Metadata Layer           │\n",
    "│  metadata.json → manifest list  │\n",
    "│  → manifest files               │\n",
    "│  (스냅샷, 스키마, 파티션 정보,   │\n",
    "│   파일 수준 통계 등)             │\n",
    "└──────────────┬──────────────────┘\n",
    "               │\n",
    "               ▼\n",
    "┌─────────────────────────────────┐\n",
    "│          Data Layer             │\n",
    "│  실제 데이터가 저장된            │\n",
    "│  Parquet / ORC / Avro 파일들    │\n",
    "└─────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### 각 계층의 역할\n",
    "\n",
    "| 계층 | 구성 요소 | 역할 |\n",
    "|------|-----------|------|\n",
    "| **Catalog Layer** | Hadoop FS / Hive Metastore / REST 등 | 테이블 이름을 현재 metadata.json 파일 경로로 매핑 |\n",
    "| **Metadata Layer** | metadata.json, snap-*.avro, manifest-*.avro | 테이블 스냅샷, 스키마, 파티션 정보, 파일 수준 통계 관리 |\n",
    "| **Data Layer** | .parquet 파일들 | 실제 레코드가 저장된 데이터 파일 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d6",
   "metadata": {},
   "source": [
    "## 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1b2c3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.spark_setup import create_spark_session\n",
    "from utils.data_generator import generate_orders, to_spark_df\n",
    "from utils.file_explorer import show_tree, count_files, total_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1b2c3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark + Iceberg 세션 준비 완료 (warehouse: file:///home/jovyan/data/warehouse)\n"
     ]
    }
   ],
   "source": [
    "spark = create_spark_session(\"ArchOverview\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d9",
   "metadata": {},
   "source": [
    "## 테이블 생성\n",
    "\n",
    "`PARTITIONED BY (months(order_date))`를 사용하여 월 단위 파티션을 설정합니다.  \n",
    "이것은 Iceberg의 **Hidden Partitioning** 기능으로, 사용자가 파티션 컬럼을 직접 관리할 필요가 없습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1b2c3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테이블 생성 완료: demo.lab.arch_orders\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS demo.lab\")\n",
    "spark.sql(\"DROP TABLE IF EXISTS demo.lab.arch_orders\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    CREATE TABLE demo.lab.arch_orders (\n",
    "        order_id     BIGINT,\n",
    "        customer_id  BIGINT,\n",
    "        product_name STRING,\n",
    "        order_date   DATE,\n",
    "        amount       DOUBLE,\n",
    "        status       STRING\n",
    "    )\n",
    "    USING iceberg\n",
    "    PARTITIONED BY (months(order_date))\n",
    "\"\"\")\n",
    "\n",
    "print(\"테이블 생성 완료: demo.lab.arch_orders\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3db",
   "metadata": {},
   "source": [
    "## 데이터 삽입\n",
    "\n",
    "여러 번의 배치 적재를 시뮬레이션합니다.\n",
    "**각 append마다 새로운 스냅샷, manifest list, manifest file**이 생성되므로 Metadata Layer가 어떻게 쌓이는지 관찰할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1b2c3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 1/4 완료 (200건 삽입)\n",
      "배치 2/4 완료 (200건 삽입)\n",
      "배치 3/4 완료 (200건 삽입)\n",
      "배치 4/4 완료 (200건 삽입)\n",
      "\n",
      "총 레코드: 800건\n"
     ]
    }
   ],
   "source": [
    "# 4번의 배치 적재 → 4개의 스냅샷, 각각 새로운 manifest file 생성\n",
    "for i in range(4):\n",
    "    orders = generate_orders(num_records=200, seed=i, id_offset=i*200+1)\n",
    "    df = to_spark_df(spark, orders)\n",
    "    df.writeTo(\"demo.lab.arch_orders\").append()\n",
    "    print(f\"배치 {i+1}/4 완료 (200건 삽입)\")\n",
    "\n",
    "count = spark.sql(\"SELECT COUNT(*) AS cnt FROM demo.lab.arch_orders\").collect()[0][\"cnt\"]\n",
    "print(f\"\\n총 레코드: {count}건\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3dd",
   "metadata": {},
   "source": [
    "## Warehouse 디렉토리 구조 탐색\n",
    "\n",
    "`show_tree`로 Iceberg 테이블이 파일 시스템에 어떤 구조로 저장되는지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1b2c3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "├── data/\n",
      "│   ├── order_date_month=2024-01/\n",
      "│   │   ├── 00000-11-5decdb65-aafa-48cf-b0b7-17fe7d84e297-00001.parquet  (2.9 KB)\n",
      "│   │   ├── 00000-17-9ba26da7-af04-4847-aa9c-21c79fbb45f2-00001.parquet  (2.9 KB)\n",
      "│   │   ├── 00000-23-3eeb50fc-6dcd-48b8-bbaf-fe8714f1ad17-00001.parquet  (2.9 KB)\n",
      "│   │   └── 00000-5-bc643c3e-960f-4d5e-abf7-a34c45cbf6cc-00001.parquet  (2.9 KB)\n",
      "│   ├── order_date_month=2024-02/\n",
      "│   │   ├── 00000-11-5decdb65-aafa-48cf-b0b7-17fe7d84e297-00002.parquet  (2.9 KB)\n",
      "│   │   ├── 00000-17-9ba26da7-af04-4847-aa9c-21c79fbb45f2-00002.parquet  (2.9 KB)\n",
      "│   │   ├── 00000-23-3eeb50fc-6dcd-48b8-bbaf-fe8714f1ad17-00002.parquet  (2.9 KB)\n",
      "│   │   └── 00000-5-bc643c3e-960f-4d5e-abf7-a34c45cbf6cc-00002.parquet  (2.9 KB)\n",
      "│   └── order_date_month=2024-03/\n",
      "│       ├── 00000-11-5decdb65-aafa-48cf-b0b7-17fe7d84e297-00003.parquet  (2.9 KB)\n",
      "│       ├── 00000-17-9ba26da7-af04-4847-aa9c-21c79fbb45f2-00003.parquet  (2.8 KB)\n",
      "│       ├── 00000-23-3eeb50fc-6dcd-48b8-bbaf-fe8714f1ad17-00003.parquet  (2.9 KB)\n",
      "│       └── 00000-5-bc643c3e-960f-4d5e-abf7-a34c45cbf6cc-00003.parquet  (2.8 KB)\n",
      "└── metadata/\n",
      "    ├── 21b9ef12-d1ac-493e-b390-f0d0970daf1c-m0.avro  (7.3 KB)\n",
      "    ├── 2e4a8e6c-7949-455b-9fdf-a0c502e12f2f-m0.avro  (7.3 KB)\n",
      "    ├── 4c80a311-a64d-49b1-a6b7-6cf83c3e500f-m0.avro  (7.3 KB)\n",
      "    ├── 55448ca6-9406-44f9-b7b4-7124675d6200-m0.avro  (7.3 KB)\n",
      "    ├── snap-28521936869422133-1-55448ca6-9406-44f9-b7b4-7124675d6200.avro  (4.3 KB)\n",
      "    ├── snap-4484300566518094620-1-21b9ef12-d1ac-493e-b390-f0d0970daf1c.avro  (4.3 KB)\n",
      "    ├── snap-6906939341173646190-1-2e4a8e6c-7949-455b-9fdf-a0c502e12f2f.avro  (4.2 KB)\n",
      "    ├── snap-8589837090881560253-1-4c80a311-a64d-49b1-a6b7-6cf83c3e500f.avro  (4.3 KB)\n",
      "    ├── v1.metadata.json  (1.5 KB)\n",
      "    ├── v2.metadata.json  (2.5 KB)\n",
      "    ├── v3.metadata.json  (3.5 KB)\n",
      "    ├── v4.metadata.json  (4.5 KB)\n",
      "    ├── v5.metadata.json  (5.5 KB)\n",
      "    └── version-hint.text  (1 B)\n"
     ]
    }
   ],
   "source": [
    "TABLE_PATH = \"/home/jovyan/data/warehouse/lab/arch_orders\"\n",
    "\n",
    "show_tree(TABLE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3df",
   "metadata": {},
   "source": [
    "## 파일 통계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1b2c3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet 파일 (Data Layer):    12개\n",
      "JSON 파일 (Metadata Layer):   5개\n",
      "Avro 파일 (Metadata Layer):   8개\n",
      "전체 크기:                    98.2 KB\n"
     ]
    }
   ],
   "source": [
    "parquet_count = count_files(TABLE_PATH, ext=\".parquet\")\n",
    "json_count = count_files(TABLE_PATH, ext=\".json\")\n",
    "avro_count = count_files(TABLE_PATH, ext=\".avro\")\n",
    "total = total_size(TABLE_PATH)\n",
    "\n",
    "print(f\"Parquet 파일 (Data Layer):    {parquet_count}개\")\n",
    "print(f\"JSON 파일 (Metadata Layer):   {json_count}개\")\n",
    "print(f\"Avro 파일 (Metadata Layer):   {avro_count}개\")\n",
    "print(f\"전체 크기:                    {total / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3e1",
   "metadata": {},
   "source": [
    "## 관찰 포인트\n",
    "\n",
    "디렉토리 구조를 보면 크게 두 영역으로 나뉩니다:\n",
    "\n",
    "### Data Layer (`data/` 디렉토리)\n",
    "- `data/` 안에 파티션 디렉토리들이 존재 (예: `order_date_month=2024-01/`)\n",
    "- 각 파티션 안에 `.parquet` 파일 = **실제 데이터**\n",
    "- **4번의 append로 파티션당 최대 4개의 parquet 파일**이 생성됨\n",
    "\n",
    "### Metadata Layer (`metadata/` 디렉토리)\n",
    "\n",
    "| 파일 | 역할 |\n",
    "|------|------|\n",
    "| `v1~v5.metadata.json` | 테이블 생성(v1) + 4번 append(v2~v5). 가장 최신 버전이 현재 상태 |\n",
    "| `snap-*.avro` (4개) | **Manifest List** — 각 스냅샷이 어떤 manifest file들을 참조하는지 |\n",
    "| `*-m0.avro` (4개) | **Manifest File** — 각 append에서 추가된 parquet 파일 목록 + 통계 |\n",
    "\n",
    "### 핵심: 계층 구조\n",
    "\n",
    "```\n",
    "metadata.json (현재 스냅샷 ID를 가리킴)\n",
    "  └─▶ snap-*.avro (Manifest List)  ← 스냅샷 4는 manifest 4개를 참조\n",
    "        ├─▶ manifest-1.avro  → [parquet-1a, parquet-1b, parquet-1c]  (배치 1)\n",
    "        ├─▶ manifest-2.avro  → [parquet-2a, parquet-2b, parquet-2c]  (배치 2)\n",
    "        ├─▶ manifest-3.avro  → [parquet-3a, parquet-3b, parquet-3c]  (배치 3)\n",
    "        └─▶ manifest-4.avro  → [parquet-4a, parquet-4b, parquet-4c]  (배치 4)\n",
    "```\n",
    "\n",
    "**최신 스냅샷의 manifest list가 이전 배치의 manifest file까지 모두 포함**합니다.\n",
    "이렇게 해야 \"현재 테이블의 전체 데이터\"를 알 수 있기 때문입니다.\n",
    "\n",
    "### Catalog Layer\n",
    "- Hadoop catalog의 경우, `version-hint.text` 파일이 현재 metadata.json의 버전 번호를 가리킵니다\n",
    "- 이것이 Catalog Layer의 \"포인터\" 역할\n",
    "\n",
    "---\n",
    "\n",
    "**다음 노트북에서 이 파일들의 내부를 분석합니다.** Data Layer의 Parquet 파일 내부 구조와 Metadata Layer의 JSON/Avro 파일 내용을 직접 읽어보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1b2c3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark 세션 종료\n"
     ]
    }
   ],
   "source": [
    "spark.stop()\n",
    "print(\"Spark 세션 종료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2ed7b3-8c70-4a65-90c2-b201cb6da59e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
